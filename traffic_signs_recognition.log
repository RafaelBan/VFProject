./run_all_categories.sh v1 ${HOME}/repos/VFProject/alpha-beta-CROWN/vnncomp_scripts $(pwd) results_traffic_signs_recognition.csv ./counter-examples "traffic_signs_recognition" all
Running measurements with vnncomp folder '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks' for tool scripts in '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp_scripts' and saving results to 'results_traffic_signs_recognition.csv'.
Running traffic_signs_recognition category from /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/instances.csv
Category 'traffic_signs_recognition' timeout sum: 45000 seconds
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:16:37 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 85%   48C    P5              27W / 170W |    642MiB / 12288MiB |     15%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     69MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    222MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.057934236

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:16:47 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2153s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 472., 1398., 1508., 1554., 1440., 1482.,  750., 1084., 1158.,  136.,
          838.,  876.,  268., -116.,  338., 1376.,  570.,  442.,  658.,  596.,
          488.,  748.,  286.,  696.,  920.,  612.,  568.,  204., 1012.,  134.,
          568.,  486.,  692.,  690.,  -60.,  610., -102., -604.,  332.,  378.,
          422.,  514.,  536.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 466., 1348., 1526., 1508., 1366., 1516.,  772., 1090., 1176.,  138.,
           888.,  930.,  330.,  -46.,  396., 1358.,  572.,  356.,  604.,  590.,
           582.,  734.,  224.,  582.,  914.,  586.,  678.,  190., 1066.,   64.,
           594.,  500.,  706.,  776.,  -78.,  588.,  -52., -586.,  326.,  352.,
           548.,  588.,  586.],
         [ 466., 1348., 1526., 1508., 1366., 1516.,  772., 1090., 1176.,  138.,
           888.,  930.,  330.,  -46.,  396., 1358.,  572.,  356.,  604.,  590.,
           582.,  734.,  224.,  582.,  914.,  586.,  678.,  190., 1066.,   64.,
           594.,  500.,  706.,  776.,  -78.,  588.,  -52., -586.,  326.,  352.,
           548.,  588.,  586.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[1042.,  160.,  -18.,  142.,   -8.,  736.,  418.,  332., 1370.,  620.]]],
       device='cuda:0')
number of violation:  2
Attack finished in 0.0487 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 0.994276762008667
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.838875522
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:16:54 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 84%   47C    P5              30W / 170W |    676MiB / 12288MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     69MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    222MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      126MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.042773029

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:17:04 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2496s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 472., 1398., 1508., 1554., 1440., 1482.,  750., 1084., 1158.,  136.,
          838.,  876.,  268., -116.,  338., 1376.,  570.,  442.,  658.,  596.,
          488.,  748.,  286.,  696.,  920.,  612.,  568.,  204., 1012.,  134.,
          568.,  486.,  692.,  690.,  -60.,  610., -102., -604.,  332.,  378.,
          422.,  514.,  536.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 532., 1322., 1536., 1494., 1364., 1622.,  802., 1028., 1226.,  156.,
           874.,  692.,  236., -144.,  234., 1304.,  550.,  318.,  698.,  520.,
           528.,  860.,  282.,  736.,  908.,  448.,  716.,  180., 1008.,  238.,
           564.,  374.,  704.,  670., -104.,  586.,  -58., -548.,  392.,  334.,
           502.,  542.,  688.],
         [ 532., 1322., 1536., 1494., 1364., 1622.,  802., 1028., 1226.,  156.,
           874.,  692.,  236., -144.,  234., 1304.,  550.,  318.,  698.,  520.,
           528.,  860.,  282.,  736.,  908.,  448.,  716.,  180., 1008.,  238.,
           564.,  374.,  704.,  670., -104.,  586.,  -58., -548.,  392.,  334.,
           502.,  542.,  688.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 962.,  172.,  -42.,  130., -128.,  692.,  466.,  268., 1338.,  620.]]],
       device='cuda:0')
number of violation:  2
Attack finished in 0.0490 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0107052326202393
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.998166390
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:17:11 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 84%   46C    P5              27W / 170W |    642MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     69MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    222MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 11.983922861

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:17:21 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2010s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 472., 1398., 1508., 1554., 1440., 1482.,  750., 1084., 1158.,  136.,
          838.,  876.,  268., -116.,  338., 1376.,  570.,  442.,  658.,  596.,
          488.,  748.,  286.,  696.,  920.,  612.,  568.,  204., 1012.,  134.,
          568.,  486.,  692.,  690.,  -60.,  610., -102., -604.,  332.,  378.,
          422.,  514.,  536.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 738., 1252., 1482., 1488., 1318., 1484.,  608., 1110., 1324.,  -78.,
           768.,  814.,   46., -250.,  268., 1494.,  456.,  436.,  660.,  554.,
           566.,  674.,  368.,  738.,  962.,  430.,  850.,  254., 1046.,  156.,
           638.,  600.,  622.,  696., -254.,  496.,  -88., -562.,  370.,  312.,
           324.,  332.,  386.],
         [ 738., 1252., 1482., 1488., 1318., 1484.,  608., 1110., 1324.,  -78.,
           768.,  814.,   46., -250.,  268., 1494.,  456.,  436.,  660.,  554.,
           566.,  674.,  368.,  738.,  962.,  430.,  850.,  254., 1046.,  156.,
           638.,  600.,  622.,  696., -254.,  496.,  -88., -562.,  370.,  312.,
           324.,  332.,  386.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 750.,  236.,    6.,  170.,    4.,  880.,  378.,  164., 1566.,  720.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0529 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0376243591308594
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.917746672
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:17:28 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 83%   47C    P0              38W / 170W |    653MiB / 12288MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          218MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     71MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    222MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.021417032

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:17:38 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2230s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 472., 1398., 1508., 1554., 1440., 1482.,  750., 1084., 1158.,  136.,
          838.,  876.,  268., -116.,  338., 1376.,  570.,  442.,  658.,  596.,
          488.,  748.,  286.,  696.,  920.,  612.,  568.,  204., 1012.,  134.,
          568.,  486.,  692.,  690.,  -60.,  610., -102., -604.,  332.,  378.,
          422.,  514.,  536.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 476., 1322., 1616., 1554., 1360., 1334.,  518., 1016., 1198.,  176.,
           818.,  948.,  108.,    4.,  454., 1528.,  310.,  146.,  590.,  428.,
           732.,  736.,  362.,  708.,  856.,  356.,  636.,  396., 1164.,  314.,
           508.,  738.,  680.,  838., -160.,  722., -194., -556.,  436.,  338.,
           502.,  458.,  448.],
         [ 476., 1322., 1616., 1554., 1360., 1334.,  518., 1016., 1198.,  176.,
           818.,  948.,  108.,    4.,  454., 1528.,  310.,  146.,  590.,  428.,
           732.,  736.,  362.,  708.,  856.,  356.,  636.,  396., 1164.,  314.,
           508.,  738.,  680.,  838., -160.,  722., -194., -556.,  436.,  338.,
           502.,  458.,  448.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[1078.,  232.,  -62.,  194.,  220., 1036.,  538.,  356., 1378.,  736.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0489 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0021202564239502
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.924496021
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:17:45 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 82%   44C    P5              29W / 170W |    646MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     75MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    220MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.002680532

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:17:55 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2279s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_7040_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 478., 1396., 1510., 1552., 1442., 1488.,  748., 1082., 1168.,  134.,
          820.,  882.,  274., -126.,  340., 1370.,  584.,  448.,  664.,  590.,
          502.,  758.,  292.,  702.,  914.,  606.,  570.,  198., 1018.,  132.,
          562.,  480.,  698.,  700.,  -42.,  612., -100., -586.,  334.,  368.,
          428.,  512.,  542.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 470., 1172., 1418., 1332., 1326., 1540.,  556., 1174., 1544.,  230.,
           672.,  682.,  286.,  -18.,  -76., 1402.,  708.,  340.,  772.,  322.,
           418.,  806.,  400.,  678.,  826.,  626.,  942.,  162., 1126.,  320.,
           670.,  412.,  642.,  732., -186.,  648.,  -60., -334.,  282.,  344.,
           396.,  224.,  370.],
         [ 470., 1172., 1418., 1332., 1326., 1540.,  556., 1174., 1544.,  230.,
           672.,  682.,  286.,  -18.,  -76., 1402.,  708.,  340.,  772.,  322.,
           418.,  806.,  400.,  678.,  826.,  626.,  942.,  162., 1126.,  320.,
           670.,  412.,  642.,  732., -186.,  648.,  -60., -334.,  282.,  344.,
           396.,  224.,  370.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 862.,  160.,  -86.,    6., -208.,  776.,  158., -212., 1102.,  660.]]],
       device='cuda:0')
number of violation:  4
Attack finished in 0.0483 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0062439441680908
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.930347761
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:18:02 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 82%   44C    P5              27W / 170W |    646MiB / 12288MiB |      4%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     75MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    220MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
100%|| 1/1 [00:04<00:00,  4.24s/it]
100%|| 1/1 [00:03<00:00,  3.94s/it]
100%|| 1/1 [00:03<00:00,  3.95s/it]
100%|| 1/1 [00:04<00:00,  4.06s/it]
100%|| 1/1 [00:04<00:00,  4.09s/it]
100%|| 1/1 [00:04<00:00,  4.03s/it]
100%|| 1/1 [00:03<00:00,  3.98s/it]
100%|| 1/1 [00:04<00:00,  4.03s/it]
100%|| 1/1 [00:04<00:00,  4.10s/it]
100%|| 1/1 [00:03<00:00,  3.98s/it]
  0%|                                                     | 0/1 [00:00<?, ?it/s]Preparation finished.
prepare_instance.sh exit code: 0, runtime: 52.118621355

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:18:52 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2890s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.69s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.08000000e+02,  5.18000000e+02,  8.64000000e+02,  7.70000000e+02,
           7.88000000e+02,  9.18000000e+02,  9.40000000e+01,  7.04000000e+02,
           5.42000000e+02,  8.44000000e+02,  7.02000000e+02,  1.15600000e+03,
           3.28000000e+02,  7.96000000e+02, -1.15000000e+03,  7.84000000e+02,
           5.06000000e+02, -5.50000000e+02,  1.90000000e+02,  1.41200000e+03,
           3.00000000e+02,  1.12000000e+02, -2.00000000e+00,  2.64000000e+02,
           3.00000000e+02,  3.68000000e+02,  5.12000000e+02,  4.36000000e+02,
           7.60000000e+02,  3.70000000e+02,  7.68000000e+02,  5.66000000e+02,
          -1.92000000e+02,  3.05800000e+03,  7.04000000e+02,  1.66200000e+03,
           7.46000000e+02,  3.84000000e+02,  5.64000000e+02,  1.25800000e+03,
           4.94000000e+02, -6.60000000e+01, -2.68000000e+02],
         [ 1.08000000e+02,  5.18000000e+02,  8.64000000e+02,  7.70000000e+02,
           7.88000000e+02,  9.18000000e+02,  9.40000000e+01,  7.04000000e+02,
           5.42000000e+02,  8.44000000e+02,  7.02000000e+02,  1.15600000e+03,
           3.28000000e+02,  7.96000000e+02, -1.15000000e+03,  7.84000000e+02,
           5.06000000e+02, -5.50000000e+02,  1.90000000e+02,  1.41200000e+03,
           3.00000000e+02,  1.12000000e+02, -2.00000000e+00,  2.64000000e+02,
           3.00000000e+02,  3.68000000e+02,  5.12000000e+02,  4.36000000e+02,
           7.60000000e+02,  3.70000000e+02,  7.68000000e+02,  5.66000000e+02,
          -1.92000000e+02,  3.05800000e+03,  7.04000000e+02,  1.66200000e+03,
           7.46000000e+02,  3.84000000e+02,  5.64000000e+02,  1.25800000e+03,
           4.94000000e+02, -6.60000000e+01, -2.68000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2950., 2540., 2194., 2288., 2270., 2140., 2964., 2354., 2516., 2214.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.7022 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   72.,   478.,   904.,   778.,   748.,   830.,   146.,   776.,
            534.,   908.,   678.,  1224.,   412.,   752., -1162.,   788.,
            454.,  -598.,   198.,  1404.,   276.,    96.,   -22.,   380.,
            356.,   344.,   468.,   416.,   788.,   322.,   836.,   614.,
           -212.,  3214.,   728.,  1490.,   682.,   368.,   524.,  1186.,
            642.,  -190.,  -184.],
         [   72.,   478.,   904.,   778.,   748.,   830.,   146.,   776.,
            534.,   908.,   678.,  1224.,   412.,   752., -1162.,   788.,
            454.,  -598.,   198.,  1404.,   276.,    96.,   -22.,   380.,
            356.,   344.,   468.,   416.,   788.,   322.,   836.,   614.,
           -212.,  3214.,   728.,  1490.,   682.,   368.,   524.,  1186.,
            642.,  -190.,  -184.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2736., 2310., 2436., 2466., 2384., 3068., 2438., 2680., 2306.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0608 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.09s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  172.,   506.,   904.,   798.,   788.,   886.,   110.,   788.,
            538.,   936.,   686.,  1232.,   440.,   804., -1166.,   800.,
            518.,  -574.,   110.,  1340.,   268.,    48.,   -66.,   352.,
            288.,   280.,   576.,   440.,   792.,   314.,   836.,   546.,
           -224.,  3030.,   764.,  1622.,   678.,   384.,   516.,  1210.,
            538.,   -58.,  -240.],
         [  172.,   506.,   904.,   798.,   788.,   886.,   110.,   788.,
            538.,   936.,   686.,  1232.,   440.,   804., -1166.,   800.,
            518.,  -574.,   110.,  1340.,   268.,    48.,   -66.,   352.,
            288.,   280.,   576.,   440.,   792.,   314.,   836.,   546.,
           -224.,  3030.,   764.,  1622.,   678.,   384.,   516.,  1210.,
            538.,   -58.,  -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2858., 2524., 2126., 2232., 2242., 2144., 2920., 2242., 2492., 2094.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1008 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.34s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   480.,   886.,   764.,   842.,   828.,   144.,   734.,
            524.,   910.,   684.,  1230.,   422.,   706., -1132.,   790.,
            420.,  -624.,   188.,  1402.,   202.,    94.,   -24.,   402.,
            310.,   370.,   462.,   430.,   794.,   280.,   798.,   608.,
           -178.,  3220.,   746.,  1492.,   640.,   386.,   538.,  1176.,
            648.,  -140.,  -254.],
         [   74.,   480.,   886.,   764.,   842.,   828.,   144.,   734.,
            524.,   910.,   684.,  1230.,   422.,   706., -1132.,   790.,
            420.,  -624.,   188.,  1402.,   202.,    94.,   -24.,   402.,
            310.,   370.,   462.,   430.,   794.,   280.,   798.,   608.,
           -178.,  3220.,   746.,  1492.,   640.,   386.,   538.,  1176.,
            648.,  -140.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3146., 2740., 2334., 2456., 2378., 2392., 3076., 2486., 2696., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3505 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  198.,   496.,   834.,   832.,   806.,   916.,   116.,   670.,
            564.,   902.,   696.,  1146.,   406.,   826., -1116.,   806.,
            528.,  -556.,   124.,  1382.,   266.,    38.,    24.,   318.,
            282.,   378.,   534.,   442.,   790.,   380.,   822.,   492.,
           -182.,  3040.,   770.,  1632.,   692.,   374.,   522.,  1212.,
            544.,   -76.,  -246.],
         [  198.,   496.,   834.,   832.,   806.,   916.,   116.,   670.,
            564.,   902.,   696.,  1146.,   406.,   826., -1116.,   806.,
            528.,  -556.,   124.,  1382.,   266.,    38.,    24.,   318.,
            282.,   378.,   534.,   442.,   790.,   380.,   822.,   492.,
           -182.,  3040.,   770.,  1632.,   692.,   374.,   522.,  1212.,
            544.,   -76.,  -246.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2842., 2544., 2206., 2208., 2234., 2124., 2924., 2370., 2476., 2138.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9848 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.10s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   470.,   892.,   770.,   820.,   818.,   150.,   772.,
            514.,   888.,   694.,  1236.,   432.,   728., -1146.,   824.,
            454.,  -594.,   166.,  1352.,   212.,   100.,   -14.,   384.,
            336.,   328.,   484.,   400.,   788.,   250.,   788.,   566.,
           -200.,  3254.,   728.,  1534.,   690.,   392.,   496.,  1206.,
            654.,  -166.,  -264.],
         [   88.,   470.,   892.,   770.,   820.,   818.,   150.,   772.,
            514.,   888.,   694.,  1236.,   432.,   728., -1146.,   824.,
            454.,  -594.,   166.,  1352.,   212.,   100.,   -14.,   384.,
            336.,   328.,   484.,   400.,   788.,   250.,   788.,   566.,
           -200.,  3254.,   728.,  1534.,   690.,   392.,   496.,  1206.,
            654.,  -166.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2784., 2362., 2484., 2434., 2436., 3104., 2482., 2740., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1066 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.09s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  164.,   510.,   888.,   838.,   820.,   918.,    70.,   672.,
            534.,   844.,   650.,  1124.,   320.,   864., -1186.,   752.,
            518.,  -506.,   174.,  1412.,   220.,    36.,   -10.,   284.,
            296.,   356.,   528.,   420.,   800.,   346.,   764.,   550.,
           -228.,  3062.,   716.,  1658.,   738.,   376.,   548.,  1230.,
            506.,   -90.,  -276.],
         [  164.,   510.,   888.,   838.,   820.,   918.,    70.,   672.,
            534.,   844.,   650.,  1124.,   320.,   864., -1186.,   752.,
            518.,  -506.,   174.,  1412.,   220.,    36.,   -10.,   284.,
            296.,   356.,   528.,   420.,   800.,   346.,   764.,   550.,
           -228.,  3062.,   716.,  1658.,   738.,   376.,   548.,  1230.,
            506.,   -90.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2552., 2174., 2224., 2242., 2144., 2992., 2390., 2528., 2218.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0977 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.16s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 7.20000000e+01,  4.70000000e+02,  9.00000000e+02,  8.10000000e+02,
           8.32000000e+02,  8.10000000e+02,  1.50000000e+02,  7.68000000e+02,
           4.94000000e+02,  8.96000000e+02,  7.54000000e+02,  1.22400000e+03,
           4.20000000e+02,  7.40000000e+02, -1.11800000e+03,  8.28000000e+02,
           4.46000000e+02, -6.06000000e+02,  2.18000000e+02,  1.38800000e+03,
           2.12000000e+02,  7.60000000e+01,  2.00000000e+00,  3.52000000e+02,
           3.36000000e+02,  3.36000000e+02,  4.56000000e+02,  3.80000000e+02,
           8.00000000e+02,  2.46000000e+02,  8.08000000e+02,  6.26000000e+02,
          -2.12000000e+02,  3.24600000e+03,  7.32000000e+02,  1.50200000e+03,
           6.66000000e+02,  3.68000000e+02,  5.08000000e+02,  1.21800000e+03,
           6.66000000e+02, -1.90000000e+02, -2.28000000e+02],
         [ 7.20000000e+01,  4.70000000e+02,  9.00000000e+02,  8.10000000e+02,
           8.32000000e+02,  8.10000000e+02,  1.50000000e+02,  7.68000000e+02,
           4.94000000e+02,  8.96000000e+02,  7.54000000e+02,  1.22400000e+03,
           4.20000000e+02,  7.40000000e+02, -1.11800000e+03,  8.28000000e+02,
           4.46000000e+02, -6.06000000e+02,  2.18000000e+02,  1.38800000e+03,
           2.12000000e+02,  7.60000000e+01,  2.00000000e+00,  3.52000000e+02,
           3.36000000e+02,  3.36000000e+02,  4.56000000e+02,  3.80000000e+02,
           8.00000000e+02,  2.46000000e+02,  8.08000000e+02,  6.26000000e+02,
          -2.12000000e+02,  3.24600000e+03,  7.32000000e+02,  1.50200000e+03,
           6.66000000e+02,  3.68000000e+02,  5.08000000e+02,  1.21800000e+03,
           6.66000000e+02, -1.90000000e+02, -2.28000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3174., 2776., 2346., 2436., 2414., 2436., 3096., 2478., 2752., 2350.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1625 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   566.,   916.,   802.,   840.,   886.,   126.,   716.,
            522.,   896.,   614.,  1172.,   428.,   820., -1186.,   756.,
            522.,  -546.,    78.,  1392.,   280.,   116.,    14.,   280.,
            344.,   376.,   496.,   448.,   780.,   294.,   772.,   518.,
           -212.,  3054.,   700.,  1666.,   682.,   344.,   532.,  1214.,
            570.,   -94.,  -268.],
         [  156.,   566.,   916.,   802.,   840.,   886.,   126.,   716.,
            522.,   896.,   614.,  1172.,   428.,   820., -1186.,   756.,
            522.,  -546.,    78.,  1392.,   280.,   116.,    14.,   280.,
            344.,   376.,   496.,   448.,   780.,   294.,   772.,   518.,
           -212.,  3054.,   700.,  1666.,   682.,   344.,   532.,  1214.,
            570.,   -94.,  -268.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2488., 2138., 2252., 2214., 2168., 2928., 2338., 2532., 2158.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1152 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   72.,   466.,   920.,   798.,   792.,   858.,   118.,   740.,
            582.,   876.,   726.,  1176.,   364.,   756., -1130.,   756.,
            470.,  -634.,   178.,  1368.,   248.,   140.,     6.,   364.,
            344.,   380.,   516.,   448.,   752.,   278.,   796.,   562.,
           -152.,  3218.,   756.,  1518.,   634.,   396.,   516.,  1242.,
            614.,  -154.,  -236.],
         [   72.,   466.,   920.,   798.,   792.,   858.,   118.,   740.,
            582.,   876.,   726.,  1176.,   364.,   756., -1130.,   756.,
            470.,  -634.,   178.,  1368.,   248.,   140.,     6.,   364.,
            344.,   380.,   516.,   448.,   752.,   278.,   796.,   562.,
           -152.,  3218.,   756.,  1518.,   634.,   396.,   516.,  1242.,
            614.,  -154.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3146., 2752., 2298., 2420., 2426., 2360., 3100., 2478., 2636., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0581 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  164.,   506.,   892.,   818.,   784.,   894.,    70.,   720.,
            518.,   848.,   630.,  1144.,   356.,   884., -1126.,   816.,
            522.,  -542.,   126.,  1428.,   308.,    76.,   -58.,   280.,
            304.,   368.,   552.,   432.,   756.,   358.,   800.,   542.,
           -196.,  3042.,   704.,  1658.,   694.,   372.,   484.,  1262.,
            542.,   -78.,  -240.],
         [  164.,   506.,   892.,   818.,   784.,   894.,    70.,   720.,
            518.,   848.,   630.,  1144.,   356.,   884., -1126.,   816.,
            522.,  -542.,   126.,  1428.,   308.,    76.,   -58.,   280.,
            304.,   368.,   552.,   432.,   756.,   358.,   800.,   542.,
           -196.,  3042.,   704.,  1658.,   694.,   372.,   484.,  1262.,
            542.,   -78.,  -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2878., 2536., 2150., 2224., 2258., 2148., 2972., 2322., 2524., 2194.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9922 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   450.,   908.,   750.,   776.,   870.,   134.,   788.,
            526.,   892.,   694.,  1204.,   344.,   736., -1086.,   768.,
            510.,  -638.,   182.,  1396.,   308.,    88.,   -42.,   404.,
            304.,   328.,   500.,   468.,   740.,   298.,   812.,   622.,
           -208.,  3246.,   680.,  1502.,   658.,   372.,   504.,  1218.,
            598.,  -142.,  -216.],
         [   60.,   450.,   908.,   750.,   776.,   870.,   134.,   788.,
            526.,   892.,   694.,  1204.,   344.,   736., -1086.,   768.,
            510.,  -638.,   182.,  1396.,   308.,    88.,   -42.,   404.,
            304.,   328.,   500.,   468.,   740.,   298.,   812.,   622.,
           -208.,  3246.,   680.,  1502.,   658.,   372.,   504.,  1218.,
            598.,  -142.,  -216.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3186., 2796., 2338., 2496., 2470., 2376., 3112., 2458., 2720., 2354.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0347 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   476.,   918.,   792.,   802.,   896.,   120.,   778.,
            548.,   882.,   692.,  1254.,   410.,   790., -1200.,   814.,
            544.,  -620.,   116.,  1398.,   334.,    90.,   -20.,   378.,
            290.,   302.,   558.,   490.,   754.,   308.,   726.,   560.,
           -182.,  3048.,   702.,  1660.,   728.,   334.,   546.,  1220.,
            580.,   -36.,  -230.],
         [  102.,   476.,   918.,   792.,   802.,   896.,   120.,   778.,
            548.,   882.,   692.,  1254.,   410.,   790., -1200.,   814.,
            544.,  -620.,   116.,  1398.,   334.,    90.,   -20.,   378.,
            290.,   302.,   558.,   490.,   754.,   308.,   726.,   560.,
           -182.,  3048.,   702.,  1660.,   728.,   334.,   546.,  1220.,
            580.,   -36.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2946., 2572., 2130., 2256., 2246., 2152., 2928., 2270., 2500., 2166.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0715 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   62.,   484.,   898.,   728.,   806.,   824.,   100.,   726.,
            488.,   862.,   712.,  1254.,   410.,   714., -1184.,   810.,
            456.,  -600.,   184.,  1402.,   278.,   106.,   -36.,   350.,
            346.,   358.,   482.,   402.,   814.,   228.,   826.,   588.,
           -194.,  3228.,   726.,  1508.,   684.,   382.,   494.,  1184.,
            680.,  -172.,  -234.],
         [   62.,   484.,   898.,   728.,   806.,   824.,   100.,   726.,
            488.,   862.,   712.,  1254.,   410.,   714., -1184.,   810.,
            456.,  -600.,   184.,  1402.,   278.,   106.,   -36.,   350.,
            346.,   358.,   482.,   402.,   814.,   228.,   826.,   588.,
           -194.,  3228.,   726.,  1508.,   684.,   382.,   494.,  1184.,
            680.,  -172.,  -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2744., 2330., 2500., 2422., 2404., 3128., 2502., 2740., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9821 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   498.,   944.,   762.,   804.,   954.,   154.,   740.,
            550.,   872.,   738.,  1228.,   456.,   780., -1130.,   764.,
            514.,  -638.,   146.,  1336.,   304.,    92.,   -54.,   388.,
            248.,   324.,   572.,   468.,   760.,   338.,   788.,   562.,
           -172.,  3026.,   732.,  1610.,   650.,   332.,   544.,  1194.,
            558.,   -58.,  -196.],
         [   88.,   498.,   944.,   762.,   804.,   954.,   154.,   740.,
            550.,   872.,   738.,  1228.,   456.,   780., -1130.,   764.,
            514.,  -638.,   146.,  1336.,   304.,    92.,   -54.,   388.,
            248.,   324.,   572.,   468.,   760.,   338.,   788.,   562.,
           -172.,  3026.,   732.,  1610.,   650.,   332.,   544.,  1194.,
            558.,   -58.,  -196.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2938., 2528., 2082., 2264., 2222., 2072., 2872., 2286., 2476., 2154.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9992 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   96.,   478.,   884.,   770.,   872.,   818.,   102.,   700.,
            518.,   876.,   766.,  1160.,   396.,   708., -1114.,   788.,
            418.,  -614.,   194.,  1380.,   264.,   140.,   -34.,   376.,
            340.,   332.,   472.,   428.,   760.,   238.,   804.,   590.,
           -192.,  3238.,   752.,  1498.,   658.,   372.,   496.,  1182.,
            642.,  -146.,  -220.],
         [   96.,   478.,   884.,   770.,   872.,   818.,   102.,   700.,
            518.,   876.,   766.,  1160.,   396.,   708., -1114.,   788.,
            418.,  -614.,   194.,  1380.,   264.,   140.,   -34.,   376.,
            340.,   332.,   472.,   428.,   760.,   238.,   804.,   590.,
           -192.,  3238.,   752.,  1498.,   658.,   372.,   496.,  1182.,
            642.,  -146.,  -220.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2760., 2354., 2468., 2366., 2420., 3136., 2538., 2720., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9781 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   506.,   876.,   850.,   804.,   922.,    86.,   780.,
            586.,   884.,   706.,  1148.,   400.,   864., -1150.,   784.,
            518.,  -586.,   158.,  1312.,   292.,    60.,   -14.,   304.,
            264.,   348.,   528.,   472.,   760.,   406.,   824.,   598.,
           -200.,  3010.,   736.,  1618.,   610.,   336.,   540.,  1210.,
            498.,   -98.,  -264.],
         [   88.,   506.,   876.,   850.,   804.,   922.,    86.,   780.,
            586.,   884.,   706.,  1148.,   400.,   864., -1150.,   784.,
            518.,  -586.,   158.,  1312.,   292.,    60.,   -14.,   304.,
            264.,   348.,   528.,   472.,   760.,   406.,   824.,   598.,
           -200.,  3010.,   736.,  1618.,   610.,   336.,   540.,  1210.,
            498.,   -98.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2922., 2504., 2134., 2160., 2206., 2088., 2924., 2230., 2424., 2126.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9689 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   22.,   440.,   914.,   772.,   854.,   808.,   112.,   770.,
            576.,   850.,   732.,  1186.,   358.,   710., -1132.,   750.,
            424.,  -588.,   212.,  1414.,   274.,    86.,   -24.,   382.,
            330.,   326.,   494.,   438.,   814.,   336.,   818.,   644.,
           -182.,  3212.,   694.,  1500.,   676.,   378.,   482.,  1224.,
            608.,  -192.,  -230.],
         [   22.,   440.,   914.,   772.,   854.,   808.,   112.,   770.,
            576.,   850.,   732.,  1186.,   358.,   710., -1132.,   750.,
            424.,  -588.,   212.,  1414.,   274.,    86.,   -24.,   382.,
            330.,   326.,   494.,   438.,   814.,   336.,   818.,   644.,
           -182.,  3212.,   694.,  1500.,   676.,   378.,   482.,  1224.,
            608.,  -192.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3190., 2772., 2298., 2440., 2358., 2404., 3100., 2442., 2636., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0364 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   92.,   502.,   876.,   770.,   792.,   926.,   106.,   764.,
            574.,   880.,   706.,  1180.,   460.,   772., -1154.,   776.,
            586.,  -574.,   154.,  1380.,   364.,    92.,    -6.,   356.,
            276.,   316.,   548.,   520.,   756.,   346.,   776.,   586.,
           -188.,  3014.,   732.,  1626.,   710.,   352.,   536.,  1250.,
            506.,   -26.,  -248.],
         [   92.,   502.,   876.,   770.,   792.,   926.,   106.,   764.,
            574.,   880.,   706.,  1180.,   460.,   772., -1154.,   776.,
            586.,  -574.,   154.,  1380.,   364.,    92.,    -6.,   356.,
            276.,   316.,   548.,   520.,   756.,   346.,   776.,   586.,
           -188.,  3014.,   732.,  1626.,   710.,   352.,   536.,  1250.,
            506.,   -26.,  -248.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2922., 2512., 2138., 2244., 2222., 2088., 2908., 2250., 2440., 2134.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0545 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   462.,   944.,   750.,   828.,   866.,   162.,   792.,
            522.,   892.,   722.,  1200.,   408.,   692., -1130.,   784.,
            438.,  -570.,   146.,  1376.,   260.,   128.,   -14.,   356.,
            312.,   336.,   528.,   392.,   792.,   302.,   836.,   582.,
           -240.,  3254.,   672.,  1518.,   674.,   328.,   484.,  1186.,
            606.,  -138.,  -248.],
         [   88.,   462.,   944.,   750.,   828.,   866.,   162.,   792.,
            522.,   892.,   722.,  1200.,   408.,   692., -1130.,   784.,
            438.,  -570.,   146.,  1376.,   260.,   128.,   -14.,   356.,
            312.,   336.,   528.,   392.,   792.,   302.,   836.,   582.,
           -240.,  3254.,   672.,  1518.,   674.,   328.,   484.,  1186.,
            606.,  -138.,  -248.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2792., 2310., 2504., 2426., 2388., 3092., 2462., 2732., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9769 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  128.,   498.,   872.,   790.,   804.,   918.,    94.,   712.,
            558.,   864.,   694.,  1136.,   352.,   840., -1158.,   752.,
            542.,  -530.,   182.,  1396.,   308.,    80.,   -26.,   276.,
            352.,   388.,   536.,   420.,   784.,   338.,   792.,   534.,
           -180.,  3058.,   700.,  1654.,   690.,   376.,   508.,  1258.,
            538.,   -58.,  -228.],
         [  128.,   498.,   872.,   790.,   804.,   918.,    94.,   712.,
            558.,   864.,   694.,  1136.,   352.,   840., -1158.,   752.,
            542.,  -530.,   182.,  1396.,   308.,    80.,   -26.,   276.,
            352.,   388.,   536.,   420.,   784.,   338.,   792.,   534.,
           -180.,  3058.,   700.,  1654.,   690.,   376.,   508.,  1258.,
            538.,   -58.,  -228.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2930., 2560., 2186., 2268., 2254., 2140., 2964., 2346., 2500., 2194.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.7131 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.48s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   436.,   874.,   776.,   830.,   844.,   148.,   746.,
            516.,   878.,   720.,  1230.,   430.,   626., -1112.,   790.,
            532.,  -624.,   160.,  1398.,   290.,   146.,   -44.,   346.,
            326.,   350.,   466.,   430.,   766.,   252.,   786.,   596.,
           -254.,  3244.,   746.,  1532.,   608.,   370.,   466.,  1212.,
            640.,  -100.,  -242.],
         [   74.,   436.,   874.,   776.,   830.,   844.,   148.,   746.,
            516.,   878.,   720.,  1230.,   430.,   626., -1112.,   790.,
            532.,  -624.,   160.,  1398.,   290.,   146.,   -44.,   346.,
            326.,   350.,   466.,   430.,   766.,   252.,   786.,   596.,
           -254.,  3244.,   746.,  1532.,   608.,   370.,   466.,  1212.,
            640.,  -100.,  -242.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3170., 2808., 2370., 2468., 2414., 2400., 3096., 2498., 2728., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.4891 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  128.,   502.,   900.,   814.,   828.,   866.,    70.,   748.,
            506.,   848.,   666.,  1104.,   320.,   868., -1138.,   784.,
            558.,  -558.,   142.,  1404.,   320.,   108.,    14.,   336.,
            304.,   396.,   516.,   520.,   752.,   362.,   744.,   554.,
           -220.,  3054.,   680.,  1670.,   690.,   368.,   508.,  1238.,
            498.,   -42.,  -236.],
         [  128.,   502.,   900.,   814.,   828.,   866.,    70.,   748.,
            506.,   848.,   666.,  1104.,   320.,   868., -1138.,   784.,
            558.,  -558.,   142.,  1404.,   320.,   108.,    14.,   336.,
            304.,   396.,   516.,   520.,   752.,   362.,   744.,   554.,
           -220.,  3054.,   680.,  1670.,   690.,   368.,   508.,  1238.,
            498.,   -42.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2552., 2154., 2240., 2226., 2188., 2984., 2306., 2548., 2206.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0741 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   482.,   848.,   790.,   828.,   846.,   134.,   740.,
            506.,   836.,   702.,  1184.,   400.,   740., -1058.,   848.,
            462.,  -614.,   250.,  1396.,   212.,   124.,   -18.,   356.,
            296.,   376.,   504.,   344.,   788.,   262.,   824.,   574.,
           -168.,  3222.,   724.,  1506.,   646.,   364.,   500.,  1262.,
            638.,  -146.,  -256.],
         [   60.,   482.,   848.,   790.,   828.,   846.,   134.,   740.,
            506.,   836.,   702.,  1184.,   400.,   740., -1058.,   848.,
            462.,  -614.,   250.,  1396.,   212.,   124.,   -18.,   356.,
            296.,   376.,   504.,   344.,   788.,   262.,   824.,   574.,
           -168.,  3222.,   724.,  1506.,   646.,   364.,   500.,  1262.,
            638.,  -146.,  -256.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3162., 2740., 2374., 2432., 2394., 2376., 3088., 2482., 2716., 2386.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0580 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.31s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  140.,   478.,   900.,   810.,   796.,   930.,   150.,   724.,
            558.,   876.,   642.,  1132.,   344.,   792., -1138.,   744.,
            562.,  -558.,   142.,  1400.,   304.,    88.,    42.,   284.,
            324.,   356.,   560.,   408.,   768.,   334.,   760.,   566.,
           -204.,  3066.,   640.,  1658.,   734.,   316.,   528.,  1174.,
            542.,   -70.,  -320.],
         [  140.,   478.,   900.,   810.,   796.,   930.,   150.,   724.,
            558.,   876.,   642.,  1132.,   344.,   792., -1138.,   744.,
            562.,  -558.,   142.,  1400.,   304.,    88.,    42.,   284.,
            324.,   356.,   560.,   408.,   768.,   334.,   760.,   566.,
           -204.,  3066.,   640.,  1658.,   734.,   316.,   528.,  1174.,
            542.,   -70.,  -320.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2588., 2166., 2256., 2270., 2136., 2916., 2342., 2508., 2190.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3235 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.48s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   454.,   916.,   798.,   800.,   838.,   146.,   760.,
            494.,   844.,   682.,  1196.,   400.,   724., -1158.,   772.,
            430.,  -574.,   166.,  1424.,   228.,    80.,    -6.,   364.,
            328.,   328.,   476.,   432.,   816.,   306.,   828.,   606.,
           -228.,  3242.,   708.,  1522.,   690.,   376.,   504.,  1194.,
            666.,  -166.,  -200.],
         [   60.,   454.,   916.,   798.,   800.,   838.,   146.,   760.,
            494.,   844.,   682.,  1196.,   400.,   724., -1158.,   772.,
            430.,  -574.,   166.,  1424.,   228.,    80.,    -6.,   364.,
            328.,   328.,   476.,   432.,   816.,   306.,   828.,   606.,
           -228.,  3242.,   708.,  1522.,   690.,   376.,   504.,  1194.,
            666.,  -166.,  -200.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3182., 2788., 2326., 2444., 2442., 2404., 3096., 2482., 2748., 2398.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.4912 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.04s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.40000000e+02,  4.70000000e+02,  8.88000000e+02,  7.86000000e+02,
           8.08000000e+02,  9.42000000e+02,  1.42000000e+02,  6.68000000e+02,
           5.62000000e+02,  8.44000000e+02,  6.42000000e+02,  1.16400000e+03,
           3.00000000e+02,  8.60000000e+02, -1.09800000e+03,  7.72000000e+02,
           5.34000000e+02, -5.50000000e+02,  1.54000000e+02,  1.37200000e+03,
           2.24000000e+02,  5.20000000e+01,  2.00000000e+00,  3.16000000e+02,
           3.44000000e+02,  3.56000000e+02,  5.48000000e+02,  4.20000000e+02,
           7.28000000e+02,  3.14000000e+02,  8.20000000e+02,  5.54000000e+02,
          -2.24000000e+02,  3.04200000e+03,  6.28000000e+02,  1.66600000e+03,
           7.18000000e+02,  3.40000000e+02,  4.84000000e+02,  1.21400000e+03,
           5.42000000e+02, -1.40000000e+01, -2.68000000e+02],
         [ 1.40000000e+02,  4.70000000e+02,  8.88000000e+02,  7.86000000e+02,
           8.08000000e+02,  9.42000000e+02,  1.42000000e+02,  6.68000000e+02,
           5.62000000e+02,  8.44000000e+02,  6.42000000e+02,  1.16400000e+03,
           3.00000000e+02,  8.60000000e+02, -1.09800000e+03,  7.72000000e+02,
           5.34000000e+02, -5.50000000e+02,  1.54000000e+02,  1.37200000e+03,
           2.24000000e+02,  5.20000000e+01,  2.00000000e+00,  3.16000000e+02,
           3.44000000e+02,  3.56000000e+02,  5.48000000e+02,  4.20000000e+02,
           7.28000000e+02,  3.14000000e+02,  8.20000000e+02,  5.54000000e+02,
          -2.24000000e+02,  3.04200000e+03,  6.28000000e+02,  1.66600000e+03,
           7.18000000e+02,  3.40000000e+02,  4.84000000e+02,  1.21400000e+03,
           5.42000000e+02, -1.40000000e+01, -2.68000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2902., 2572., 2154., 2256., 2234., 2100., 2900., 2374., 2480., 2198.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0512 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   68.,   486.,   888.,   794.,   824.,   822.,   102.,   740.,
            486.,   888.,   698.,  1228.,   388.,   708., -1170.,   836.,
            422.,  -570.,   182.,  1396.,   256.,    64.,    -6.,   352.,
            328.,   316.,   472.,   392.,   788.,   262.,   828.,   578.,
           -216.,  3198.,   736.,  1502.,   710.,   368.,   508.,  1178.,
            642.,  -170.,  -228.],
         [   68.,   486.,   888.,   794.,   824.,   822.,   102.,   740.,
            486.,   888.,   698.,  1228.,   388.,   708., -1170.,   836.,
            422.,  -570.,   182.,  1396.,   256.,    64.,    -6.,   352.,
            328.,   316.,   472.,   392.,   788.,   262.,   828.,   578.,
           -216.,  3198.,   736.,  1502.,   710.,   368.,   508.,  1178.,
            642.,  -170.,  -228.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3130., 2712., 2310., 2404., 2374., 2376., 3096., 2458., 2712., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9692 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.16000000e+02,  4.78000000e+02,  9.24000000e+02,  7.90000000e+02,
           8.36000000e+02,  9.18000000e+02,  8.20000000e+01,  7.84000000e+02,
           5.78000000e+02,  8.92000000e+02,  6.70000000e+02,  1.18800000e+03,
           3.84000000e+02,  8.28000000e+02, -1.14600000e+03,  7.80000000e+02,
           5.54000000e+02, -5.70000000e+02,  1.62000000e+02,  1.31600000e+03,
           2.76000000e+02,  6.00000000e+01,  2.00000000e+00,  3.28000000e+02,
           2.80000000e+02,  3.28000000e+02,  6.00000000e+02,  4.04000000e+02,
           8.04000000e+02,  3.46000000e+02,  8.44000000e+02,  5.66000000e+02,
          -2.28000000e+02,  3.00200000e+03,  6.72000000e+02,  1.65400000e+03,
           6.50000000e+02,  3.36000000e+02,  5.24000000e+02,  1.21400000e+03,
           5.42000000e+02, -2.00000000e+00, -2.12000000e+02],
         [ 1.16000000e+02,  4.78000000e+02,  9.24000000e+02,  7.90000000e+02,
           8.36000000e+02,  9.18000000e+02,  8.20000000e+01,  7.84000000e+02,
           5.78000000e+02,  8.92000000e+02,  6.70000000e+02,  1.18800000e+03,
           3.84000000e+02,  8.28000000e+02, -1.14600000e+03,  7.80000000e+02,
           5.54000000e+02, -5.70000000e+02,  1.62000000e+02,  1.31600000e+03,
           2.76000000e+02,  6.00000000e+01,  2.00000000e+00,  3.28000000e+02,
           2.80000000e+02,  3.28000000e+02,  6.00000000e+02,  4.04000000e+02,
           8.04000000e+02,  3.46000000e+02,  8.44000000e+02,  5.66000000e+02,
          -2.28000000e+02,  3.00200000e+03,  6.72000000e+02,  1.65400000e+03,
           6.50000000e+02,  3.36000000e+02,  5.24000000e+02,  1.21400000e+03,
           5.42000000e+02, -2.00000000e+00, -2.12000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2886., 2524., 2078., 2212., 2166., 2084., 2920., 2218., 2424., 2110.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0737 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.12s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   96.,   430.,   948.,   794.,   804.,   854.,   102.,   744.,
            530.,   888.,   706.,  1224.,   336.,   696., -1158.,   772.,
            494.,  -634.,   170.,  1424.,   308.,   120.,   -30.,   384.,
            344.,   308.,   508.,   404.,   764.,   258.,   796.,   598.,
           -248.,  3226.,   704.,  1498.,   678.,   376.,   488.,  1198.,
            630.,  -178.,  -256.],
         [   96.,   430.,   948.,   794.,   804.,   854.,   102.,   744.,
            530.,   888.,   706.,  1224.,   336.,   696., -1158.,   772.,
            494.,  -634.,   170.,  1424.,   308.,   120.,   -30.,   384.,
            344.,   308.,   508.,   404.,   764.,   258.,   796.,   598.,
           -248.,  3226.,   704.,  1498.,   678.,   376.,   488.,  1198.,
            630.,  -178.,  -256.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3130., 2796., 2278., 2432., 2422., 2372., 3124., 2482., 2696., 2338.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1302 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.33s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  124.,   506.,   852.,   826.,   792.,   894.,   114.,   696.,
            582.,   936.,   674.,  1200.,   440.,   832., -1130.,   788.,
            514.,  -610.,   174.,  1344.,   280.,    28.,   -22.,   336.,
            244.,   320.,   544.,   448.,   812.,   390.,   772.,   558.,
           -176.,  3050.,   760.,  1650.,   710.,   380.,   568.,  1202.,
            530.,    -6.,  -264.],
         [  124.,   506.,   852.,   826.,   792.,   894.,   114.,   696.,
            582.,   936.,   674.,  1200.,   440.,   832., -1130.,   788.,
            514.,  -610.,   174.,  1344.,   280.,    28.,   -22.,   336.,
            244.,   320.,   544.,   448.,   812.,   390.,   772.,   558.,
           -176.,  3050.,   760.,  1650.,   710.,   380.,   568.,  1202.,
            530.,    -6.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2544., 2198., 2224., 2258., 2156., 2936., 2354., 2468., 2114.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3389 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.16s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   70.,   444.,   926.,   784.,   850.,   820.,   144.,   746.,
            524.,   854.,   728.,  1178.,   330.,   714., -1128.,   826.,
            440.,  -596.,   224.,  1350.,   262.,    94.,   -24.,   374.,
            354.,   374.,   474.,   394.,   774.,   280.,   766.,   580.,
           -206.,  3228.,   730.,  1500.,   716.,   394.,   518.,  1240.,
            628.,  -140.,  -250.],
         [   70.,   444.,   926.,   784.,   850.,   820.,   144.,   746.,
            524.,   854.,   728.,  1178.,   330.,   714., -1128.,   826.,
            440.,  -596.,   224.,  1350.,   262.,    94.,   -24.,   374.,
            354.,   374.,   474.,   394.,   774.,   280.,   766.,   580.,
           -206.,  3228.,   730.,  1500.,   716.,   394.,   518.,  1240.,
            628.,  -140.,  -250.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3158., 2784., 2302., 2444., 2378., 2408., 3084., 2482., 2704., 2374.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1706 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.56s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   454.,   892.,   854.,   816.,   934.,   134.,   700.,
            558.,   844.,   630.,  1192.,   344.,   828., -1138.,   740.,
            522.,  -566.,   134.,  1412.,   236.,    64.,    50.,   344.,
            304.,   364.,   568.,   436.,   780.,   334.,   772.,   570.,
           -224.,  3054.,   632.,  1650.,   718.,   348.,   536.,  1234.,
            578.,   -78.,  -276.],
         [  156.,   454.,   892.,   854.,   816.,   934.,   134.,   700.,
            558.,   844.,   630.,  1192.,   344.,   828., -1138.,   740.,
            522.,  -566.,   134.,  1412.,   236.,    64.,    50.,   344.,
            304.,   364.,   568.,   436.,   780.,   334.,   772.,   570.,
           -224.,  3054.,   632.,  1650.,   718.,   348.,   536.,  1234.,
            578.,   -78.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2600., 2162., 2200., 2238., 2120., 2920., 2354., 2496., 2210.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.5639 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   480.,   882.,   760.,   762.,   864.,   132.,   774.,
            504.,   890.,   700.,  1226.,   430.,   678., -1124.,   742.,
            508.,  -608.,   136.,  1362.,   234.,    82.,   -72.,   286.,
            326.,   326.,   458.,   442.,   778.,   288.,   846.,   580.,
           -198.,  3256.,   694.,  1524.,   676.,   362.,   482.,  1156.,
            628.,  -144.,  -194.],
         [  102.,   480.,   882.,   760.,   762.,   864.,   132.,   774.,
            504.,   890.,   700.,  1226.,   430.,   678., -1124.,   742.,
            508.,  -608.,   136.,  1362.,   234.,    82.,   -72.,   286.,
            326.,   326.,   458.,   442.,   778.,   288.,   846.,   580.,
           -198.,  3256.,   694.,  1524.,   676.,   362.,   482.,  1156.,
            628.,  -144.,  -194.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3154., 2776., 2374., 2496., 2494., 2392., 3124., 2482., 2752., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.6392 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  154.,   516.,   886.,   796.,   806.,   908.,    64.,   726.,
            552.,   886.,   624.,  1198.,   406.,   862., -1156.,   786.,
            504.,  -540.,   156.,  1362.,   254.,    42.,   -68.,   322.,
            286.,   330.,   570.,   426.,   802.,   356.,   806.,   544.,
           -230.,  3044.,   754.,  1648.,   652.,   398.,   498.,  1220.,
            540.,   -32.,  -266.],
         [  154.,   516.,   886.,   796.,   806.,   908.,    64.,   726.,
            552.,   886.,   624.,  1198.,   406.,   862., -1156.,   786.,
            504.,  -540.,   156.,  1362.,   254.,    42.,   -68.,   322.,
            286.,   330.,   570.,   426.,   802.,   356.,   806.,   544.,
           -230.,  3044.,   754.,  1648.,   652.,   398.,   498.,  1220.,
            540.,   -32.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2890., 2528., 2158., 2248., 2238., 2136., 2980., 2318., 2492., 2158.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0825 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.66s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   46.,   424.,   910.,   788.,   866.,   820.,   152.,   730.,
            500.,   878.,   744.,  1190.,   362.,   726., -1140.,   754.,
            424.,  -620.,   216.,  1382.,   262.,    82.,   -44.,   342.,
            298.,   330.,   466.,   438.,   834.,   300.,   790.,   620.,
           -174.,  3208.,   714.,  1472.,   660.,   402.,   530.,  1224.,
            592.,  -192.,  -190.],
         [   46.,   424.,   910.,   788.,   866.,   820.,   152.,   730.,
            500.,   878.,   744.,  1190.,   362.,   726., -1140.,   754.,
            424.,  -620.,   216.,  1382.,   262.,    82.,   -44.,   342.,
            298.,   330.,   466.,   438.,   834.,   300.,   790.,   620.,
           -174.,  3208.,   714.,  1472.,   660.,   402.,   530.,  1224.,
            592.,  -192.,  -190.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3162., 2784., 2298., 2420., 2342., 2388., 3056., 2478., 2708., 2330.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.6655 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.04s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   490.,   876.,   794.,   824.,   866.,    98.,   676.,
            578.,   948.,   666.,  1176.,   428.,   876., -1110.,   808.,
            558.,  -534.,   202.,  1340.,   328.,    52.,   -14.,   308.,
            244.,   320.,   584.,   452.,   792.,   414.,   812.,   550.,
           -176.,  3002.,   764.,  1618.,   658.,   364.,   536.,  1210.,
            514.,   -38.,  -244.],
         [  156.,   490.,   876.,   794.,   824.,   866.,    98.,   676.,
            578.,   948.,   666.,  1176.,   428.,   876., -1110.,   808.,
            558.,  -534.,   202.,  1340.,   328.,    52.,   -14.,   308.,
            244.,   320.,   584.,   452.,   792.,   414.,   812.,   550.,
           -176.,  3002.,   764.,  1618.,   658.,   364.,   536.,  1210.,
            514.,   -38.,  -244.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2846., 2512., 2126., 2208., 2178., 2136., 2904., 2326., 2424., 2054.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0471 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.04s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   64.,   450.,   860.,   766.,   820.,   814.,   170.,   756.,
            538.,   868.,   682.,  1208.,   400.,   708., -1062.,   784.,
            478.,  -602.,   202.,  1348.,   260.,   108.,   -30.,   360.,
            316.,   376.,   480.,   444.,   768.,   286.,   824.,   578.,
           -196.,  3262.,   724.,  1534.,   630.,   344.,   480.,  1246.,
            642.,  -130.,  -172.],
         [   64.,   450.,   860.,   766.,   820.,   814.,   170.,   756.,
            538.,   868.,   682.,  1208.,   400.,   708., -1062.,   784.,
            478.,  -602.,   202.,  1348.,   260.,   108.,   -30.,   360.,
            316.,   376.,   480.,   444.,   768.,   286.,   824.,   578.,
           -196.,  3262.,   724.,  1534.,   630.,   344.,   480.,  1246.,
            642.,  -130.,  -172.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3198., 2812., 2402., 2496., 2442., 2448., 3092., 2506., 2724., 2394.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0482 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  124.,   522.,   832.,   806.,   812.,   878.,    98.,   684.,
            538.,   872.,   630.,  1180.,   408.,   796., -1162.,   752.,
            518.,  -534.,   166.,  1400.,   252.,    68.,    34.,   304.,
            300.,   340.,   564.,   448.,   792.,   362.,   800.,   522.,
           -216.,  3070.,   776.,  1670.,   702.,   428.,   544.,  1218.,
            574.,   -38.,  -264.],
         [  124.,   522.,   832.,   806.,   812.,   878.,    98.,   684.,
            538.,   872.,   630.,  1180.,   408.,   796., -1162.,   752.,
            518.,  -534.,   166.,  1400.,   252.,    68.,    34.,   304.,
            300.,   340.,   564.,   448.,   792.,   362.,   800.,   522.,
           -216.,  3070.,   776.,  1670.,   702.,   428.,   544.,  1218.,
            574.,   -38.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2946., 2548., 2238., 2264., 2258., 2192., 2972., 2386., 2532., 2198.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9727 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.04s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   492.,   862.,   772.,   774.,   852.,   172.,   742.,
            508.,   886.,   708.,  1210.,   422.,   686., -1116.,   746.,
            436.,  -612.,   176.,  1354.,   194.,    70.,    24.,   378.,
            314.,   282.,   470.,   414.,   758.,   288.,   822.,   568.,
           -170.,  3216.,   774.,  1508.,   676.,   398.,   498.,  1176.,
            668.,  -120.,  -218.],
         [   74.,   492.,   862.,   772.,   774.,   852.,   172.,   742.,
            508.,   886.,   708.,  1210.,   422.,   686., -1116.,   746.,
            436.,  -612.,   176.,  1354.,   194.,    70.,    24.,   378.,
            314.,   282.,   470.,   414.,   758.,   288.,   822.,   568.,
           -170.,  3216.,   774.,  1508.,   676.,   398.,   498.,  1176.,
            668.,  -120.,  -218.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2724., 2354., 2444., 2442., 2364., 3044., 2474., 2708., 2330.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0495 seconds.
PGD attack failed
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/2): BoundBuffers(name=/2, inputs=[], perturbed=False)
  (/shape): BoundBuffers(name=/shape, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True)
  (/13): BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True)
  (/17): BoundSplit(name=/17, inputs=[/shape], perturbed=False)
  (/18): BoundSplit(name=/18, inputs=[/shape], perturbed=False)
  (/19): BoundSqueeze(name=/19, inputs=[/17], perturbed=False)
  (/20): BoundSqueeze(name=/20, inputs=[/18], perturbed=False)
  (/21): BoundUnsqueeze(name=/21, inputs=[/19], perturbed=False)
  (/22): BoundUnsqueeze(name=/22, inputs=[/20], perturbed=False)
  (/23): BoundConcat(name=/23, inputs=[/21, /22], perturbed=False)
  (/24): BoundReshape(name=/24, inputs=[/14/merge, /23], perturbed=True)
  (/25): BoundTranspose(name=/25, inputs=[/8], perturbed=False)
  (/26): BoundMatMul(name=/26, inputs=[/24, /25], perturbed=True)
  (/10/merge): BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
  (/14/merge): BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
)
Original output: tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
Split layers:
  BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True): [(BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True), 0)]
  BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True): [(BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True), 0)]
Nonlinear functions:
   BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
   BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
layer /10/merge using sparse-features alpha with shape [387]; unstable size 387; total size 12544 ([1, 16, 28, 28])
layer /10/merge start_node /13 using full alpha [4, 32, 1, 387] with unstable size 29 total_size 32 output_shape 32
layer /10/merge start_node /26 using full alpha [4, 42, 1, 387] with unstable size None total_size 42 output_shape 42
layer /14/merge using sparse-features alpha with shape [3657]; unstable size 3657; total size 23328 ([1, 32, 27, 27])
layer /14/merge start_node /26 using full alpha [4, 42, 1, 3657] with unstable size None total_size 42 output_shape 42
Optimizable variables initialized.
initial CROWN bounds: tensor([[ -526., -1004., -1490., -1420., -1310., -1460.,  -752., -1262., -1092.,
         -1402., -1060., -1642.,  -962., -1318.,   236., -1458., -1044.,  -212.,
          -776., -1894.,  -934.,  -534.,  -504., -1086.,  -578.,  -910., -1030.,
         -1086., -1362., -1032., -1122., -1160.,  -422., -1074., -2100., -1252.,
          -990.,  -894., -2112., -1060.,  -404.,  -226.]], device='cuda:0') None
best_l after optimization: -40658.62890625
alpha/beta optimization time: 1.5754337310791016
initial alpha-crown bounds: tensor([[ -526.00000000, -1004.00000000, -1173.97937012, -1420.00000000,
         -1310.00000000, -1176.97863770,  -752.00000000, -1262.00000000,
         -1092.00000000, -1402.00000000, -1060.00000000, -1288.70483398,
          -962.00000000, -1318.00000000,   236.00000000, -1111.07861328,
         -1044.00000000,  -212.00000000,  -776.00000000, -1408.34448242,
          -934.00000000,  -534.00000000,  -504.00000000, -1086.00000000,
          -578.00000000,  -910.00000000, -1030.00000000, -1086.00000000,
         -1362.00000000, -1032.00000000, -1122.00000000, -1160.00000000,
          -422.00000000, -1074.00000000, -1470.84973145, -1252.00000000,
          -990.00000000,  -894.00000000, -1464.69177246, -1060.00000000,
          -404.00000000,  -226.00000000]], device='cuda:0')
Worst class: (+ rhs) -1470.8497314453125
Total VNNLIB file length: 42, max property batch size: 1, total number of batches: 42
lA shape: [torch.Size([42, 1, 16, 28, 28]), torch.Size([42, 1, 32, 27, 27])]

Properties batch 0, size 1
Remaining timeout: 830.3347692489624
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-526.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
setting alpha for layer /10/merge start_node /26 with alignment adjustment
setting alpha for layer /14/merge start_node /26 with alignment adjustment
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-526.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 14257] 
split level 1: [/13, 15065] 
split level 2: [/13, 20199] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 9.250640869140625e-05
Time: prepare 0.0004    bound 0.2181    transfer 0.0002    finalize 0.0006    func 0.2194    
Accumulated time: func 0.2194    prepare 0.0008    bound 0.2181    transfer 0.0002    finalize 0.0006    
Current worst splitting domains lb-rhs (depth):
-264.54343 (3), -264.54004 (3), -264.53769 (3), -264.53427 (3), -264.27521 (3), -264.26938 (3), -264.20071 (3), -264.19492 (3), 
length of domains: 8
Time: pickout 0.0003    decision 0.0211    set_bounds 0.0012    solve 0.2194    add 0.0104    
Accumulated time: pickout 0.0003    decision 0.0211    set_bounds 0.0012    solve 0.2194    add 0.0104    
Current (lb-rhs): -264.5434265136719
8 domains visited
Cumulative time: 0.3756833076477051

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 8.082389831542969e-05
Time: prepare 0.0017    bound 0.0841    transfer 0.0004    finalize 0.0012    func 0.0874    
Accumulated time: func 0.3068    prepare 0.0029    bound 0.3022    transfer 0.0006    finalize 0.0018    
Current worst splitting domains lb-rhs (depth):
-60.65464 (4), -60.62450 (4), -60.41720 (4), -60.39231 (4), -60.38712 (4), -60.36217 (4), -60.08931 (4), -60.05917 (4), -59.86079 (4), -59.85201 (4), -59.83067 (4), -59.82704 (4), -59.82189 (4), -59.79703 (4), -59.29559 (4), -59.26548 (4), 
length of domains: 16
Time: pickout 0.0004    decision 0.0288    set_bounds 0.0019    solve 0.0875    add 0.0019    
Accumulated time: pickout 0.0008    decision 0.0499    set_bounds 0.0031    solve 0.3069    add 0.0123    
Current (lb-rhs): -60.654640197753906
24 domains visited
Cumulative time: 0.49633121490478516

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/9, 7858] [/9, 9817] [/9, 4644] [/9, 7858] [/13, 121] [/9, 7858] [/9, 8513] [/9, 9967] [/9, 7858] [/9, 7858] 

all verified at 12th iter
pruning_in_iteration open status: True
ratio of positive domain = 32 / 32 = 1.0
pruning-in-iteration extra time: 0.00024962425231933594
Time: prepare 0.0023    bound 0.0518    transfer 0.0006    finalize 0.0018    func 0.0566    
Accumulated time: func 0.3634    prepare 0.0056    bound 0.3540    transfer 0.0013    finalize 0.0036    
length of domains: 0
Time: pickout 0.0004    decision 0.0302    set_bounds 0.0024    solve 0.0566    add 0.0001    
Accumulated time: pickout 0.0012    decision 0.0801    set_bounds 0.0055    solve 0.3635    add 0.0123    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
24 domains visited
Cumulative time: 0.5862107276916504


Properties batch 1, size 1
Remaining timeout: 829.6559948921204
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-1004.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
setting alpha for layer /10/merge start_node /26 with alignment adjustment
setting alpha for layer /14/merge start_node /26 with alignment adjustment
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-1004.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 4133] 
split level 1: [/13, 11420] 
split level 2: [/13, 20199] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0004    bound 0.0799    transfer 0.0002    finalize 0.0005    func 0.0810    
Accumulated time: func 0.0810    prepare 0.0007    bound 0.0799    transfer 0.0002    finalize 0.0005    
Current worst splitting domains lb-rhs (depth):
-689.59540 (3), -689.46790 (3), -689.44458 (3), -689.43378 (3), -688.79279 (3), -688.66516 (3), -688.64191 (3), -688.63110 (3), 
length of domains: 8
Time: pickout 0.0002    decision 0.0166    set_bounds 0.0012    solve 0.0811    add 0.0009    
Accumulated time: pickout 0.0002    decision 0.0166    set_bounds 0.0012    solve 0.0811    add 0.0009    
Current (lb-rhs): -689.5953979492188
8 domains visited
Cumulative time: 0.10364770889282227

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 7951] [/9, 7951] [/9, 7983] [/9, 7951] [/9, 7951] [/9, 7983] [/9, 7951] [/9, 7951] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 6.771087646484375e-05
Time: prepare 0.0012    bound 0.0791    transfer 0.0003    finalize 0.0010    func 0.0816    
Accumulated time: func 0.1627    prepare 0.0022    bound 0.1591    transfer 0.0005    finalize 0.0015    
Current worst splitting domains lb-rhs (depth):
-449.88385 (4), -449.81845 (4), -449.79770 (4), -449.72296 (4), -449.62637 (4), -449.54031 (4), -449.53333 (4), -449.44724 (4), -448.60110 (4), -448.53571 (4), -448.51495 (4), -448.44958 (4), -448.34363 (4), -448.25049 (4), -448.24814 (4), -448.16449 (4), 
length of domains: 16
Time: pickout 0.0003    decision 0.0193    set_bounds 0.0014    solve 0.0817    add 0.0016    
Accumulated time: pickout 0.0005    decision 0.0359    set_bounds 0.0026    solve 0.1627    add 0.0026    
Current (lb-rhs): -449.88385009765625
24 domains visited
Cumulative time: 0.20804834365844727

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 4225] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 9967] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 5.53131103515625e-05
Time: prepare 0.0022    bound 0.0802    transfer 0.0005    finalize 0.0018    func 0.0848    
Accumulated time: func 0.2475    prepare 0.0047    bound 0.2393    transfer 0.0011    finalize 0.0032    
Current worst splitting domains lb-rhs (depth):
-342.24847 (5), -342.15085 (5), -342.14966 (5), -342.14084 (5), -342.10870 (5), -342.06223 (5), -342.05191 (5), -342.04132 (5), -342.00977 (5), -341.96460 (5), -341.96329 (5), -341.90048 (5), -341.84903 (5), -341.80280 (5), -341.80148 (5), -341.70386 (5), -340.85245 (5), -340.75482 (5), -340.75351 (5), -340.75262 (5), 
length of domains: 32
Time: pickout 0.0004    decision 0.0301    set_bounds 0.0024    solve 0.0848    add 0.0032    
Accumulated time: pickout 0.0009    decision 0.0660    set_bounds 0.0050    solve 0.2476    add 0.0058    
Current (lb-rhs): -342.24847412109375
56 domains visited
Cumulative time: 0.3290538787841797

BaB round 4
batch: 32
Average branched neurons at iteration 4:  1.0000
splitting decisions: 
split level 0: [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 7951] [/9, 7983] [/9, 10474] [/9, 10474] [/9, 3953] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 5.626678466796875e-05
Time: prepare 0.0044    bound 0.1134    transfer 0.0010    finalize 0.0054    func 0.1242    
Accumulated time: func 0.3717    prepare 0.0094    bound 0.3527    transfer 0.0021    finalize 0.0086    
Current worst splitting domains lb-rhs (depth):
-292.78281 (6), -292.77908 (6), -292.77081 (6), -292.76703 (6), -292.72467 (6), -292.72095 (6), -292.67847 (6), -292.67480 (6), -292.67303 (6), -292.67081 (6), -292.66702 (6), -292.66104 (6), -292.65729 (6), -292.65726 (6), -292.64490 (6), -292.64346 (6), -292.64188 (6), -292.64124 (6), -292.63983 (6), -292.56876 (6), 
length of domains: 64
Time: pickout 0.0006    decision 0.0508    set_bounds 0.0042    solve 0.1243    add 0.0075    
Accumulated time: pickout 0.0015    decision 0.1168    set_bounds 0.0092    solve 0.3718    add 0.0133    
Current (lb-rhs): -292.7828063964844
120 domains visited
Cumulative time: 0.5166444778442383

BaB round 5
batch: 64
Average branched neurons at iteration 5:  1.0000
splitting decisions: 
split level 0: [/9, 4509] [/9, 7983] [/9, 4517] [/9, 4509] [/9, 7983] [/9, 4509] [/9, 4509] [/9, 3964] [/9, 7983] [/9, 7983] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 6.67572021484375e-05
Time: prepare 0.0086    bound 0.2271    transfer 0.0019    finalize 0.0100    func 0.2477    
Accumulated time: func 0.6194    prepare 0.0183    bound 0.5798    transfer 0.0040    finalize 0.0186    
Current worst splitting domains lb-rhs (depth):
-270.57593 (7), -270.55057 (7), -270.54883 (7), -270.54843 (7), -270.53680 (7), -270.53064 (7), -270.53012 (7), -270.52356 (7), -270.52313 (7), -270.52304 (7), -270.50479 (7), -270.50266 (7), -270.49789 (7), -270.49786 (7), -270.49377 (7), -270.47653 (7), -270.46170 (7), -270.45831 (7), -270.45325 (7), -270.45148 (7), 
length of domains: 128
Time: pickout 0.0010    decision 0.0954    set_bounds 0.0077    solve 0.2477    add 0.0123    
Accumulated time: pickout 0.0025    decision 0.2122    set_bounds 0.0169    solve 0.6196    add 0.0257    
Current (lb-rhs): -270.575927734375
248 domains visited
Cumulative time: 0.8811357021331787

BaB round 6
batch: 128
Average branched neurons at iteration 6:  1.0000
splitting decisions: 
split level 0: [/9, 7983] [/9, 4517] [/9, 9967] [/9, 7983] [/9, 4517] [/9, 10474] [/9, 10474] [/9, 7983] [/9, 4517] [/9, 4517] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.651878356933594e-05
Time: prepare 0.0175    bound 0.3776    transfer 0.0037    finalize 0.0253    func 0.4242    
Accumulated time: func 1.0436    prepare 0.0361    bound 0.9574    transfer 0.0077    finalize 0.0439    
Current worst splitting domains lb-rhs (depth):
-253.54488 (8), -253.54486 (8), -253.53702 (8), -253.53654 (8), -253.49490 (8), -253.49442 (8), -253.48637 (8), -253.48592 (8), -253.48582 (8), -253.48532 (8), -253.44344 (8), -253.43634 (8), -253.43633 (8), -253.43472 (8), -253.43468 (8), -253.42839 (8), -253.42838 (8), -253.42830 (8), -253.42654 (8), -253.42603 (8), 
length of domains: 256
Time: pickout 0.0026    decision 0.1788    set_bounds 0.0149    solve 0.4242    add 0.0312    
Accumulated time: pickout 0.0051    decision 0.3910    set_bounds 0.0318    solve 1.0438    add 0.0569    
Current (lb-rhs): -253.5448760986328
504 domains visited
Cumulative time: 1.5348455905914307

BaB round 7
batch: 128
Average branched neurons at iteration 7:  1.0000
splitting decisions: 
split level 0: [/9, 4517] [/9, 4509] [/9, 3964] [/9, 9967] [/9, 4509] [/9, 3953] [/9, 4517] [/13, 124] [/9, 4509] [/9, 10474] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0235    bound 0.3793    transfer 0.0037    finalize 0.0287    func 0.4353    
Accumulated time: func 1.4789    prepare 0.0599    bound 1.3367    transfer 0.0114    finalize 0.0726    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 384
Time: pickout 0.0027    decision 0.1844    set_bounds 0.0151    solve 0.4354    add 0.0266    
Accumulated time: pickout 0.0078    decision 0.5755    set_bounds 0.0469    solve 1.4792    add 0.0834    
Current (lb-rhs): -253.54486083984375
760 domains visited
Cumulative time: 2.1993117332458496

BaB round 8
batch: 128
Average branched neurons at iteration 8:  1.0000
splitting decisions: 
split level 0: [/9, 9967] [/13, 465] [/13, 121] [/9, 4517] [/9, 9967] [/9, 3964] [/13, 124] [/9, 4517] [/9, 9967] [/9, 3964] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 7.009506225585938e-05
Time: prepare 0.0182    bound 0.4408    transfer 0.0039    finalize 0.0140    func 0.4770    
Accumulated time: func 1.9558    prepare 0.0784    bound 1.7776    transfer 0.0153    finalize 0.0866    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 512
Time: pickout 0.0021    decision 0.1790    set_bounds 0.0149    solve 0.4771    add 0.0307    
Accumulated time: pickout 0.0100    decision 0.7545    set_bounds 0.0618    solve 1.9563    add 0.1142    
Current (lb-rhs): -253.54486083984375
1016 domains visited
Cumulative time: 2.903489351272583

BaB round 9
batch: 128
Average branched neurons at iteration 9:  1.0000
splitting decisions: 
split level 0: [/9, 3964] [/9, 9967] [/9, 4509] [/9, 3964] [/13, 444] [/9, 4517] [/9, 11686] [/9, 4225] [/9, 3964] [/9, 4509] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.651878356933594e-05
Time: prepare 0.0189    bound 0.3739    transfer 0.0120    finalize 0.0292    func 0.4340    
Accumulated time: func 2.3899    prepare 0.0977    bound 2.1515    transfer 0.0272    finalize 0.1158    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 640
Time: pickout 0.0028    decision 0.1831    set_bounds 0.0154    solve 0.4341    add 0.0272    
Accumulated time: pickout 0.0127    decision 0.9376    set_bounds 0.0772    solve 2.3904    add 0.1413    
Current (lb-rhs): -253.54486083984375
1272 domains visited
Cumulative time: 3.568021774291992

BaB round 10
batch: 128
Average branched neurons at iteration 10:  1.0000
splitting decisions: 
split level 0: [/9, 11483] [/13, 124] [/9, 7951] [/9, 11686] [/9, 9817] [/13, 146] [/9, 9967] [/9, 8451] [/9, 4225] [/9, 4225] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.079673767089844e-05
Time: prepare 0.0182    bound 0.3745    transfer 0.0037    finalize 0.0284    func 0.4249    
Accumulated time: func 2.8148    prepare 0.1162    bound 2.5260    transfer 0.0309    finalize 0.1442    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 768
Time: pickout 0.0024    decision 0.1773    set_bounds 0.0149    solve 0.4250    add 0.0305    
Accumulated time: pickout 0.0152    decision 1.1150    set_bounds 0.0921    solve 2.8154    add 0.1718    
Current (lb-rhs): -253.54486083984375
1528 domains visited
Cumulative time: 4.220148086547852

BaB round 11
batch: 128
Average branched neurons at iteration 11:  1.0000
splitting decisions: 
split level 0: [/9, 8451] [/9, 4225] [/9, 4225] [/9, 4225] [/9, 4225] [/13, 121] [/9, 4311] [/9, 4509] [/13, 146] [/9, 11686] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.67572021484375e-05
Time: prepare 0.0231    bound 0.3924    transfer 0.0037    finalize 0.0280    func 0.4477    
Accumulated time: func 3.2624    prepare 0.1398    bound 2.9184    transfer 0.0346    finalize 0.1722    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 896
Time: pickout 0.0026    decision 0.2154    set_bounds 0.0155    solve 0.4478    add 0.0266    
Accumulated time: pickout 0.0178    decision 1.3304    set_bounds 0.1075    solve 3.2632    add 0.1984    
Current (lb-rhs): -253.54486083984375
1784 domains visited
Cumulative time: 4.930039167404175

BaB round 12
batch: 128
Average branched neurons at iteration 12:  1.0000
splitting decisions: 
split level 0: [/9, 4311] [/9, 11686] [/9, 11686] [/9, 4311] [/9, 3964] [/9, 9967] [/9, 4225] [/9, 9967] [/9, 11686] [/13, 444] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.151199340820312e-05
Time: prepare 0.0189    bound 0.3713    transfer 0.0037    finalize 0.0280    func 0.4220    
Accumulated time: func 3.6845    prepare 0.1591    bound 3.2898    transfer 0.0383    finalize 0.2002    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1024
Time: pickout 0.0025    decision 0.1789    set_bounds 0.0151    solve 0.4221    add 0.0266    
Accumulated time: pickout 0.0203    decision 1.5093    set_bounds 0.1227    solve 3.6853    add 0.2250    
Current (lb-rhs): -253.54486083984375
2040 domains visited
Cumulative time: 5.577362775802612

BaB round 13
batch: 128
Average branched neurons at iteration 13:  1.0000
splitting decisions: 
split level 0: [/9, 11686] [/9, 4311] [/9, 4311] [/13, 124] [/9, 11686] [/9, 11686] [/9, 3964] [/9, 11686] [/9, 4311] [/9, 4311] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.9604644775390625e-05
Time: prepare 0.0187    bound 0.3724    transfer 0.0037    finalize 0.0279    func 0.4228    
Accumulated time: func 4.1073    prepare 0.1781    bound 3.6622    transfer 0.0420    finalize 0.2281    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1152
Time: pickout 0.0025    decision 0.1780    set_bounds 0.0151    solve 0.4229    add 0.2718    
Accumulated time: pickout 0.0229    decision 1.6873    set_bounds 0.1377    solve 4.1082    add 0.4968    
Current (lb-rhs): -253.54486083984375
2296 domains visited
Cumulative time: 6.468057870864868

BaB round 14
batch: 128
Average branched neurons at iteration 14:  1.0000
splitting decisions: 
split level 0: [/9, 4225] [/9, 3964] [/9, 9817] [/9, 9817] [/9, 11483] [/9, 4311] [/9, 8451] [/9, 4311] [/9, 10220] [/13, 417] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.745887756347656e-05
Time: prepare 0.0185    bound 0.3698    transfer 0.0037    finalize 0.0136    func 0.4057    
Accumulated time: func 4.5130    prepare 0.1970    bound 4.0319    transfer 0.0457    finalize 0.2417    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1280
Time: pickout 0.0025    decision 0.1788    set_bounds 0.0150    solve 0.4057    add 0.0252    
Accumulated time: pickout 0.0253    decision 1.8660    set_bounds 0.1527    solve 4.5140    add 0.5220    
Current (lb-rhs): -253.54486083984375
2552 domains visited
Cumulative time: 7.095544338226318

BaB round 15
batch: 128
Average branched neurons at iteration 15:  1.0000
splitting decisions: 
split level 0: [/9, 9817] [/13, 121] [/9, 8451] [/9, 7981] [/9, 4311] [/9, 11483] [/9, 9817] [/9, 9817] [/9, 9817] [/9, 9817] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0189    bound 0.3719    transfer 0.0038    finalize 0.0139    func 0.4086    
Accumulated time: func 4.9215    prepare 0.2162    bound 4.4038    transfer 0.0495    finalize 0.2556    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1408
Time: pickout 0.0022    decision 0.1783    set_bounds 0.0150    solve 0.4087    add 0.0288    
Accumulated time: pickout 0.0275    decision 2.0443    set_bounds 0.1677    solve 4.9226    add 0.5508    
Current (lb-rhs): -253.54486083984375
2808 domains visited
Cumulative time: 7.728811740875244

BaB round 16
batch: 128
Average branched neurons at iteration 16:  1.0000
splitting decisions: 
split level 0: [/9, 10220] [/9, 8451] [/9, 10220] [/9, 10220] [/9, 8451] [/9, 9817] [/9, 2039] [/13, 146] [/13, 465] [/9, 8451] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.222724914550781e-05
Time: prepare 0.0188    bound 0.3712    transfer 0.0037    finalize 0.0142    func 0.4080    
Accumulated time: func 5.3295    prepare 0.2353    bound 4.7749    transfer 0.0532    finalize 0.2699    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1536
Time: pickout 0.0025    decision 0.1780    set_bounds 0.0150    solve 0.4080    add 0.0237    
Accumulated time: pickout 0.0300    decision 2.2223    set_bounds 0.1827    solve 5.3307    add 0.5746    
Current (lb-rhs): -253.54486083984375
3064 domains visited
Cumulative time: 8.356364965438843

BaB round 17
batch: 128
Average branched neurons at iteration 17:  1.0000
splitting decisions: 
split level 0: [/9, 9628] [/9, 9817] [/9, 2039] [/9, 11672] [/9, 10220] [/9, 10220] [/9, 11483] [/9, 11483] [/9, 8451] [/9, 7981] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.793571472167969e-05
Time: prepare 0.0189    bound 0.3711    transfer 0.0037    finalize 0.0136    func 0.4073    
Accumulated time: func 5.7368    prepare 0.2544    bound 5.1460    transfer 0.0569    finalize 0.2835    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1664
Time: pickout 0.0024    decision 0.1771    set_bounds 0.0149    solve 0.4074    add 0.0240    
Accumulated time: pickout 0.0324    decision 2.3994    set_bounds 0.1977    solve 5.7380    add 0.5985    
Current (lb-rhs): -253.54486083984375
3320 domains visited
Cumulative time: 8.982519626617432

BaB round 18
batch: 128
Average branched neurons at iteration 18:  1.0000
splitting decisions: 
split level 0: [/9, 11672] [/9, 11483] [/9, 11483] [/9, 8451] [/13, 121] [/9, 8451] [/9, 10220] [/9, 10220] [/13, 124] [/13, 124] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0188    bound 0.3717    transfer 0.0037    finalize 0.0136    func 0.4078    
Accumulated time: func 6.1445    prepare 0.2735    bound 5.5177    transfer 0.0606    finalize 0.2970    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1792
Time: pickout 0.0024    decision 0.1772    set_bounds 0.0150    solve 0.4078    add 0.0240    
Accumulated time: pickout 0.0348    decision 2.5766    set_bounds 0.2127    solve 6.1459    add 0.6225    
Current (lb-rhs): -253.54486083984375
3576 domains visited
Cumulative time: 9.609358787536621

BaB round 19
batch: 128
Average branched neurons at iteration 19:  1.0000
splitting decisions: 
split level 0: [/9, 7981] [/9, 10220] [/9, 7981] [/9, 11483] [/9, 11672] [/9, 1713] [/9, 7981] [/9, 2039] [/9, 2039] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.91278076171875e-05
Time: prepare 0.0185    bound 0.3723    transfer 0.0037    finalize 0.0136    func 0.4082    
Accumulated time: func 6.5527    prepare 0.2923    bound 5.8900    transfer 0.0643    finalize 0.3107    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 1920
Time: pickout 0.0021    decision 0.1766    set_bounds 0.0149    solve 0.4082    add 0.0241    
Accumulated time: pickout 0.0369    decision 2.7532    set_bounds 0.2276    solve 6.5541    add 0.6466    
Current (lb-rhs): -253.54486083984375
3832 domains visited
Cumulative time: 10.23564076423645

BaB round 20
batch: 128
Average branched neurons at iteration 20:  1.0000
splitting decisions: 
split level 0: [/9, 2039] [/9, 11672] [/9, 9628] [/9, 2039] [/9, 7981] [/13, 465] [/9, 9628] [/9, 7981] [/13, 444] [/9, 11483] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.650520324707031e-05
Time: prepare 0.0193    bound 0.3729    transfer 0.0037    finalize 0.0136    func 0.4096    
Accumulated time: func 6.9623    prepare 0.3119    bound 6.2629    transfer 0.0680    finalize 0.3243    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2048
Time: pickout 0.0021    decision 0.1766    set_bounds 0.0149    solve 0.4096    add 0.0238    
Accumulated time: pickout 0.0390    decision 2.9298    set_bounds 0.2425    solve 6.9637    add 0.6704    
Current (lb-rhs): -253.54486083984375
4088 domains visited
Cumulative time: 10.862925052642822

BaB round 21
batch: 128
Average branched neurons at iteration 21:  1.0000
splitting decisions: 
split level 0: [/9, 1713] [/9, 2039] [/9, 11672] [/13, 146] [/9, 9900] [/9, 4082] [/9, 11672] [/9, 9628] [/13, 417] [/9, 10220] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.008148193359375e-05
Time: prepare 0.0190    bound 0.3723    transfer 0.0037    finalize 0.0137    func 0.4087    
Accumulated time: func 7.3710    prepare 0.3312    bound 6.6352    transfer 0.0717    finalize 0.3379    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2176
Time: pickout 0.0026    decision 0.1772    set_bounds 0.0153    solve 0.4088    add 0.4657    
Accumulated time: pickout 0.0416    decision 3.1070    set_bounds 0.2577    solve 7.3725    add 1.1361    
Current (lb-rhs): -253.54486083984375
4344 domains visited
Cumulative time: 11.932840585708618

BaB round 22
batch: 128
Average branched neurons at iteration 22:  1.0000
splitting decisions: 
split level 0: [/9, 9900] [/9, 7981] [/9, 1713] [/13, 417] [/9, 4082] [/9, 7981] [/9, 7858] [/9, 9900] [/9, 7981] [/9, 2039] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.8650970458984375e-05
Time: prepare 0.0186    bound 0.3703    transfer 0.0037    finalize 0.0137    func 0.4064    
Accumulated time: func 7.7773    prepare 0.3502    bound 7.0055    transfer 0.0754    finalize 0.3516    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2304
Time: pickout 0.0025    decision 0.1787    set_bounds 0.0149    solve 0.4065    add 0.0286    
Accumulated time: pickout 0.0441    decision 3.2857    set_bounds 0.2726    solve 7.7790    add 1.1647    
Current (lb-rhs): -253.54486083984375
4600 domains visited
Cumulative time: 12.56441330909729

BaB round 23
batch: 128
Average branched neurons at iteration 23:  1.0000
splitting decisions: 
split level 0: [/9, 7858] [/9, 8513] [/9, 4082] [/9, 9628] [/9, 2039] [/13, 444] [/9, 4082] [/9, 7858] [/9, 1713] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.151199340820312e-05
Time: prepare 0.0189    bound 0.3712    transfer 0.0037    finalize 0.0138    func 0.4082    
Accumulated time: func 8.1856    prepare 0.3694    bound 7.3767    transfer 0.0791    finalize 0.3654    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2432
Time: pickout 0.0025    decision 0.1770    set_bounds 0.0150    solve 0.4083    add 0.0267    
Accumulated time: pickout 0.0466    decision 3.4627    set_bounds 0.2876    solve 8.1873    add 1.1914    
Current (lb-rhs): -253.54486083984375
4856 domains visited
Cumulative time: 13.194267511367798

BaB round 24
batch: 128
Average branched neurons at iteration 24:  1.0000
splitting decisions: 
split level 0: [/9, 8513] [/9, 9628] [/9, 9912] [/13, 121] [/13, 124] [/9, 8374] [/9, 11312] [/9, 11312] [/13, 121] [/9, 9628] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0186    bound 0.3720    transfer 0.0037    finalize 0.0137    func 0.4080    
Accumulated time: func 8.5936    prepare 0.3883    bound 7.7487    transfer 0.0828    finalize 0.3791    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2560
Time: pickout 0.0027    decision 0.1784    set_bounds 0.0149    solve 0.4081    add 0.0266    
Accumulated time: pickout 0.0493    decision 3.6410    set_bounds 0.3025    solve 8.5954    add 1.2180    
Current (lb-rhs): -253.54486083984375
5112 domains visited
Cumulative time: 13.825372219085693

BaB round 25
batch: 128
Average branched neurons at iteration 25:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/9, 8374] [/9, 9900] [/13, 146] [/9, 11312] [/9, 2039] [/13, 124] [/13, 465] [/9, 11483] [/9, 8374] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0189    bound 0.3725    transfer 0.0037    finalize 0.0137    func 0.4089    
Accumulated time: func 9.0025    prepare 0.4075    bound 8.1212    transfer 0.0865    finalize 0.3928    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2688
Time: pickout 0.0026    decision 0.1768    set_bounds 0.0148    solve 0.4090    add 0.0257    
Accumulated time: pickout 0.0519    decision 3.8178    set_bounds 0.3174    solve 9.0043    add 1.2438    
Current (lb-rhs): -253.54486083984375
5368 domains visited
Cumulative time: 14.454643726348877

BaB round 26
batch: 128
Average branched neurons at iteration 26:  1.0000
splitting decisions: 
split level 0: [/9, 9912] [/9, 4082] [/13, 146] [/13, 124] [/13, 124] [/9, 9912] [/9, 9900] [/9, 11672] [/9, 9628] [/9, 11672] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.270408630371094e-05
Time: prepare 0.0187    bound 0.3722    transfer 0.0037    finalize 0.0136    func 0.4083    
Accumulated time: func 9.4108    prepare 0.4265    bound 8.4934    transfer 0.0902    finalize 0.4064    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2816
Time: pickout 0.0025    decision 0.1767    set_bounds 0.0149    solve 0.4084    add 0.0262    
Accumulated time: pickout 0.0544    decision 3.9945    set_bounds 0.3323    solve 9.4127    add 1.2700    
Current (lb-rhs): -253.54486083984375
5624 domains visited
Cumulative time: 15.08371353149414

BaB round 27
batch: 128
Average branched neurons at iteration 27:  1.0000
splitting decisions: 
split level 0: [/9, 11312] [/9, 1713] [/9, 8513] [/9, 1713] [/9, 9628] [/9, 11672] [/9, 8513] [/9, 1713] [/9, 11672] [/9, 1713] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.198883056640625e-05
Time: prepare 0.0187    bound 0.3716    transfer 0.0037    finalize 0.0137    func 0.4078    
Accumulated time: func 9.8186    prepare 0.4456    bound 8.8651    transfer 0.0939    finalize 0.4201    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 2944
Time: pickout 0.0025    decision 0.1770    set_bounds 0.0149    solve 0.4079    add 0.0279    
Accumulated time: pickout 0.0569    decision 4.1715    set_bounds 0.3472    solve 9.8206    add 1.2979    
Current (lb-rhs): -253.54486083984375
5880 domains visited
Cumulative time: 15.714399337768555

BaB round 28
batch: 128
Average branched neurons at iteration 28:  1.0000
splitting decisions: 
split level 0: [/9, 4082] [/9, 9912] [/9, 8260] [/9, 11312] [/9, 7858] [/9, 9628] [/9, 9956] [/9, 4082] [/9, 9900] [/9, 9900] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0187    bound 0.3725    transfer 0.0037    finalize 0.0143    func 0.4093    
Accumulated time: func 10.2278    prepare 0.4646    bound 9.2376    transfer 0.0976    finalize 0.4344    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3072
Time: pickout 0.0025    decision 0.1767    set_bounds 0.0149    solve 0.4093    add 0.0248    
Accumulated time: pickout 0.0594    decision 4.3482    set_bounds 0.3621    solve 10.2300    add 1.3227    
Current (lb-rhs): -253.54486083984375
6136 domains visited
Cumulative time: 16.343135118484497

BaB round 29
batch: 128
Average branched neurons at iteration 29:  1.0000
splitting decisions: 
split level 0: [/9, 8260] [/9, 9900] [/9, 7858] [/9, 9900] [/13, 124] [/9, 8260] [/9, 9912] [/13, 444] [/13, 465] [/9, 4082] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.222724914550781e-05
Time: prepare 0.0194    bound 0.3707    transfer 0.0037    finalize 0.0137    func 0.4075    
Accumulated time: func 10.6354    prepare 0.4843    bound 9.6083    transfer 0.1013    finalize 0.4481    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3200
Time: pickout 0.0025    decision 0.1766    set_bounds 0.0150    solve 0.4076    add 0.0249    
Accumulated time: pickout 0.0619    decision 4.5248    set_bounds 0.3771    solve 10.6375    add 1.3476    
Current (lb-rhs): -253.54486083984375
6392 domains visited
Cumulative time: 16.9702091217041

BaB round 30
batch: 128
Average branched neurons at iteration 30:  1.0000
splitting decisions: 
split level 0: [/9, 9956] [/9, 7858] [/9, 11116] [/9, 8513] [/9, 9956] [/9, 9900] [/9, 8260] [/9, 9912] [/13, 146] [/13, 444] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.008148193359375e-05
Time: prepare 0.0192    bound 0.3712    transfer 0.0037    finalize 0.0137    func 0.4079    
Accumulated time: func 11.0433    prepare 0.5038    bound 9.9795    transfer 0.1050    finalize 0.4618    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3328
Time: pickout 0.0027    decision 0.1775    set_bounds 0.0149    solve 0.4080    add 0.0254    
Accumulated time: pickout 0.0647    decision 4.7023    set_bounds 0.3920    solve 11.0456    add 1.3731    
Current (lb-rhs): -253.54486083984375
6648 domains visited
Cumulative time: 17.599190950393677

BaB round 31
batch: 128
Average branched neurons at iteration 31:  1.0000
splitting decisions: 
split level 0: [/9, 9996] [/9, 9996] [/9, 11312] [/13, 121] [/9, 8513] [/9, 7858] [/9, 9539] [/9, 8374] [/9, 4082] [/9, 11312] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.936622619628906e-05
Time: prepare 0.0187    bound 0.3720    transfer 0.0037    finalize 0.0137    func 0.4081    
Accumulated time: func 11.4514    prepare 0.5228    bound 10.3515    transfer 0.1087    finalize 0.4755    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3456
Time: pickout 0.0026    decision 0.1770    set_bounds 0.0149    solve 0.4082    add 0.0273    
Accumulated time: pickout 0.0673    decision 4.8793    set_bounds 0.4069    solve 11.4538    add 1.4004    
Current (lb-rhs): -253.54486083984375
6904 domains visited
Cumulative time: 18.22958779335022

BaB round 32
batch: 128
Average branched neurons at iteration 32:  1.0000
splitting decisions: 
split level 0: [/9, 11116] [/9, 11312] [/9, 9956] [/9, 8374] [/13, 121] [/13, 121] [/9, 4317] [/9, 8513] [/9, 7858] [/9, 9956] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0188    bound 0.3713    transfer 0.0037    finalize 0.0137    func 0.4076    
Accumulated time: func 11.8591    prepare 0.5419    bound 10.7228    transfer 0.1124    finalize 0.4892    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3584
Time: pickout 0.0024    decision 0.1768    set_bounds 0.0149    solve 0.4077    add 0.0261    
Accumulated time: pickout 0.0697    decision 5.0561    set_bounds 0.4218    solve 11.8615    add 1.4264    
Current (lb-rhs): -253.54486083984375
7160 domains visited
Cumulative time: 18.85786747932434

BaB round 33
batch: 128
Average branched neurons at iteration 33:  1.0000
splitting decisions: 
split level 0: [/9, 11397] [/9, 11397] [/9, 9539] [/9, 4082] [/9, 11397] [/9, 11510] [/13, 417] [/9, 11510] [/9, 8513] [/9, 7858] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.866455078125e-05
Time: prepare 0.0186    bound 0.3715    transfer 0.0037    finalize 0.0138    func 0.4076    
Accumulated time: func 12.2667    prepare 0.5609    bound 11.0943    transfer 0.1161    finalize 0.5030    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3712
Time: pickout 0.0025    decision 0.1765    set_bounds 0.0153    solve 0.4077    add 0.0265    
Accumulated time: pickout 0.0721    decision 5.2326    set_bounds 0.4371    solve 12.2692    add 1.4530    
Current (lb-rhs): -253.54486083984375
7416 domains visited
Cumulative time: 19.486886501312256

BaB round 34
batch: 128
Average branched neurons at iteration 34:  1.0000
splitting decisions: 
split level 0: [/9, 9539] [/9, 11116] [/9, 2116] [/9, 9956] [/9, 9912] [/9, 11312] [/13, 124] [/9, 9956] [/9, 11312] [/9, 8260] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.793571472167969e-05
Time: prepare 0.0186    bound 0.3714    transfer 0.0037    finalize 0.0138    func 0.4076    
Accumulated time: func 12.6743    prepare 0.5798    bound 11.4658    transfer 0.1198    finalize 0.5168    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3840
Time: pickout 0.0025    decision 0.1766    set_bounds 0.0149    solve 0.4077    add 0.0259    
Accumulated time: pickout 0.0747    decision 5.4093    set_bounds 0.4520    solve 12.6769    add 1.4789    
Current (lb-rhs): -253.54486083984375
7672 domains visited
Cumulative time: 20.114980697631836

BaB round 35
batch: 128
Average branched neurons at iteration 35:  1.0000
splitting decisions: 
split level 0: [/9, 8091] [/9, 9539] [/13, 146] [/9, 9912] [/13, 146] [/9, 8513] [/9, 1713] [/9, 11397] [/9, 9912] [/9, 9996] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.8650970458984375e-05
Time: prepare 0.0189    bound 0.3714    transfer 0.0037    finalize 0.0138    func 0.4084    
Accumulated time: func 13.0827    prepare 0.5990    bound 11.8372    transfer 0.1235    finalize 0.5305    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 3968
Time: pickout 0.0025    decision 0.1766    set_bounds 0.0149    solve 0.4085    add 0.0271    
Accumulated time: pickout 0.0772    decision 5.5858    set_bounds 0.4669    solve 13.0853    add 1.5060    
Current (lb-rhs): -253.54486083984375
7928 domains visited
Cumulative time: 20.744994640350342

BaB round 36
batch: 128
Average branched neurons at iteration 36:  1.0000
splitting decisions: 
split level 0: [/9, 4317] [/9, 10037] [/9, 9996] [/9, 7858] [/9, 1713] [/9, 11397] [/9, 10037] [/9, 4317] [/9, 8260] [/9, 9912] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.246566772460938e-05
Time: prepare 0.0191    bound 0.3699    transfer 0.0037    finalize 0.0138    func 0.4066    
Accumulated time: func 13.4892    prepare 0.6185    bound 12.2071    transfer 0.1272    finalize 0.5443    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4096
Time: pickout 0.0025    decision 0.2120    set_bounds 0.0151    solve 0.4067    add 0.0276    
Accumulated time: pickout 0.0796    decision 5.7978    set_bounds 0.4820    solve 13.4920    add 1.5336    
Current (lb-rhs): -253.54486083984375
8184 domains visited
Cumulative time: 21.409316778182983

BaB round 37
batch: 128
Average branched neurons at iteration 37:  1.0000
splitting decisions: 
split level 0: [/9, 10037] [/13, 124] [/9, 11397] [/9, 8260] [/13, 146] [/13, 121] [/9, 9996] [/9, 8260] [/9, 9956] [/9, 8513] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0187    bound 0.3710    transfer 0.0037    finalize 0.0137    func 0.4072    
Accumulated time: func 13.8964    prepare 0.6375    bound 12.5782    transfer 0.1309    finalize 0.5580    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4224
Time: pickout 0.0025    decision 0.1772    set_bounds 0.0150    solve 0.4073    add 0.9357    
Accumulated time: pickout 0.0821    decision 5.9750    set_bounds 0.4970    solve 13.8993    add 2.4693    
Current (lb-rhs): -253.54486083984375
8440 domains visited
Cumulative time: 22.947420597076416

BaB round 38
batch: 128
Average branched neurons at iteration 38:  1.0000
splitting decisions: 
split level 0: [/9, 3991] [/9, 4317] [/13, 124] [/9, 9996] [/13, 121] [/9, 9956] [/9, 11116] [/9, 9996] [/9, 11397] [/9, 4317] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.341934204101562e-05
Time: prepare 0.0190    bound 0.3713    transfer 0.0037    finalize 0.0137    func 0.4077    
Accumulated time: func 14.3042    prepare 0.6567    bound 12.9494    transfer 0.1346    finalize 0.5718    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4352
Time: pickout 0.0026    decision 0.1785    set_bounds 0.0155    solve 0.4078    add 0.0268    
Accumulated time: pickout 0.0847    decision 6.1535    set_bounds 0.5125    solve 14.3071    add 2.4961    
Current (lb-rhs): -253.54486083984375
8696 domains visited
Cumulative time: 23.579162120819092

BaB round 39
batch: 128
Average branched neurons at iteration 39:  1.0000
splitting decisions: 
split level 0: [/9, 8374] [/13, 146] [/9, 8374] [/9, 11397] [/13, 465] [/9, 8091] [/9, 11397] [/13, 465] [/9, 11116] [/9, 10037] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0192    bound 0.3715    transfer 0.0037    finalize 0.0138    func 0.4083    
Accumulated time: func 14.7124    prepare 0.6763    bound 13.3209    transfer 0.1383    finalize 0.5856    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4480
Time: pickout 0.0025    decision 0.1764    set_bounds 0.0149    solve 0.4084    add 0.0268    
Accumulated time: pickout 0.0872    decision 6.3300    set_bounds 0.5274    solve 14.7154    add 2.5229    
Current (lb-rhs): -253.54486083984375
8952 domains visited
Cumulative time: 24.208726406097412

BaB round 40
batch: 128
Average branched neurons at iteration 40:  1.0000
splitting decisions: 
split level 0: [/9, 2116] [/13, 121] [/9, 10037] [/13, 444] [/9, 9996] [/9, 9996] [/9, 8091] [/9, 11116] [/9, 9996] [/9, 11397] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0187    bound 0.3717    transfer 0.0037    finalize 0.0137    func 0.4085    
Accumulated time: func 15.1209    prepare 0.6953    bound 13.6926    transfer 0.1421    finalize 0.5993    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4608
Time: pickout 0.0026    decision 0.1766    set_bounds 0.0149    solve 0.4085    add 0.0269    
Accumulated time: pickout 0.0898    decision 6.5065    set_bounds 0.5423    solve 15.1240    add 2.5499    
Current (lb-rhs): -253.54486083984375
9208 domains visited
Cumulative time: 24.83872938156128

BaB round 41
batch: 128
Average branched neurons at iteration 41:  1.0000
splitting decisions: 
split level 0: [/9, 11200] [/9, 8091] [/9, 4317] [/13, 121] [/9, 9539] [/9, 11116] [/9, 7916] [/13, 124] [/9, 3991] [/9, 11116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.103515625e-05
Time: prepare 0.0190    bound 0.3720    transfer 0.0037    finalize 0.0138    func 0.4086    
Accumulated time: func 15.5295    prepare 0.7146    bound 14.0646    transfer 0.1457    finalize 0.6131    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4736
Time: pickout 0.0026    decision 0.1766    set_bounds 0.0149    solve 0.4086    add 0.0272    
Accumulated time: pickout 0.0923    decision 6.6832    set_bounds 0.5572    solve 15.5326    add 2.5771    
Current (lb-rhs): -253.54486083984375
9464 domains visited
Cumulative time: 25.469197511672974

BaB round 42
batch: 128
Average branched neurons at iteration 42:  1.0000
splitting decisions: 
split level 0: [/9, 7916] [/13, 124] [/9, 8091] [/9, 11116] [/9, 8260] [/13, 124] [/9, 3991] [/9, 9539] [/9, 9539] [/9, 9539] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.793571472167969e-05
Time: prepare 0.0188    bound 0.3721    transfer 0.0038    finalize 0.0138    func 0.4086    
Accumulated time: func 15.9380    prepare 0.7338    bound 14.4367    transfer 0.1495    finalize 0.6269    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4864
Time: pickout 0.0025    decision 0.1763    set_bounds 0.0150    solve 0.4086    add 0.0273    
Accumulated time: pickout 0.0948    decision 6.8595    set_bounds 0.5722    solve 15.9413    add 2.6044    
Current (lb-rhs): -253.54486083984375
9720 domains visited
Cumulative time: 26.09937882423401

BaB round 43
batch: 128
Average branched neurons at iteration 43:  1.0000
splitting decisions: 
split level 0: [/13, 121] [/9, 9956] [/9, 3991] [/9, 9539] [/13, 124] [/9, 3991] [/9, 8374] [/9, 8091] [/9, 8091] [/9, 8091] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0187    bound 0.3712    transfer 0.0037    finalize 0.0137    func 0.4074    
Accumulated time: func 16.3454    prepare 0.7528    bound 14.8079    transfer 0.1532    finalize 0.6406    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 4992
Time: pickout 0.0027    decision 0.1762    set_bounds 0.0150    solve 0.4075    add 0.0263    
Accumulated time: pickout 0.0975    decision 7.0357    set_bounds 0.5871    solve 16.3487    add 2.6307    
Current (lb-rhs): -253.54486083984375
9976 domains visited
Cumulative time: 26.727556943893433

BaB round 44
batch: 128
Average branched neurons at iteration 44:  1.0000
splitting decisions: 
split level 0: [/9, 2289] [/9, 8260] [/9, 2289] [/13, 121] [/9, 10037] [/13, 124] [/13, 121] [/9, 2116] [/9, 4317] [/9, 7916] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0190    bound 0.3720    transfer 0.0037    finalize 0.0138    func 0.4085    
Accumulated time: func 16.7539    prepare 0.7721    bound 15.1799    transfer 0.1569    finalize 0.6544    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5120
Time: pickout 0.0026    decision 0.1766    set_bounds 0.0148    solve 0.4086    add 0.0275    
Accumulated time: pickout 0.1001    decision 7.2123    set_bounds 0.6020    solve 16.7573    add 2.6582    
Current (lb-rhs): -253.54486083984375
10232 domains visited
Cumulative time: 27.35819149017334

BaB round 45
batch: 128
Average branched neurons at iteration 45:  1.0000
splitting decisions: 
split level 0: [/9, 11622] [/9, 7916] [/9, 8249] [/13, 146] [/9, 11116] [/13, 121] [/9, 2116] [/9, 7916] [/9, 10037] [/9, 3991] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.103515625e-05
Time: prepare 0.0187    bound 0.3720    transfer 0.0037    finalize 0.0144    func 0.4089    
Accumulated time: func 17.1628    prepare 0.7912    bound 15.5518    transfer 0.1606    finalize 0.6688    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5248
Time: pickout 0.0025    decision 0.1764    set_bounds 0.0149    solve 0.4090    add 0.0278    
Accumulated time: pickout 0.1026    decision 7.3887    set_bounds 0.6169    solve 17.1663    add 2.6860    
Current (lb-rhs): -253.54486083984375
10488 domains visited
Cumulative time: 27.989270210266113

BaB round 46
batch: 128
Average branched neurons at iteration 46:  1.0000
splitting decisions: 
split level 0: [/9, 10995] [/9, 3991] [/9, 7916] [/13, 444] [/9, 4317] [/9, 9539] [/9, 11622] [/9, 10037] [/9, 7916] [/9, 2116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.8650970458984375e-05
Time: prepare 0.0186    bound 0.3706    transfer 0.0037    finalize 0.0137    func 0.4066    
Accumulated time: func 17.5694    prepare 0.8102    bound 15.9224    transfer 0.1643    finalize 0.6825    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5376
Time: pickout 0.0025    decision 0.1779    set_bounds 0.0149    solve 0.4067    add 0.0260    
Accumulated time: pickout 0.1051    decision 7.5666    set_bounds 0.6318    solve 17.5729    add 2.7120    
Current (lb-rhs): -253.54486083984375
10744 domains visited
Cumulative time: 28.61777901649475

BaB round 47
batch: 128
Average branched neurons at iteration 47:  1.0000
splitting decisions: 
split level 0: [/9, 3954] [/9, 11510] [/9, 3954] [/9, 4317] [/13, 146] [/13, 121] [/9, 2289] [/9, 3991] [/9, 11200] [/9, 11510] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.723403930664062e-05
Time: prepare 0.0196    bound 0.3702    transfer 0.0037    finalize 0.0138    func 0.4075    
Accumulated time: func 17.9768    prepare 0.8300    bound 16.2926    transfer 0.1680    finalize 0.6963    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5504
Time: pickout 0.0027    decision 0.1772    set_bounds 0.0149    solve 0.4076    add 0.0257    
Accumulated time: pickout 0.1078    decision 7.7438    set_bounds 0.6467    solve 17.9805    add 2.7377    
Current (lb-rhs): -253.54486083984375
11000 domains visited
Cumulative time: 29.246463775634766

BaB round 48
batch: 128
Average branched neurons at iteration 48:  1.0000
splitting decisions: 
split level 0: [/9, 8249] [/13, 465] [/9, 11622] [/9, 10037] [/9, 8091] [/9, 10037] [/9, 10995] [/9, 11622] [/9, 2116] [/13, 124] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.8650970458984375e-05
Time: prepare 0.0187    bound 0.3713    transfer 0.0037    finalize 0.0138    func 0.4076    
Accumulated time: func 18.3844    prepare 0.8491    bound 16.6639    transfer 0.1717    finalize 0.7101    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5632
Time: pickout 0.0028    decision 0.1769    set_bounds 0.0148    solve 0.4077    add 0.0275    
Accumulated time: pickout 0.1106    decision 7.9207    set_bounds 0.6616    solve 18.3882    add 2.7652    
Current (lb-rhs): -253.54486083984375
11256 domains visited
Cumulative time: 29.87662959098816

BaB round 49
batch: 128
Average branched neurons at iteration 49:  1.0000
splitting decisions: 
split level 0: [/9, 8430] [/9, 11622] [/9, 11200] [/9, 8091] [/9, 8374] [/13, 465] [/9, 8249] [/9, 2289] [/9, 11622] [/13, 417] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.008148193359375e-05
Time: prepare 0.0185    bound 0.3705    transfer 0.0037    finalize 0.0137    func 0.4065    
Accumulated time: func 18.7909    prepare 0.8679    bound 17.0344    transfer 0.1754    finalize 0.7238    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5760
Time: pickout 0.0029    decision 0.1768    set_bounds 0.0149    solve 0.4066    add 0.0230    
Accumulated time: pickout 0.1135    decision 8.0975    set_bounds 0.6764    solve 18.7948    add 2.7882    
Current (lb-rhs): -253.54486083984375
11512 domains visited
Cumulative time: 30.5013484954834

BaB round 50
batch: 128
Average branched neurons at iteration 50:  1.0000
splitting decisions: 
split level 0: [/9, 8232] [/9, 10995] [/9, 10995] [/9, 7916] [/9, 7916] [/9, 4317] [/9, 11200] [/9, 11200] [/9, 2289] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.890296936035156e-05
Time: prepare 0.0188    bound 0.3715    transfer 0.0038    finalize 0.0139    func 0.4081    
Accumulated time: func 19.1991    prepare 0.8871    bound 17.4059    transfer 0.1792    finalize 0.7378    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 5888
Time: pickout 0.0023    decision 0.1811    set_bounds 0.0172    solve 0.4083    add 0.0260    
Accumulated time: pickout 0.1158    decision 8.2786    set_bounds 0.6936    solve 19.2030    add 2.8142    
Current (lb-rhs): -253.54486083984375
11768 domains visited
Cumulative time: 31.13676929473877

BaB round 51
batch: 128
Average branched neurons at iteration 51:  1.0000
splitting decisions: 
split level 0: [/9, 4606] [/9, 9957] [/13, 121] [/13, 465] [/9, 3991] [/9, 7916] [/9, 9642] [/9, 10995] [/9, 8374] [/9, 11622] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.008148193359375e-05
Time: prepare 0.0188    bound 0.3716    transfer 0.0037    finalize 0.0138    func 0.4080    
Accumulated time: func 19.6071    prepare 0.9062    bound 17.7775    transfer 0.1829    finalize 0.7516    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6016
Time: pickout 0.0028    decision 0.1768    set_bounds 0.0149    solve 0.4080    add 0.0257    
Accumulated time: pickout 0.1186    decision 8.4554    set_bounds 0.7085    solve 19.6111    add 2.8399    
Current (lb-rhs): -253.54486083984375
12024 domains visited
Cumulative time: 31.765586137771606

BaB round 52
batch: 128
Average branched neurons at iteration 52:  1.0000
splitting decisions: 
split level 0: [/9, 11510] [/9, 2116] [/9, 9642] [/13, 444] [/9, 11622] [/9, 11622] [/9, 8430] [/9, 8249] [/9, 10995] [/9, 2289] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.031990051269531e-05
Time: prepare 0.0187    bound 0.3709    transfer 0.0037    finalize 0.0138    func 0.4078    
Accumulated time: func 20.0149    prepare 0.9252    bound 18.1484    transfer 0.1867    finalize 0.7654    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6144
Time: pickout 0.0028    decision 0.1764    set_bounds 0.0150    solve 0.4079    add 0.0261    
Accumulated time: pickout 0.1215    decision 8.6318    set_bounds 0.7235    solve 20.0190    add 2.8660    
Current (lb-rhs): -253.54486083984375
12280 domains visited
Cumulative time: 32.39442729949951

BaB round 53
batch: 128
Average branched neurons at iteration 53:  1.0000
splitting decisions: 
split level 0: [/9, 11749] [/9, 8232] [/9, 4606] [/13, 124] [/9, 11200] [/9, 2289] [/9, 11510] [/9, 8430] [/9, 8249] [/9, 10995] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.365776062011719e-05
Time: prepare 0.0188    bound 0.3754    transfer 0.0037    finalize 0.0138    func 0.4118    
Accumulated time: func 20.4267    prepare 0.9444    bound 18.5238    transfer 0.1904    finalize 0.7791    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6272
Time: pickout 0.0028    decision 0.1764    set_bounds 0.0150    solve 0.4119    add 0.0268    
Accumulated time: pickout 0.1242    decision 8.8083    set_bounds 0.7384    solve 20.4308    add 2.8928    
Current (lb-rhs): -253.54486083984375
12536 domains visited
Cumulative time: 33.027860164642334

BaB round 54
batch: 128
Average branched neurons at iteration 54:  1.0000
splitting decisions: 
split level 0: [/9, 9642] [/9, 11200] [/9, 8430] [/9, 11510] [/9, 2116] [/13, 124] [/9, 3954] [/9, 4606] [/9, 9642] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.628036499023438e-05
Time: prepare 0.0190    bound 0.3722    transfer 0.0037    finalize 0.0139    func 0.4088    
Accumulated time: func 20.8355    prepare 0.9637    bound 18.8959    transfer 0.1941    finalize 0.7930    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6400
Time: pickout 0.0027    decision 0.1771    set_bounds 0.0149    solve 0.4089    add 0.0263    
Accumulated time: pickout 0.1269    decision 8.9854    set_bounds 0.7534    solve 20.8397    add 2.9191    
Current (lb-rhs): -253.54486083984375
12792 domains visited
Cumulative time: 33.65835094451904

BaB round 55
batch: 128
Average branched neurons at iteration 55:  1.0000
splitting decisions: 
split level 0: [/9, 4508] [/9, 2289] [/9, 11398] [/9, 2116] [/9, 8430] [/9, 10995] [/9, 8232] [/9, 8232] [/9, 8430] [/9, 8249] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0190    bound 0.3715    transfer 0.0037    finalize 0.0139    func 0.4081    
Accumulated time: func 21.2435    prepare 0.9830    bound 19.2674    transfer 0.1978    finalize 0.8069    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6528
Time: pickout 0.0029    decision 0.1797    set_bounds 0.0150    solve 0.4082    add 0.0263    
Accumulated time: pickout 0.1299    decision 9.1651    set_bounds 0.7683    solve 21.2479    add 2.9453    
Current (lb-rhs): -253.54486083984375
13048 domains visited
Cumulative time: 34.29098415374756

BaB round 56
batch: 128
Average branched neurons at iteration 56:  1.0000
splitting decisions: 
split level 0: [/9, 11398] [/9, 8430] [/9, 11510] [/9, 3991] [/9, 3954] [/9, 2116] [/9, 4606] [/9, 3954] [/9, 3954] [/13, 444] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.936622619628906e-05
Time: prepare 0.0187    bound 0.3717    transfer 0.0037    finalize 0.0137    func 0.4079    
Accumulated time: func 21.6514    prepare 1.0020    bound 19.6391    transfer 0.2015    finalize 0.8206    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6656
Time: pickout 0.0028    decision 0.1763    set_bounds 0.0150    solve 0.4080    add 0.0268    
Accumulated time: pickout 0.1327    decision 9.3414    set_bounds 0.7833    solve 21.6559    add 2.9721    
Current (lb-rhs): -253.54486083984375
13304 domains visited
Cumulative time: 34.9204158782959

BaB round 57
batch: 128
Average branched neurons at iteration 57:  1.0000
splitting decisions: 
split level 0: [/9, 1576] [/9, 4606] [/9, 11749] [/9, 8430] [/9, 2289] [/13, 124] [/9, 4508] [/13, 417] [/9, 4606] [/9, 9642] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.8650970458984375e-05
Time: prepare 0.0189    bound 0.3715    transfer 0.0037    finalize 0.0145    func 0.4086    
Accumulated time: func 22.0600    prepare 1.0212    bound 20.0105    transfer 0.2052    finalize 0.8351    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6784
Time: pickout 0.0027    decision 0.1768    set_bounds 0.0150    solve 0.4087    add 0.0239    
Accumulated time: pickout 0.1354    decision 9.5182    set_bounds 0.7983    solve 22.0646    add 2.9960    
Current (lb-rhs): -253.54486083984375
13560 domains visited
Cumulative time: 35.54808831214905

BaB round 58
batch: 128
Average branched neurons at iteration 58:  1.0000
splitting decisions: 
split level 0: [/13, 444] [/9, 9642] [/9, 8232] [/9, 11622] [/9, 10995] [/13, 465] [/9, 8469] [/9, 4508] [/9, 8232] [/13, 417] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.151199340820312e-05
Time: prepare 0.0186    bound 0.3726    transfer 0.0037    finalize 0.0138    func 0.4088    
Accumulated time: func 22.4688    prepare 1.0402    bound 20.3831    transfer 0.2089    finalize 0.8488    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 6912
Time: pickout 0.0028    decision 0.1777    set_bounds 0.0150    solve 0.4088    add 0.0240    
Accumulated time: pickout 0.1381    decision 9.6959    set_bounds 0.8133    solve 22.4734    add 3.0201    
Current (lb-rhs): -253.54486083984375
13816 domains visited
Cumulative time: 36.17704153060913

BaB round 59
batch: 128
Average branched neurons at iteration 59:  1.0000
splitting decisions: 
split level 0: [/9, 9458] [/9, 1576] [/9, 4508] [/9, 2289] [/9, 8249] [/13, 124] [/9, 1576] [/9, 1576] [/9, 11510] [/9, 8430] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0185    bound 0.3771    transfer 0.0037    finalize 0.0138    func 0.4132    
Accumulated time: func 22.8820    prepare 1.0590    bound 20.7602    transfer 0.2126    finalize 0.8627    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7040
Time: pickout 0.0019    decision 0.1765    set_bounds 0.0149    solve 0.4133    add 0.0259    
Accumulated time: pickout 0.1400    decision 9.8724    set_bounds 0.8282    solve 22.8867    add 3.0460    
Current (lb-rhs): -253.54486083984375
14072 domains visited
Cumulative time: 36.81011486053467

BaB round 60
batch: 128
Average branched neurons at iteration 60:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/9, 8249] [/9, 9458] [/9, 11200] [/9, 1576] [/9, 11200] [/9, 10728] [/13, 417] [/9, 1576] [/9, 3954] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.103515625e-05
Time: prepare 0.0185    bound 0.3724    transfer 0.0037    finalize 0.0138    func 0.4085    
Accumulated time: func 23.2904    prepare 1.0779    bound 21.1326    transfer 0.2163    finalize 0.8765    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7168
Time: pickout 0.0028    decision 0.1765    set_bounds 0.0149    solve 0.4085    add 0.0259    
Accumulated time: pickout 0.1428    decision 10.0489    set_bounds 0.8431    solve 23.2952    add 3.0718    
Current (lb-rhs): -253.54486083984375
14328 domains visited
Cumulative time: 37.439390897750854

BaB round 61
batch: 128
Average branched neurons at iteration 61:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 11749] [/13, 124] [/9, 10995] [/13, 146] [/13, 124] [/9, 11398] [/9, 9642] [/9, 11398] [/9, 11200] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.270408630371094e-05
Time: prepare 0.0190    bound 0.3716    transfer 0.0037    finalize 0.0138    func 0.4080    
Accumulated time: func 23.6985    prepare 1.0972    bound 21.5041    transfer 0.2200    finalize 0.8902    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7296
Time: pickout 0.0029    decision 0.1789    set_bounds 0.0150    solve 0.4081    add 0.0273    
Accumulated time: pickout 0.1458    decision 10.2277    set_bounds 0.8581    solve 23.7033    add 3.0992    
Current (lb-rhs): -253.54486083984375
14584 domains visited
Cumulative time: 38.07222580909729

BaB round 62
batch: 128
Average branched neurons at iteration 62:  1.0000
splitting decisions: 
split level 0: [/9, 8602] [/9, 11398] [/9, 8469] [/9, 8249] [/13, 465] [/13, 121] [/9, 11749] [/9, 11749] [/9, 4508] [/9, 8232] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.842613220214844e-05
Time: prepare 0.0183    bound 0.3731    transfer 0.0038    finalize 0.0139    func 0.4092    
Accumulated time: func 24.1077    prepare 1.1158    bound 21.8772    transfer 0.2238    finalize 0.9041    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7424
Time: pickout 0.0028    decision 0.1767    set_bounds 0.0154    solve 0.4093    add 0.0266    
Accumulated time: pickout 0.1485    decision 10.4045    set_bounds 0.8735    solve 24.1126    add 3.1258    
Current (lb-rhs): -253.54486083984375
14840 domains visited
Cumulative time: 38.70364332199097

BaB round 63
batch: 128
Average branched neurons at iteration 63:  1.0000
splitting decisions: 
split level 0: [/9, 8615] [/9, 3954] [/9, 1576] [/9, 9642] [/9, 8232] [/9, 8430] [/9, 8615] [/9, 8615] [/9, 11749] [/9, 1576] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.079673767089844e-05
Time: prepare 0.0190    bound 0.3709    transfer 0.0038    finalize 0.0140    func 0.4077    
Accumulated time: func 24.5154    prepare 1.1351    bound 22.2481    transfer 0.2276    finalize 0.9181    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7552
Time: pickout 0.0027    decision 0.1764    set_bounds 0.0154    solve 0.4078    add 0.0239    
Accumulated time: pickout 0.1513    decision 10.5809    set_bounds 0.8889    solve 24.5204    add 3.1497    
Current (lb-rhs): -253.54486083984375
15096 domains visited
Cumulative time: 39.33052062988281

BaB round 64
batch: 128
Average branched neurons at iteration 64:  1.0000
splitting decisions: 
split level 0: [/9, 4549] [/9, 4508] [/9, 9992] [/9, 3954] [/9, 11749] [/13, 417] [/9, 1601] [/9, 11398] [/9, 8469] [/9, 4606] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.914138793945312e-05
Time: prepare 0.0193    bound 0.3739    transfer 0.0037    finalize 0.0138    func 0.4117    
Accumulated time: func 24.9270    prepare 1.1547    bound 22.6220    transfer 0.2313    finalize 0.9319    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7680
Time: pickout 0.0028    decision 0.1763    set_bounds 0.0150    solve 0.4118    add 0.0233    
Accumulated time: pickout 0.1541    decision 10.7572    set_bounds 0.9038    solve 24.9321    add 3.1730    
Current (lb-rhs): -253.54486083984375
15352 domains visited
Cumulative time: 39.960328102111816

BaB round 65
batch: 128
Average branched neurons at iteration 65:  1.0000
splitting decisions: 
split level 0: [/9, 9957] [/9, 9458] [/9, 8602] [/9, 8232] [/9, 11510] [/9, 8249] [/9, 9458] [/9, 8469] [/9, 1601] [/9, 11749] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0185    bound 0.3712    transfer 0.0037    finalize 0.0137    func 0.4071    
Accumulated time: func 25.3342    prepare 1.1736    bound 22.9931    transfer 0.2350    finalize 0.9456    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7808
Time: pickout 0.0028    decision 0.1775    set_bounds 0.0150    solve 0.4072    add 0.0256    
Accumulated time: pickout 0.1569    decision 10.9347    set_bounds 0.9188    solve 25.3394    add 3.1986    
Current (lb-rhs): -253.54486083984375
15608 domains visited
Cumulative time: 40.58907699584961

BaB round 66
batch: 128
Average branched neurons at iteration 66:  1.0000
splitting decisions: 
split level 0: [/9, 9992] [/9, 8602] [/9, 8148] [/9, 11398] [/9, 4606] [/9, 4606] [/9, 4549] [/9, 1601] [/9, 8602] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.222724914550781e-05
Time: prepare 0.0186    bound 0.3711    transfer 0.0037    finalize 0.0138    func 0.4072    
Accumulated time: func 25.7414    prepare 1.1925    bound 23.3642    transfer 0.2387    finalize 0.9594    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 7936
Time: pickout 0.0030    decision 0.1768    set_bounds 0.0149    solve 0.4073    add 0.0265    
Accumulated time: pickout 0.1599    decision 11.1115    set_bounds 0.9337    solve 25.7466    add 3.2251    
Current (lb-rhs): -253.54486083984375
15864 domains visited
Cumulative time: 41.21829128265381

BaB round 67
batch: 128
Average branched neurons at iteration 67:  1.0000
splitting decisions: 
split level 0: [/13, 4161] [/9, 8469] [/9, 8615] [/9, 4508] [/9, 1601] [/13, 124] [/9, 9992] [/9, 9957] [/9, 9458] [/9, 1601] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0186    bound 0.3732    transfer 0.0037    finalize 0.0138    func 0.4093    
Accumulated time: func 26.1507    prepare 1.2114    bound 23.7373    transfer 0.2424    finalize 0.9732    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 8064
Time: pickout 0.0029    decision 0.1770    set_bounds 0.0149    solve 0.4094    add 0.0272    
Accumulated time: pickout 0.1628    decision 11.2885    set_bounds 0.9486    solve 26.1561    add 3.2523    
Current (lb-rhs): -253.54486083984375
16120 domains visited
Cumulative time: 41.85039710998535

BaB round 68
batch: 128
Average branched neurons at iteration 68:  1.0000
splitting decisions: 
split level 0: [/9, 4053] [/9, 8615] [/13, 4161] [/9, 1576] [/9, 9642] [/9, 3954] [/9, 8602] [/9, 8602] [/13, 444] [/9, 9458] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0193    bound 0.3709    transfer 0.0037    finalize 0.0137    func 0.4077    
Accumulated time: func 26.5584    prepare 1.2310    bound 24.1082    transfer 0.2461    finalize 0.9869    
Current worst splitting domains lb-rhs (depth):
-253.54486 (8), -253.53654 (8), -253.49442 (8), -253.48592 (8), -253.48532 (8), -253.43634 (8), -253.43633 (8), -253.42839 (8), -253.42603 (8), -253.42542 (8), -253.41768 (8), -253.41373 (8), -253.40521 (8), -253.39384 (8), -253.39374 (8), -253.39372 (8), -253.38843 (8), -253.38635 (8), -253.38634 (8), -253.38562 (8), 
length of domains: 8192
Time: pickout 0.0028    decision 0.1770    set_bounds 0.0149    solve 0.4078    add 0.0261    
Accumulated time: pickout 0.1656    decision 11.4656    set_bounds 0.9635    solve 26.5639    add 3.2784    
Current (lb-rhs): -253.54486083984375
16376 domains visited
Cumulative time: 42.47979521751404

BaB round 69
batch: 128
Average branched neurons at iteration 69:  1.0000
splitting decisions: 
split level 0: [/9, 1601] [/9, 9992] [/9, 4549] [/9, 9957] [/9, 11398] [/13, 465] [/13, 4161] [/9, 9992] [/13, 121] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 9.417533874511719e-05
Time: prepare 0.0196    bound 0.3721    transfer 0.0048    finalize 0.0159    func 0.4791    
Accumulated time: func 27.0375    prepare 1.2509    bound 24.4804    transfer 0.2509    finalize 1.0028    
Killed
exit code: 138
head: cannot open 'out.txt' for reading: No such file or directory

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example --bound_prop_method crown --apply_output_constraints_to
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:22:32 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.8863s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.18s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.08000000e+02,  5.18000000e+02,  8.64000000e+02,  7.70000000e+02,
           7.88000000e+02,  9.18000000e+02,  9.40000000e+01,  7.04000000e+02,
           5.42000000e+02,  8.44000000e+02,  7.02000000e+02,  1.15600000e+03,
           3.28000000e+02,  7.96000000e+02, -1.15000000e+03,  7.84000000e+02,
           5.06000000e+02, -5.50000000e+02,  1.90000000e+02,  1.41200000e+03,
           3.00000000e+02,  1.12000000e+02, -2.00000000e+00,  2.64000000e+02,
           3.00000000e+02,  3.68000000e+02,  5.12000000e+02,  4.36000000e+02,
           7.60000000e+02,  3.70000000e+02,  7.68000000e+02,  5.66000000e+02,
          -1.92000000e+02,  3.05800000e+03,  7.04000000e+02,  1.66200000e+03,
           7.46000000e+02,  3.84000000e+02,  5.64000000e+02,  1.25800000e+03,
           4.94000000e+02, -6.60000000e+01, -2.68000000e+02],
         [ 1.08000000e+02,  5.18000000e+02,  8.64000000e+02,  7.70000000e+02,
           7.88000000e+02,  9.18000000e+02,  9.40000000e+01,  7.04000000e+02,
           5.42000000e+02,  8.44000000e+02,  7.02000000e+02,  1.15600000e+03,
           3.28000000e+02,  7.96000000e+02, -1.15000000e+03,  7.84000000e+02,
           5.06000000e+02, -5.50000000e+02,  1.90000000e+02,  1.41200000e+03,
           3.00000000e+02,  1.12000000e+02, -2.00000000e+00,  2.64000000e+02,
           3.00000000e+02,  3.68000000e+02,  5.12000000e+02,  4.36000000e+02,
           7.60000000e+02,  3.70000000e+02,  7.68000000e+02,  5.66000000e+02,
          -1.92000000e+02,  3.05800000e+03,  7.04000000e+02,  1.66200000e+03,
           7.46000000e+02,  3.84000000e+02,  5.64000000e+02,  1.25800000e+03,
           4.94000000e+02, -6.60000000e+01, -2.68000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2950., 2540., 2194., 2288., 2270., 2140., 2964., 2354., 2516., 2214.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1946 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   72.,   478.,   904.,   778.,   748.,   830.,   146.,   776.,
            534.,   908.,   678.,  1224.,   412.,   752., -1162.,   788.,
            454.,  -598.,   198.,  1404.,   276.,    96.,   -22.,   380.,
            356.,   344.,   468.,   416.,   788.,   322.,   836.,   614.,
           -212.,  3214.,   728.,  1490.,   682.,   368.,   524.,  1186.,
            642.,  -190.,  -184.],
         [   72.,   478.,   904.,   778.,   748.,   830.,   146.,   776.,
            534.,   908.,   678.,  1224.,   412.,   752., -1162.,   788.,
            454.,  -598.,   198.,  1404.,   276.,    96.,   -22.,   380.,
            356.,   344.,   468.,   416.,   788.,   322.,   836.,   614.,
           -212.,  3214.,   728.,  1490.,   682.,   368.,   524.,  1186.,
            642.,  -190.,  -184.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2736., 2310., 2436., 2466., 2384., 3068., 2438., 2680., 2306.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0338 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.04s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  172.,   506.,   904.,   798.,   788.,   886.,   110.,   788.,
            538.,   936.,   686.,  1232.,   440.,   804., -1166.,   800.,
            518.,  -574.,   110.,  1340.,   268.,    48.,   -66.,   352.,
            288.,   280.,   576.,   440.,   792.,   314.,   836.,   546.,
           -224.,  3030.,   764.,  1622.,   678.,   384.,   516.,  1210.,
            538.,   -58.,  -240.],
         [  172.,   506.,   904.,   798.,   788.,   886.,   110.,   788.,
            538.,   936.,   686.,  1232.,   440.,   804., -1166.,   800.,
            518.,  -574.,   110.,  1340.,   268.,    48.,   -66.,   352.,
            288.,   280.,   576.,   440.,   792.,   314.,   836.,   546.,
           -224.,  3030.,   764.,  1622.,   678.,   384.,   516.,  1210.,
            538.,   -58.,  -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2858., 2524., 2126., 2232., 2242., 2144., 2920., 2242., 2492., 2094.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0433 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.95s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   480.,   886.,   764.,   842.,   828.,   144.,   734.,
            524.,   910.,   684.,  1230.,   422.,   706., -1132.,   790.,
            420.,  -624.,   188.,  1402.,   202.,    94.,   -24.,   402.,
            310.,   370.,   462.,   430.,   794.,   280.,   798.,   608.,
           -178.,  3220.,   746.,  1492.,   640.,   386.,   538.,  1176.,
            648.,  -140.,  -254.],
         [   74.,   480.,   886.,   764.,   842.,   828.,   144.,   734.,
            524.,   910.,   684.,  1230.,   422.,   706., -1132.,   790.,
            420.,  -624.,   188.,  1402.,   202.,    94.,   -24.,   402.,
            310.,   370.,   462.,   430.,   794.,   280.,   798.,   608.,
           -178.,  3220.,   746.,  1492.,   640.,   386.,   538.,  1176.,
            648.,  -140.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3146., 2740., 2334., 2456., 2378., 2392., 3076., 2486., 2696., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9582 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  198.,   496.,   834.,   832.,   806.,   916.,   116.,   670.,
            564.,   902.,   696.,  1146.,   406.,   826., -1116.,   806.,
            528.,  -556.,   124.,  1382.,   266.,    38.,    24.,   318.,
            282.,   378.,   534.,   442.,   790.,   380.,   822.,   492.,
           -182.,  3040.,   770.,  1632.,   692.,   374.,   522.,  1212.,
            544.,   -76.,  -246.],
         [  198.,   496.,   834.,   832.,   806.,   916.,   116.,   670.,
            564.,   902.,   696.,  1146.,   406.,   826., -1116.,   806.,
            528.,  -556.,   124.,  1382.,   266.,    38.,    24.,   318.,
            282.,   378.,   534.,   442.,   790.,   380.,   822.,   492.,
           -182.,  3040.,   770.,  1632.,   692.,   374.,   522.,  1212.,
            544.,   -76.,  -246.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2842., 2544., 2206., 2208., 2234., 2124., 2924., 2370., 2476., 2138.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0631 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.20s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   470.,   892.,   770.,   820.,   818.,   150.,   772.,
            514.,   888.,   694.,  1236.,   432.,   728., -1146.,   824.,
            454.,  -594.,   166.,  1352.,   212.,   100.,   -14.,   384.,
            336.,   328.,   484.,   400.,   788.,   250.,   788.,   566.,
           -200.,  3254.,   728.,  1534.,   690.,   392.,   496.,  1206.,
            654.,  -166.,  -264.],
         [   88.,   470.,   892.,   770.,   820.,   818.,   150.,   772.,
            514.,   888.,   694.,  1236.,   432.,   728., -1146.,   824.,
            454.,  -594.,   166.,  1352.,   212.,   100.,   -14.,   384.,
            336.,   328.,   484.,   400.,   788.,   250.,   788.,   566.,
           -200.,  3254.,   728.,  1534.,   690.,   392.,   496.,  1206.,
            654.,  -166.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2784., 2362., 2484., 2434., 2436., 3104., 2482., 2740., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2162 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  164.,   510.,   888.,   838.,   820.,   918.,    70.,   672.,
            534.,   844.,   650.,  1124.,   320.,   864., -1186.,   752.,
            518.,  -506.,   174.,  1412.,   220.,    36.,   -10.,   284.,
            296.,   356.,   528.,   420.,   800.,   346.,   764.,   550.,
           -228.,  3062.,   716.,  1658.,   738.,   376.,   548.,  1230.,
            506.,   -90.,  -276.],
         [  164.,   510.,   888.,   838.,   820.,   918.,    70.,   672.,
            534.,   844.,   650.,  1124.,   320.,   864., -1186.,   752.,
            518.,  -506.,   174.,  1412.,   220.,    36.,   -10.,   284.,
            296.,   356.,   528.,   420.,   800.,   346.,   764.,   550.,
           -228.,  3062.,   716.,  1658.,   738.,   376.,   548.,  1230.,
            506.,   -90.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2552., 2174., 2224., 2242., 2144., 2992., 2390., 2528., 2218.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0693 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.26s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 7.20000000e+01,  4.70000000e+02,  9.00000000e+02,  8.10000000e+02,
           8.32000000e+02,  8.10000000e+02,  1.50000000e+02,  7.68000000e+02,
           4.94000000e+02,  8.96000000e+02,  7.54000000e+02,  1.22400000e+03,
           4.20000000e+02,  7.40000000e+02, -1.11800000e+03,  8.28000000e+02,
           4.46000000e+02, -6.06000000e+02,  2.18000000e+02,  1.38800000e+03,
           2.12000000e+02,  7.60000000e+01,  2.00000000e+00,  3.52000000e+02,
           3.36000000e+02,  3.36000000e+02,  4.56000000e+02,  3.80000000e+02,
           8.00000000e+02,  2.46000000e+02,  8.08000000e+02,  6.26000000e+02,
          -2.12000000e+02,  3.24600000e+03,  7.32000000e+02,  1.50200000e+03,
           6.66000000e+02,  3.68000000e+02,  5.08000000e+02,  1.21800000e+03,
           6.66000000e+02, -1.90000000e+02, -2.28000000e+02],
         [ 7.20000000e+01,  4.70000000e+02,  9.00000000e+02,  8.10000000e+02,
           8.32000000e+02,  8.10000000e+02,  1.50000000e+02,  7.68000000e+02,
           4.94000000e+02,  8.96000000e+02,  7.54000000e+02,  1.22400000e+03,
           4.20000000e+02,  7.40000000e+02, -1.11800000e+03,  8.28000000e+02,
           4.46000000e+02, -6.06000000e+02,  2.18000000e+02,  1.38800000e+03,
           2.12000000e+02,  7.60000000e+01,  2.00000000e+00,  3.52000000e+02,
           3.36000000e+02,  3.36000000e+02,  4.56000000e+02,  3.80000000e+02,
           8.00000000e+02,  2.46000000e+02,  8.08000000e+02,  6.26000000e+02,
          -2.12000000e+02,  3.24600000e+03,  7.32000000e+02,  1.50200000e+03,
           6.66000000e+02,  3.68000000e+02,  5.08000000e+02,  1.21800000e+03,
           6.66000000e+02, -1.90000000e+02, -2.28000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3174., 2776., 2346., 2436., 2414., 2436., 3096., 2478., 2752., 2350.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2646 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.16s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   566.,   916.,   802.,   840.,   886.,   126.,   716.,
            522.,   896.,   614.,  1172.,   428.,   820., -1186.,   756.,
            522.,  -546.,    78.,  1392.,   280.,   116.,    14.,   280.,
            344.,   376.,   496.,   448.,   780.,   294.,   772.,   518.,
           -212.,  3054.,   700.,  1666.,   682.,   344.,   532.,  1214.,
            570.,   -94.,  -268.],
         [  156.,   566.,   916.,   802.,   840.,   886.,   126.,   716.,
            522.,   896.,   614.,  1172.,   428.,   820., -1186.,   756.,
            522.,  -546.,    78.,  1392.,   280.,   116.,    14.,   280.,
            344.,   376.,   496.,   448.,   780.,   294.,   772.,   518.,
           -212.,  3054.,   700.,  1666.,   682.,   344.,   532.,  1214.,
            570.,   -94.,  -268.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2488., 2138., 2252., 2214., 2168., 2928., 2338., 2532., 2158.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1699 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.20s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   72.,   466.,   920.,   798.,   792.,   858.,   118.,   740.,
            582.,   876.,   726.,  1176.,   364.,   756., -1130.,   756.,
            470.,  -634.,   178.,  1368.,   248.,   140.,     6.,   364.,
            344.,   380.,   516.,   448.,   752.,   278.,   796.,   562.,
           -152.,  3218.,   756.,  1518.,   634.,   396.,   516.,  1242.,
            614.,  -154.,  -236.],
         [   72.,   466.,   920.,   798.,   792.,   858.,   118.,   740.,
            582.,   876.,   726.,  1176.,   364.,   756., -1130.,   756.,
            470.,  -634.,   178.,  1368.,   248.,   140.,     6.,   364.,
            344.,   380.,   516.,   448.,   752.,   278.,   796.,   562.,
           -152.,  3218.,   756.,  1518.,   634.,   396.,   516.,  1242.,
            614.,  -154.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3146., 2752., 2298., 2420., 2426., 2360., 3100., 2478., 2636., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2085 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  164.,   506.,   892.,   818.,   784.,   894.,    70.,   720.,
            518.,   848.,   630.,  1144.,   356.,   884., -1126.,   816.,
            522.,  -542.,   126.,  1428.,   308.,    76.,   -58.,   280.,
            304.,   368.,   552.,   432.,   756.,   358.,   800.,   542.,
           -196.,  3042.,   704.,  1658.,   694.,   372.,   484.,  1262.,
            542.,   -78.,  -240.],
         [  164.,   506.,   892.,   818.,   784.,   894.,    70.,   720.,
            518.,   848.,   630.,  1144.,   356.,   884., -1126.,   816.,
            522.,  -542.,   126.,  1428.,   308.,    76.,   -58.,   280.,
            304.,   368.,   552.,   432.,   756.,   358.,   800.,   542.,
           -196.,  3042.,   704.,  1658.,   694.,   372.,   484.,  1262.,
            542.,   -78.,  -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2878., 2536., 2150., 2224., 2258., 2148., 2972., 2322., 2524., 2194.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0705 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   450.,   908.,   750.,   776.,   870.,   134.,   788.,
            526.,   892.,   694.,  1204.,   344.,   736., -1086.,   768.,
            510.,  -638.,   182.,  1396.,   308.,    88.,   -42.,   404.,
            304.,   328.,   500.,   468.,   740.,   298.,   812.,   622.,
           -208.,  3246.,   680.,  1502.,   658.,   372.,   504.,  1218.,
            598.,  -142.,  -216.],
         [   60.,   450.,   908.,   750.,   776.,   870.,   134.,   788.,
            526.,   892.,   694.,  1204.,   344.,   736., -1086.,   768.,
            510.,  -638.,   182.,  1396.,   308.,    88.,   -42.,   404.,
            304.,   328.,   500.,   468.,   740.,   298.,   812.,   622.,
           -208.,  3246.,   680.,  1502.,   658.,   372.,   504.,  1218.,
            598.,  -142.,  -216.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3186., 2796., 2338., 2496., 2470., 2376., 3112., 2458., 2720., 2354.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0389 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   476.,   918.,   792.,   802.,   896.,   120.,   778.,
            548.,   882.,   692.,  1254.,   410.,   790., -1200.,   814.,
            544.,  -620.,   116.,  1398.,   334.,    90.,   -20.,   378.,
            290.,   302.,   558.,   490.,   754.,   308.,   726.,   560.,
           -182.,  3048.,   702.,  1660.,   728.,   334.,   546.,  1220.,
            580.,   -36.,  -230.],
         [  102.,   476.,   918.,   792.,   802.,   896.,   120.,   778.,
            548.,   882.,   692.,  1254.,   410.,   790., -1200.,   814.,
            544.,  -620.,   116.,  1398.,   334.,    90.,   -20.,   378.,
            290.,   302.,   558.,   490.,   754.,   308.,   726.,   560.,
           -182.,  3048.,   702.,  1660.,   728.,   334.,   546.,  1220.,
            580.,   -36.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2946., 2572., 2130., 2256., 2246., 2152., 2928., 2270., 2500., 2166.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9708 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   62.,   484.,   898.,   728.,   806.,   824.,   100.,   726.,
            488.,   862.,   712.,  1254.,   410.,   714., -1184.,   810.,
            456.,  -600.,   184.,  1402.,   278.,   106.,   -36.,   350.,
            346.,   358.,   482.,   402.,   814.,   228.,   826.,   588.,
           -194.,  3228.,   726.,  1508.,   684.,   382.,   494.,  1184.,
            680.,  -172.,  -234.],
         [   62.,   484.,   898.,   728.,   806.,   824.,   100.,   726.,
            488.,   862.,   712.,  1254.,   410.,   714., -1184.,   810.,
            456.,  -600.,   184.,  1402.,   278.,   106.,   -36.,   350.,
            346.,   358.,   482.,   402.,   814.,   228.,   826.,   588.,
           -194.,  3228.,   726.,  1508.,   684.,   382.,   494.,  1184.,
            680.,  -172.,  -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2744., 2330., 2500., 2422., 2404., 3128., 2502., 2740., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1150 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   498.,   944.,   762.,   804.,   954.,   154.,   740.,
            550.,   872.,   738.,  1228.,   456.,   780., -1130.,   764.,
            514.,  -638.,   146.,  1336.,   304.,    92.,   -54.,   388.,
            248.,   324.,   572.,   468.,   760.,   338.,   788.,   562.,
           -172.,  3026.,   732.,  1610.,   650.,   332.,   544.,  1194.,
            558.,   -58.,  -196.],
         [   88.,   498.,   944.,   762.,   804.,   954.,   154.,   740.,
            550.,   872.,   738.,  1228.,   456.,   780., -1130.,   764.,
            514.,  -638.,   146.,  1336.,   304.,    92.,   -54.,   388.,
            248.,   324.,   572.,   468.,   760.,   338.,   788.,   562.,
           -172.,  3026.,   732.,  1610.,   650.,   332.,   544.,  1194.,
            558.,   -58.,  -196.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2938., 2528., 2082., 2264., 2222., 2072., 2872., 2286., 2476., 2154.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0244 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   96.,   478.,   884.,   770.,   872.,   818.,   102.,   700.,
            518.,   876.,   766.,  1160.,   396.,   708., -1114.,   788.,
            418.,  -614.,   194.,  1380.,   264.,   140.,   -34.,   376.,
            340.,   332.,   472.,   428.,   760.,   238.,   804.,   590.,
           -192.,  3238.,   752.,  1498.,   658.,   372.,   496.,  1182.,
            642.,  -146.,  -220.],
         [   96.,   478.,   884.,   770.,   872.,   818.,   102.,   700.,
            518.,   876.,   766.,  1160.,   396.,   708., -1114.,   788.,
            418.,  -614.,   194.,  1380.,   264.,   140.,   -34.,   376.,
            340.,   332.,   472.,   428.,   760.,   238.,   804.,   590.,
           -192.,  3238.,   752.,  1498.,   658.,   372.,   496.,  1182.,
            642.,  -146.,  -220.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2760., 2354., 2468., 2366., 2420., 3136., 2538., 2720., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0156 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   506.,   876.,   850.,   804.,   922.,    86.,   780.,
            586.,   884.,   706.,  1148.,   400.,   864., -1150.,   784.,
            518.,  -586.,   158.,  1312.,   292.,    60.,   -14.,   304.,
            264.,   348.,   528.,   472.,   760.,   406.,   824.,   598.,
           -200.,  3010.,   736.,  1618.,   610.,   336.,   540.,  1210.,
            498.,   -98.,  -264.],
         [   88.,   506.,   876.,   850.,   804.,   922.,    86.,   780.,
            586.,   884.,   706.,  1148.,   400.,   864., -1150.,   784.,
            518.,  -586.,   158.,  1312.,   292.,    60.,   -14.,   304.,
            264.,   348.,   528.,   472.,   760.,   406.,   824.,   598.,
           -200.,  3010.,   736.,  1618.,   610.,   336.,   540.,  1210.,
            498.,   -98.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2922., 2504., 2134., 2160., 2206., 2088., 2924., 2230., 2424., 2126.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0291 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   22.,   440.,   914.,   772.,   854.,   808.,   112.,   770.,
            576.,   850.,   732.,  1186.,   358.,   710., -1132.,   750.,
            424.,  -588.,   212.,  1414.,   274.,    86.,   -24.,   382.,
            330.,   326.,   494.,   438.,   814.,   336.,   818.,   644.,
           -182.,  3212.,   694.,  1500.,   676.,   378.,   482.,  1224.,
            608.,  -192.,  -230.],
         [   22.,   440.,   914.,   772.,   854.,   808.,   112.,   770.,
            576.,   850.,   732.,  1186.,   358.,   710., -1132.,   750.,
            424.,  -588.,   212.,  1414.,   274.,    86.,   -24.,   382.,
            330.,   326.,   494.,   438.,   814.,   336.,   818.,   644.,
           -182.,  3212.,   694.,  1500.,   676.,   378.,   482.,  1224.,
            608.,  -192.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3190., 2772., 2298., 2440., 2358., 2404., 3100., 2442., 2636., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0107 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   92.,   502.,   876.,   770.,   792.,   926.,   106.,   764.,
            574.,   880.,   706.,  1180.,   460.,   772., -1154.,   776.,
            586.,  -574.,   154.,  1380.,   364.,    92.,    -6.,   356.,
            276.,   316.,   548.,   520.,   756.,   346.,   776.,   586.,
           -188.,  3014.,   732.,  1626.,   710.,   352.,   536.,  1250.,
            506.,   -26.,  -248.],
         [   92.,   502.,   876.,   770.,   792.,   926.,   106.,   764.,
            574.,   880.,   706.,  1180.,   460.,   772., -1154.,   776.,
            586.,  -574.,   154.,  1380.,   364.,    92.,    -6.,   356.,
            276.,   316.,   548.,   520.,   756.,   346.,   776.,   586.,
           -188.,  3014.,   732.,  1626.,   710.,   352.,   536.,  1250.,
            506.,   -26.,  -248.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2922., 2512., 2138., 2244., 2222., 2088., 2908., 2250., 2440., 2134.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0205 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   462.,   944.,   750.,   828.,   866.,   162.,   792.,
            522.,   892.,   722.,  1200.,   408.,   692., -1130.,   784.,
            438.,  -570.,   146.,  1376.,   260.,   128.,   -14.,   356.,
            312.,   336.,   528.,   392.,   792.,   302.,   836.,   582.,
           -240.,  3254.,   672.,  1518.,   674.,   328.,   484.,  1186.,
            606.,  -138.,  -248.],
         [   88.,   462.,   944.,   750.,   828.,   866.,   162.,   792.,
            522.,   892.,   722.,  1200.,   408.,   692., -1130.,   784.,
            438.,  -570.,   146.,  1376.,   260.,   128.,   -14.,   356.,
            312.,   336.,   528.,   392.,   792.,   302.,   836.,   582.,
           -240.,  3254.,   672.,  1518.,   674.,   328.,   484.,  1186.,
            606.,  -138.,  -248.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3166., 2792., 2310., 2504., 2426., 2388., 3092., 2462., 2732., 2362.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9752 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  128.,   498.,   872.,   790.,   804.,   918.,    94.,   712.,
            558.,   864.,   694.,  1136.,   352.,   840., -1158.,   752.,
            542.,  -530.,   182.,  1396.,   308.,    80.,   -26.,   276.,
            352.,   388.,   536.,   420.,   784.,   338.,   792.,   534.,
           -180.,  3058.,   700.,  1654.,   690.,   376.,   508.,  1258.,
            538.,   -58.,  -228.],
         [  128.,   498.,   872.,   790.,   804.,   918.,    94.,   712.,
            558.,   864.,   694.,  1136.,   352.,   840., -1158.,   752.,
            542.,  -530.,   182.,  1396.,   308.,    80.,   -26.,   276.,
            352.,   388.,   536.,   420.,   784.,   338.,   792.,   534.,
           -180.,  3058.,   700.,  1654.,   690.,   376.,   508.,  1258.,
            538.,   -58.,  -228.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2930., 2560., 2186., 2268., 2254., 2140., 2964., 2346., 2500., 2194.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9622 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   436.,   874.,   776.,   830.,   844.,   148.,   746.,
            516.,   878.,   720.,  1230.,   430.,   626., -1112.,   790.,
            532.,  -624.,   160.,  1398.,   290.,   146.,   -44.,   346.,
            326.,   350.,   466.,   430.,   766.,   252.,   786.,   596.,
           -254.,  3244.,   746.,  1532.,   608.,   370.,   466.,  1212.,
            640.,  -100.,  -242.],
         [   74.,   436.,   874.,   776.,   830.,   844.,   148.,   746.,
            516.,   878.,   720.,  1230.,   430.,   626., -1112.,   790.,
            532.,  -624.,   160.,  1398.,   290.,   146.,   -44.,   346.,
            326.,   350.,   466.,   430.,   766.,   252.,   786.,   596.,
           -254.,  3244.,   746.,  1532.,   608.,   370.,   466.,  1212.,
            640.,  -100.,  -242.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3170., 2808., 2370., 2468., 2414., 2400., 3096., 2498., 2728., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9936 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  128.,   502.,   900.,   814.,   828.,   866.,    70.,   748.,
            506.,   848.,   666.,  1104.,   320.,   868., -1138.,   784.,
            558.,  -558.,   142.,  1404.,   320.,   108.,    14.,   336.,
            304.,   396.,   516.,   520.,   752.,   362.,   744.,   554.,
           -220.,  3054.,   680.,  1670.,   690.,   368.,   508.,  1238.,
            498.,   -42.,  -236.],
         [  128.,   502.,   900.,   814.,   828.,   866.,    70.,   748.,
            506.,   848.,   666.,  1104.,   320.,   868., -1138.,   784.,
            558.,  -558.,   142.,  1404.,   320.,   108.,    14.,   336.,
            304.,   396.,   516.,   520.,   752.,   362.,   744.,   554.,
           -220.,  3054.,   680.,  1670.,   690.,   368.,   508.,  1238.,
            498.,   -42.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2552., 2154., 2240., 2226., 2188., 2984., 2306., 2548., 2206.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0309 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   482.,   848.,   790.,   828.,   846.,   134.,   740.,
            506.,   836.,   702.,  1184.,   400.,   740., -1058.,   848.,
            462.,  -614.,   250.,  1396.,   212.,   124.,   -18.,   356.,
            296.,   376.,   504.,   344.,   788.,   262.,   824.,   574.,
           -168.,  3222.,   724.,  1506.,   646.,   364.,   500.,  1262.,
            638.,  -146.,  -256.],
         [   60.,   482.,   848.,   790.,   828.,   846.,   134.,   740.,
            506.,   836.,   702.,  1184.,   400.,   740., -1058.,   848.,
            462.,  -614.,   250.,  1396.,   212.,   124.,   -18.,   356.,
            296.,   376.,   504.,   344.,   788.,   262.,   824.,   574.,
           -168.,  3222.,   724.,  1506.,   646.,   364.,   500.,  1262.,
            638.,  -146.,  -256.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3162., 2740., 2374., 2432., 2394., 2376., 3088., 2482., 2716., 2386.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9880 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  140.,   478.,   900.,   810.,   796.,   930.,   150.,   724.,
            558.,   876.,   642.,  1132.,   344.,   792., -1138.,   744.,
            562.,  -558.,   142.,  1400.,   304.,    88.,    42.,   284.,
            324.,   356.,   560.,   408.,   768.,   334.,   760.,   566.,
           -204.,  3066.,   640.,  1658.,   734.,   316.,   528.,  1174.,
            542.,   -70.,  -320.],
         [  140.,   478.,   900.,   810.,   796.,   930.,   150.,   724.,
            558.,   876.,   642.,  1132.,   344.,   792., -1138.,   744.,
            562.,  -558.,   142.,  1400.,   304.,    88.,    42.,   284.,
            324.,   356.,   560.,   408.,   768.,   334.,   760.,   566.,
           -204.,  3066.,   640.,  1658.,   734.,   316.,   528.,  1174.,
            542.,   -70.,  -320.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2588., 2166., 2256., 2270., 2136., 2916., 2342., 2508., 2190.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1214 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   60.,   454.,   916.,   798.,   800.,   838.,   146.,   760.,
            494.,   844.,   682.,  1196.,   400.,   724., -1158.,   772.,
            430.,  -574.,   166.,  1424.,   228.,    80.,    -6.,   364.,
            328.,   328.,   476.,   432.,   816.,   306.,   828.,   606.,
           -228.,  3242.,   708.,  1522.,   690.,   376.,   504.,  1194.,
            666.,  -166.,  -200.],
         [   60.,   454.,   916.,   798.,   800.,   838.,   146.,   760.,
            494.,   844.,   682.,  1196.,   400.,   724., -1158.,   772.,
            430.,  -574.,   166.,  1424.,   228.,    80.,    -6.,   364.,
            328.,   328.,   476.,   432.,   816.,   306.,   828.,   606.,
           -228.,  3242.,   708.,  1522.,   690.,   376.,   504.,  1194.,
            666.,  -166.,  -200.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3182., 2788., 2326., 2444., 2442., 2404., 3096., 2482., 2748., 2398.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9881 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.40000000e+02,  4.70000000e+02,  8.88000000e+02,  7.86000000e+02,
           8.08000000e+02,  9.42000000e+02,  1.42000000e+02,  6.68000000e+02,
           5.62000000e+02,  8.44000000e+02,  6.42000000e+02,  1.16400000e+03,
           3.00000000e+02,  8.60000000e+02, -1.09800000e+03,  7.72000000e+02,
           5.34000000e+02, -5.50000000e+02,  1.54000000e+02,  1.37200000e+03,
           2.24000000e+02,  5.20000000e+01,  2.00000000e+00,  3.16000000e+02,
           3.44000000e+02,  3.56000000e+02,  5.48000000e+02,  4.20000000e+02,
           7.28000000e+02,  3.14000000e+02,  8.20000000e+02,  5.54000000e+02,
          -2.24000000e+02,  3.04200000e+03,  6.28000000e+02,  1.66600000e+03,
           7.18000000e+02,  3.40000000e+02,  4.84000000e+02,  1.21400000e+03,
           5.42000000e+02, -1.40000000e+01, -2.68000000e+02],
         [ 1.40000000e+02,  4.70000000e+02,  8.88000000e+02,  7.86000000e+02,
           8.08000000e+02,  9.42000000e+02,  1.42000000e+02,  6.68000000e+02,
           5.62000000e+02,  8.44000000e+02,  6.42000000e+02,  1.16400000e+03,
           3.00000000e+02,  8.60000000e+02, -1.09800000e+03,  7.72000000e+02,
           5.34000000e+02, -5.50000000e+02,  1.54000000e+02,  1.37200000e+03,
           2.24000000e+02,  5.20000000e+01,  2.00000000e+00,  3.16000000e+02,
           3.44000000e+02,  3.56000000e+02,  5.48000000e+02,  4.20000000e+02,
           7.28000000e+02,  3.14000000e+02,  8.20000000e+02,  5.54000000e+02,
          -2.24000000e+02,  3.04200000e+03,  6.28000000e+02,  1.66600000e+03,
           7.18000000e+02,  3.40000000e+02,  4.84000000e+02,  1.21400000e+03,
           5.42000000e+02, -1.40000000e+01, -2.68000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2902., 2572., 2154., 2256., 2234., 2100., 2900., 2374., 2480., 2198.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0022 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   68.,   486.,   888.,   794.,   824.,   822.,   102.,   740.,
            486.,   888.,   698.,  1228.,   388.,   708., -1170.,   836.,
            422.,  -570.,   182.,  1396.,   256.,    64.,    -6.,   352.,
            328.,   316.,   472.,   392.,   788.,   262.,   828.,   578.,
           -216.,  3198.,   736.,  1502.,   710.,   368.,   508.,  1178.,
            642.,  -170.,  -228.],
         [   68.,   486.,   888.,   794.,   824.,   822.,   102.,   740.,
            486.,   888.,   698.,  1228.,   388.,   708., -1170.,   836.,
            422.,  -570.,   182.,  1396.,   256.,    64.,    -6.,   352.,
            328.,   316.,   472.,   392.,   788.,   262.,   828.,   578.,
           -216.,  3198.,   736.,  1502.,   710.,   368.,   508.,  1178.,
            642.,  -170.,  -228.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3130., 2712., 2310., 2404., 2374., 2376., 3096., 2458., 2712., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0790 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 1.16000000e+02,  4.78000000e+02,  9.24000000e+02,  7.90000000e+02,
           8.36000000e+02,  9.18000000e+02,  8.20000000e+01,  7.84000000e+02,
           5.78000000e+02,  8.92000000e+02,  6.70000000e+02,  1.18800000e+03,
           3.84000000e+02,  8.28000000e+02, -1.14600000e+03,  7.80000000e+02,
           5.54000000e+02, -5.70000000e+02,  1.62000000e+02,  1.31600000e+03,
           2.76000000e+02,  6.00000000e+01,  2.00000000e+00,  3.28000000e+02,
           2.80000000e+02,  3.28000000e+02,  6.00000000e+02,  4.04000000e+02,
           8.04000000e+02,  3.46000000e+02,  8.44000000e+02,  5.66000000e+02,
          -2.28000000e+02,  3.00200000e+03,  6.72000000e+02,  1.65400000e+03,
           6.50000000e+02,  3.36000000e+02,  5.24000000e+02,  1.21400000e+03,
           5.42000000e+02, -2.00000000e+00, -2.12000000e+02],
         [ 1.16000000e+02,  4.78000000e+02,  9.24000000e+02,  7.90000000e+02,
           8.36000000e+02,  9.18000000e+02,  8.20000000e+01,  7.84000000e+02,
           5.78000000e+02,  8.92000000e+02,  6.70000000e+02,  1.18800000e+03,
           3.84000000e+02,  8.28000000e+02, -1.14600000e+03,  7.80000000e+02,
           5.54000000e+02, -5.70000000e+02,  1.62000000e+02,  1.31600000e+03,
           2.76000000e+02,  6.00000000e+01,  2.00000000e+00,  3.28000000e+02,
           2.80000000e+02,  3.28000000e+02,  6.00000000e+02,  4.04000000e+02,
           8.04000000e+02,  3.46000000e+02,  8.44000000e+02,  5.66000000e+02,
          -2.28000000e+02,  3.00200000e+03,  6.72000000e+02,  1.65400000e+03,
           6.50000000e+02,  3.36000000e+02,  5.24000000e+02,  1.21400000e+03,
           5.42000000e+02, -2.00000000e+00, -2.12000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2886., 2524., 2078., 2212., 2166., 2084., 2920., 2218., 2424., 2110.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0104 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   96.,   430.,   948.,   794.,   804.,   854.,   102.,   744.,
            530.,   888.,   706.,  1224.,   336.,   696., -1158.,   772.,
            494.,  -634.,   170.,  1424.,   308.,   120.,   -30.,   384.,
            344.,   308.,   508.,   404.,   764.,   258.,   796.,   598.,
           -248.,  3226.,   704.,  1498.,   678.,   376.,   488.,  1198.,
            630.,  -178.,  -256.],
         [   96.,   430.,   948.,   794.,   804.,   854.,   102.,   744.,
            530.,   888.,   706.,  1224.,   336.,   696., -1158.,   772.,
            494.,  -634.,   170.,  1424.,   308.,   120.,   -30.,   384.,
            344.,   308.,   508.,   404.,   764.,   258.,   796.,   598.,
           -248.,  3226.,   704.,  1498.,   678.,   376.,   488.,  1198.,
            630.,  -178.,  -256.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3130., 2796., 2278., 2432., 2422., 2372., 3124., 2482., 2696., 2338.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9725 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  124.,   506.,   852.,   826.,   792.,   894.,   114.,   696.,
            582.,   936.,   674.,  1200.,   440.,   832., -1130.,   788.,
            514.,  -610.,   174.,  1344.,   280.,    28.,   -22.,   336.,
            244.,   320.,   544.,   448.,   812.,   390.,   772.,   558.,
           -176.,  3050.,   760.,  1650.,   710.,   380.,   568.,  1202.,
            530.,    -6.,  -264.],
         [  124.,   506.,   852.,   826.,   792.,   894.,   114.,   696.,
            582.,   936.,   674.,  1200.,   440.,   832., -1130.,   788.,
            514.,  -610.,   174.,  1344.,   280.,    28.,   -22.,   336.,
            244.,   320.,   544.,   448.,   812.,   390.,   772.,   558.,
           -176.,  3050.,   760.,  1650.,   710.,   380.,   568.,  1202.,
            530.,    -6.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2544., 2198., 2224., 2258., 2156., 2936., 2354., 2468., 2114.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9932 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   70.,   444.,   926.,   784.,   850.,   820.,   144.,   746.,
            524.,   854.,   728.,  1178.,   330.,   714., -1128.,   826.,
            440.,  -596.,   224.,  1350.,   262.,    94.,   -24.,   374.,
            354.,   374.,   474.,   394.,   774.,   280.,   766.,   580.,
           -206.,  3228.,   730.,  1500.,   716.,   394.,   518.,  1240.,
            628.,  -140.,  -250.],
         [   70.,   444.,   926.,   784.,   850.,   820.,   144.,   746.,
            524.,   854.,   728.,  1178.,   330.,   714., -1128.,   826.,
            440.,  -596.,   224.,  1350.,   262.,    94.,   -24.,   374.,
            354.,   374.,   474.,   394.,   774.,   280.,   766.,   580.,
           -206.,  3228.,   730.,  1500.,   716.,   394.,   518.,  1240.,
            628.,  -140.,  -250.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3158., 2784., 2302., 2444., 2378., 2408., 3084., 2482., 2704., 2374.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0274 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.19s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   454.,   892.,   854.,   816.,   934.,   134.,   700.,
            558.,   844.,   630.,  1192.,   344.,   828., -1138.,   740.,
            522.,  -566.,   134.,  1412.,   236.,    64.,    50.,   344.,
            304.,   364.,   568.,   436.,   780.,   334.,   772.,   570.,
           -224.,  3054.,   632.,  1650.,   718.,   348.,   536.,  1234.,
            578.,   -78.,  -276.],
         [  156.,   454.,   892.,   854.,   816.,   934.,   134.,   700.,
            558.,   844.,   630.,  1192.,   344.,   828., -1138.,   740.,
            522.,  -566.,   134.,  1412.,   236.,    64.,    50.,   344.,
            304.,   364.,   568.,   436.,   780.,   334.,   772.,   570.,
           -224.,  3054.,   632.,  1650.,   718.,   348.,   536.,  1234.,
            578.,   -78.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2898., 2600., 2162., 2200., 2238., 2120., 2920., 2354., 2496., 2210.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2012 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.24s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   480.,   882.,   760.,   762.,   864.,   132.,   774.,
            504.,   890.,   700.,  1226.,   430.,   678., -1124.,   742.,
            508.,  -608.,   136.,  1362.,   234.,    82.,   -72.,   286.,
            326.,   326.,   458.,   442.,   778.,   288.,   846.,   580.,
           -198.,  3256.,   694.,  1524.,   676.,   362.,   482.,  1156.,
            628.,  -144.,  -194.],
         [  102.,   480.,   882.,   760.,   762.,   864.,   132.,   774.,
            504.,   890.,   700.,  1226.,   430.,   678., -1124.,   742.,
            508.,  -608.,   136.,  1362.,   234.,    82.,   -72.,   286.,
            326.,   326.,   458.,   442.,   778.,   288.,   846.,   580.,
           -198.,  3256.,   694.,  1524.,   676.,   362.,   482.,  1156.,
            628.,  -144.,  -194.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3154., 2776., 2374., 2496., 2494., 2392., 3124., 2482., 2752., 2366.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2458 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.95s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  154.,   516.,   886.,   796.,   806.,   908.,    64.,   726.,
            552.,   886.,   624.,  1198.,   406.,   862., -1156.,   786.,
            504.,  -540.,   156.,  1362.,   254.,    42.,   -68.,   322.,
            286.,   330.,   570.,   426.,   802.,   356.,   806.,   544.,
           -230.,  3044.,   754.,  1648.,   652.,   398.,   498.,  1220.,
            540.,   -32.,  -266.],
         [  154.,   516.,   886.,   796.,   806.,   908.,    64.,   726.,
            552.,   886.,   624.,  1198.,   406.,   862., -1156.,   786.,
            504.,  -540.,   156.,  1362.,   254.,    42.,   -68.,   322.,
            286.,   330.,   570.,   426.,   802.,   356.,   806.,   544.,
           -230.,  3044.,   754.,  1648.,   652.,   398.,   498.,  1220.,
            540.,   -32.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2890., 2528., 2158., 2248., 2238., 2136., 2980., 2318., 2492., 2158.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9600 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   46.,   424.,   910.,   788.,   866.,   820.,   152.,   730.,
            500.,   878.,   744.,  1190.,   362.,   726., -1140.,   754.,
            424.,  -620.,   216.,  1382.,   262.,    82.,   -44.,   342.,
            298.,   330.,   466.,   438.,   834.,   300.,   790.,   620.,
           -174.,  3208.,   714.,  1472.,   660.,   402.,   530.,  1224.,
            592.,  -192.,  -190.],
         [   46.,   424.,   910.,   788.,   866.,   820.,   152.,   730.,
            500.,   878.,   744.,  1190.,   362.,   726., -1140.,   754.,
            424.,  -620.,   216.,  1382.,   262.,    82.,   -44.,   342.,
            298.,   330.,   466.,   438.,   834.,   300.,   790.,   620.,
           -174.,  3208.,   714.,  1472.,   660.,   402.,   530.,  1224.,
            592.,  -192.,  -190.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3162., 2784., 2298., 2420., 2342., 2388., 3056., 2478., 2708., 2330.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9993 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.12s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  156.,   490.,   876.,   794.,   824.,   866.,    98.,   676.,
            578.,   948.,   666.,  1176.,   428.,   876., -1110.,   808.,
            558.,  -534.,   202.,  1340.,   328.,    52.,   -14.,   308.,
            244.,   320.,   584.,   452.,   792.,   414.,   812.,   550.,
           -176.,  3002.,   764.,  1618.,   658.,   364.,   536.,  1210.,
            514.,   -38.,  -244.],
         [  156.,   490.,   876.,   794.,   824.,   866.,    98.,   676.,
            578.,   948.,   666.,  1176.,   428.,   876., -1110.,   808.,
            558.,  -534.,   202.,  1340.,   328.,    52.,   -14.,   308.,
            244.,   320.,   584.,   452.,   792.,   414.,   812.,   550.,
           -176.,  3002.,   764.,  1618.,   658.,   364.,   536.,  1210.,
            514.,   -38.,  -244.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2846., 2512., 2126., 2208., 2178., 2136., 2904., 2326., 2424., 2054.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1317 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   64.,   450.,   860.,   766.,   820.,   814.,   170.,   756.,
            538.,   868.,   682.,  1208.,   400.,   708., -1062.,   784.,
            478.,  -602.,   202.,  1348.,   260.,   108.,   -30.,   360.,
            316.,   376.,   480.,   444.,   768.,   286.,   824.,   578.,
           -196.,  3262.,   724.,  1534.,   630.,   344.,   480.,  1246.,
            642.,  -130.,  -172.],
         [   64.,   450.,   860.,   766.,   820.,   814.,   170.,   756.,
            538.,   868.,   682.,  1208.,   400.,   708., -1062.,   784.,
            478.,  -602.,   202.,  1348.,   260.,   108.,   -30.,   360.,
            316.,   376.,   480.,   444.,   768.,   286.,   824.,   578.,
           -196.,  3262.,   724.,  1534.,   630.,   344.,   480.,  1246.,
            642.,  -130.,  -172.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3198., 2812., 2402., 2496., 2442., 2448., 3092., 2506., 2724., 2394.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0297 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  124.,   522.,   832.,   806.,   812.,   878.,    98.,   684.,
            538.,   872.,   630.,  1180.,   408.,   796., -1162.,   752.,
            518.,  -534.,   166.,  1400.,   252.,    68.,    34.,   304.,
            300.,   340.,   564.,   448.,   792.,   362.,   800.,   522.,
           -216.,  3070.,   776.,  1670.,   702.,   428.,   544.,  1218.,
            574.,   -38.,  -264.],
         [  124.,   522.,   832.,   806.,   812.,   878.,    98.,   684.,
            538.,   872.,   630.,  1180.,   408.,   796., -1162.,   752.,
            518.,  -534.,   166.,  1400.,   252.,    68.,    34.,   304.,
            300.,   340.,   564.,   448.,   792.,   362.,   800.,   522.,
           -216.,  3070.,   776.,  1670.,   702.,   428.,   544.,  1218.,
            574.,   -38.,  -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2946., 2548., 2238., 2264., 2258., 2192., 2972., 2386., 2532., 2198.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0396 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   492.,   862.,   772.,   774.,   852.,   172.,   742.,
            508.,   886.,   708.,  1210.,   422.,   686., -1116.,   746.,
            436.,  -612.,   176.,  1354.,   194.,    70.,    24.,   378.,
            314.,   282.,   470.,   414.,   758.,   288.,   822.,   568.,
           -170.,  3216.,   774.,  1508.,   676.,   398.,   498.,  1176.,
            668.,  -120.,  -218.],
         [   74.,   492.,   862.,   772.,   774.,   852.,   172.,   742.,
            508.,   886.,   708.,  1210.,   422.,   686., -1116.,   746.,
            436.,  -612.,   176.,  1354.,   194.,    70.,    24.,   378.,
            314.,   282.,   470.,   414.,   758.,   288.,   822.,   568.,
           -170.,  3216.,   774.,  1508.,   676.,   398.,   498.,  1176.,
            668.,  -120.,  -218.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2724., 2354., 2444., 2442., 2364., 3044., 2474., 2708., 2330.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9683 seconds.
PGD attack failed
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/2): BoundBuffers(name=/2, inputs=[], perturbed=False)
  (/shape): BoundBuffers(name=/shape, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True)
  (/13): BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True)
  (/17): BoundSplit(name=/17, inputs=[/shape], perturbed=False)
  (/18): BoundSplit(name=/18, inputs=[/shape], perturbed=False)
  (/19): BoundSqueeze(name=/19, inputs=[/17], perturbed=False)
  (/20): BoundSqueeze(name=/20, inputs=[/18], perturbed=False)
  (/21): BoundUnsqueeze(name=/21, inputs=[/19], perturbed=False)
  (/22): BoundUnsqueeze(name=/22, inputs=[/20], perturbed=False)
  (/23): BoundConcat(name=/23, inputs=[/21, /22], perturbed=False)
  (/24): BoundReshape(name=/24, inputs=[/14/merge, /23], perturbed=True)
  (/25): BoundTranspose(name=/25, inputs=[/8], perturbed=False)
  (/26): BoundMatMul(name=/26, inputs=[/24, /25], perturbed=True)
  (/10/merge): BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
  (/14/merge): BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
)
Original output: tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
Split layers:
  BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True): [(BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True), 0)]
  BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True): [(BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True), 0)]
Nonlinear functions:
   BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
   BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
initial crown bounds: tensor([[ -526., -1004., -1490., -1420., -1310., -1460.,  -752., -1262., -1092.,
         -1402., -1060., -1642.,  -962., -1318.,   236., -1458., -1044.,  -212.,
          -776., -1894.,  -934.,  -534.,  -504., -1086.,  -578.,  -910., -1030.,
         -1086., -1362., -1032., -1122., -1160.,  -422., -1074., -2100., -1252.,
          -990.,  -894., -2112., -1060.,  -404.,  -226.]], device='cuda:0')
Worst class: (+ rhs) -2112.0
Total VNNLIB file length: 42, max property batch size: 1, total number of batches: 42
lA shape: [torch.Size([42, 1, 16, 28, 28]), torch.Size([42, 1, 32, 27, 27])]

Properties batch 0, size 1
Remaining timeout: 836.1612312793732
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-526.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-526.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 14257] 
split level 1: [/13, 15065] 
split level 2: [/13, 20199] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 9.059906005859375e-05
Time: prepare 0.0004    bound 0.2222    transfer 0.0002    finalize 0.0006    func 0.2235    
Accumulated time: func 0.2235    prepare 0.0007    bound 0.2222    transfer 0.0002    finalize 0.0006    
Current worst splitting domains lb-rhs (depth):
-264.97104 (3), -264.96072 (3), -264.94513 (3), -264.93478 (3), -264.58063 (3), -264.57190 (3), -264.55469 (3), -264.54593 (3), 
length of domains: 8
Time: pickout 0.0003    decision 0.0488    set_bounds 0.0012    solve 0.2235    add 0.0095    
Accumulated time: pickout 0.0003    decision 0.0488    set_bounds 0.0012    solve 0.2235    add 0.0095    
Current (lb-rhs): -264.9710388183594
8 domains visited
Cumulative time: 0.5070726871490479

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 8469] [/9, 4451] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 5.364418029785156e-05
Time: prepare 0.0018    bound 0.0848    transfer 0.0003    finalize 0.0010    func 0.0878    
Accumulated time: func 0.3113    prepare 0.0029    bound 0.3070    transfer 0.0005    finalize 0.0016    
Current worst splitting domains lb-rhs (depth):
-62.89564 (4), -62.88129 (4), -62.50754 (4), -62.47741 (4), -62.45042 (4), -62.42039 (4), -62.40545 (4), -62.37600 (4), -62.37535 (4), -62.34599 (4), -61.98783 (4), -61.95775 (4), -61.93081 (4), -61.90075 (4), -61.88572 (4), -61.85564 (4), 
length of domains: 16
Time: pickout 0.0005    decision 0.0291    set_bounds 0.0019    solve 0.0879    add 0.0015    
Accumulated time: pickout 0.0008    decision 0.0779    set_bounds 0.0031    solve 0.3114    add 0.0111    
Current (lb-rhs): -62.89563751220703
24 domains visited
Cumulative time: 0.6280758380889893

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/13, 444] [/9, 8249] [/9, 8513] [/9, 8513] [/9, 7858] [/13, 124] [/9, 7858] [/9, 7858] [/9, 7858] 

all verified at 12th iter
pruning_in_iteration open status: False
ratio of positive domain = 32 / 32 = 1.0
pruning-in-iteration extra time: 0.00013828277587890625
Time: prepare 0.0023    bound 0.0527    transfer 0.0006    finalize 0.0019    func 0.0575    
Accumulated time: func 0.3688    prepare 0.0055    bound 0.3597    transfer 0.0011    finalize 0.0034    
length of domains: 0
Time: pickout 0.0004    decision 0.0300    set_bounds 0.0024    solve 0.0575    add 0.0001    
Accumulated time: pickout 0.0011    decision 0.1079    set_bounds 0.0055    solve 0.3689    add 0.0112    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
24 domains visited
Cumulative time: 0.718660831451416


Properties batch 1, size 1
Remaining timeout: 835.3306777477264
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-1004.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-1004.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 4133] 
split level 1: [/13, 11420] 
split level 2: [/13, 20199] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 5.5789947509765625e-05
Time: prepare 0.0004    bound 0.0828    transfer 0.0002    finalize 0.0005    func 0.0839    
Accumulated time: func 0.0839    prepare 0.0007    bound 0.0828    transfer 0.0002    finalize 0.0005    
Current worst splitting domains lb-rhs (depth):
-690.20398 (3), -690.08173 (3), -690.06860 (3), -690.04517 (3), -689.44971 (3), -689.32745 (3), -689.31433 (3), -689.29083 (3), 
length of domains: 8
Time: pickout 0.0002    decision 0.0170    set_bounds 0.0012    solve 0.0839    add 0.0009    
Accumulated time: pickout 0.0002    decision 0.0170    set_bounds 0.0012    solve 0.0839    add 0.0009    
Current (lb-rhs): -690.2039794921875
8 domains visited
Cumulative time: 0.10847783088684082

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 3953] [/9, 7951] [/9, 7951] [/9, 7951] [/9, 7951] [/9, 7951] [/9, 7951] [/9, 7951] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0012    bound 0.0824    transfer 0.0003    finalize 0.0010    func 0.0850    
Accumulated time: func 0.1689    prepare 0.0021    bound 0.1652    transfer 0.0005    finalize 0.0015    
Current worst splitting domains lb-rhs (depth):
-452.08755 (4), -452.00150 (4), -451.84409 (4), -451.75803 (4), -451.63708 (4), -451.55096 (4), -451.50726 (4), -451.42117 (4), -450.83585 (4), -450.74976 (4), -450.59244 (4), -450.38538 (4), -450.38086 (4), -450.29926 (4), -450.25555 (4), -450.16946 (4), 
length of domains: 16
Time: pickout 0.0003    decision 0.0194    set_bounds 0.0014    solve 0.0850    add 0.0020    
Accumulated time: pickout 0.0005    decision 0.0364    set_bounds 0.0026    solve 0.1690    add 0.0029    
Current (lb-rhs): -452.0875549316406
24 domains visited
Cumulative time: 0.2167370319366455

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/9, 7983] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 3953] [/9, 4509] [/13, 121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 5.698204040527344e-05
Time: prepare 0.0023    bound 0.0796    transfer 0.0005    finalize 0.0018    func 0.0843    
Accumulated time: func 0.2532    prepare 0.0047    bound 0.2448    transfer 0.0011    finalize 0.0034    
Current worst splitting domains lb-rhs (depth):
-345.33792 (5), -345.24042 (5), -345.23904 (5), -345.14139 (5), -345.09045 (5), -345.05600 (5), -344.99286 (5), -344.99149 (5), -344.95834 (5), -344.95712 (5), -344.90616 (5), -344.89389 (5), -344.85938 (5), -344.80844 (5), -344.80728 (5), -344.70956 (5), -343.99503 (5), -343.89740 (5), -343.89737 (5), -343.89606 (5), 
length of domains: 32
Time: pickout 0.0004    decision 0.0336    set_bounds 0.0024    solve 0.0843    add 0.0032    
Accumulated time: pickout 0.0010    decision 0.0700    set_bounds 0.0050    solve 0.2532    add 0.0061    
Current (lb-rhs): -345.3379211425781
56 domains visited
Cumulative time: 0.34082889556884766

BaB round 4
batch: 32
Average branched neurons at iteration 4:  1.0000
splitting decisions: 
split level 0: [/9, 7951] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 10474] [/9, 3953] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 6.151199340820312e-05
Time: prepare 0.0044    bound 0.1129    transfer 0.0010    finalize 0.0060    func 0.1243    
Accumulated time: func 0.3774    prepare 0.0094    bound 0.3577    transfer 0.0021    finalize 0.0093    
Current worst splitting domains lb-rhs (depth):
-296.20526 (6), -296.20148 (6), -296.20078 (6), -296.19696 (6), -296.16983 (6), -296.16614 (6), -296.14526 (6), -296.14145 (6), -296.09058 (6), -296.08682 (6), -296.08615 (6), -296.08240 (6), -296.05511 (6), -296.05151 (6), -296.03055 (6), -296.02689 (6), -295.99127 (6), -295.98764 (6), -295.97791 (6), -295.97412 (6), 
length of domains: 64
Time: pickout 0.0006    decision 0.0508    set_bounds 0.0042    solve 0.1243    add 0.0070    
Accumulated time: pickout 0.0016    decision 0.1208    set_bounds 0.0092    solve 0.3775    add 0.0130    
Current (lb-rhs): -296.20526123046875
120 domains visited
Cumulative time: 0.5278487205505371

BaB round 5
batch: 64
Average branched neurons at iteration 5:  1.0000
splitting decisions: 
split level 0: [/9, 10474] [/9, 7983] [/9, 9967] [/9, 7983] [/9, 7983] [/9, 7983] [/9, 7983] [/9, 7983] [/9, 7983] [/9, 10474] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0086    bound 0.2023    transfer 0.0019    finalize 0.0104    func 0.2232    
Accumulated time: func 0.6006    prepare 0.0183    bound 0.5600    transfer 0.0040    finalize 0.0197    
Current worst splitting domains lb-rhs (depth):
-273.86688 (7), -273.85266 (7), -273.82904 (7), -273.82904 (7), -273.82846 (7), -273.82797 (7), -273.80487 (7), -273.80383 (7), -273.80121 (7), -273.78607 (7), -273.77701 (7), -273.76239 (7), -273.74127 (7), -273.74127 (7), -273.73624 (7), -273.71771 (7), -273.71771 (7), -273.71353 (7), -273.71283 (7), -273.71259 (7), 
length of domains: 128
Time: pickout 0.0008    decision 0.0952    set_bounds 0.0077    solve 0.2233    add 0.0117    
Accumulated time: pickout 0.0024    decision 0.2160    set_bounds 0.0169    solve 0.6008    add 0.0248    
Current (lb-rhs): -273.86688232421875
248 domains visited
Cumulative time: 0.8668110370635986

BaB round 6
batch: 128
Average branched neurons at iteration 6:  1.0000
splitting decisions: 
split level 0: [/9, 4517] [/9, 4311] [/9, 4517] [/9, 4517] [/9, 4517] [/9, 4517] [/9, 4517] [/9, 4517] [/9, 7951] [/9, 7983] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.365776062011719e-05
Time: prepare 0.0175    bound 0.3767    transfer 0.0037    finalize 0.0255    func 0.4235    
Accumulated time: func 1.0241    prepare 0.0361    bound 0.9367    transfer 0.0076    finalize 0.0452    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.83035 (8), -256.83035 (8), -256.81195 (8), -256.81195 (8), -256.80899 (8), -256.76935 (8), -256.75882 (8), -256.75833 (8), -256.74701 (8), -256.74652 (8), -256.72754 (8), -256.72751 (8), -256.71671 (8), -256.71353 (8), -256.70834 (8), -256.70782 (8), -256.70169 (8), -256.70120 (8), 
length of domains: 256
Time: pickout 0.0024    decision 0.1780    set_bounds 0.0147    solve 0.4235    add 0.0289    
Accumulated time: pickout 0.0048    decision 0.3941    set_bounds 0.0316    solve 1.0244    add 0.0537    
Current (lb-rhs): -256.86285400390625
504 domains visited
Cumulative time: 1.5155029296875

BaB round 7
batch: 128
Average branched neurons at iteration 7:  1.0000
splitting decisions: 
split level 0: [/9, 4509] [/9, 4517] [/9, 3964] [/9, 4509] [/9, 4509] [/9, 9817] [/9, 4509] [/9, 4509] [/9, 11483] [/9, 4509] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.079673767089844e-05
Time: prepare 0.0175    bound 0.3745    transfer 0.0037    finalize 0.0274    func 0.4231    
Accumulated time: func 1.4472    prepare 0.0539    bound 1.3112    transfer 0.0113    finalize 0.0726    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 384
Time: pickout 0.0021    decision 0.1794    set_bounds 0.0157    solve 0.4232    add 0.0249    
Accumulated time: pickout 0.0069    decision 0.5734    set_bounds 0.0474    solve 1.4475    add 0.0786    
Current (lb-rhs): -256.86285400390625
760 domains visited
Cumulative time: 2.1626930236816406

BaB round 8
batch: 128
Average branched neurons at iteration 8:  1.0000
splitting decisions: 
split level 0: [/9, 4225] [/9, 4509] [/9, 7983] [/9, 9967] [/9, 4311] [/9, 4509] [/9, 11686] [/9, 3964] [/9, 4225] [/9, 9967] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.270408630371094e-05
Time: prepare 0.0176    bound 0.3761    transfer 0.0037    finalize 0.0275    func 0.4249    
Accumulated time: func 1.8721    prepare 0.0718    bound 1.6873    transfer 0.0150    finalize 0.1002    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 512
Time: pickout 0.0025    decision 0.1790    set_bounds 0.0148    solve 0.4250    add 0.0250    
Accumulated time: pickout 0.0094    decision 0.7524    set_bounds 0.0622    solve 1.8725    add 0.1036    
Current (lb-rhs): -256.86285400390625
1016 domains visited
Cumulative time: 2.811060667037964

BaB round 9
batch: 128
Average branched neurons at iteration 9:  1.0000
splitting decisions: 
split level 0: [/9, 9967] [/9, 9967] [/9, 4311] [/13, 121] [/9, 9967] [/9, 9967] [/9, 4311] [/13, 121] [/9, 4517] [/9, 4517] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.604194641113281e-05
Time: prepare 0.0176    bound 0.3778    transfer 0.0037    finalize 0.0276    func 0.4267    
Accumulated time: func 2.2988    prepare 0.0897    bound 2.0651    transfer 0.0187    finalize 0.1277    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 640
Time: pickout 0.0025    decision 0.1784    set_bounds 0.0151    solve 0.4268    add 0.0271    
Accumulated time: pickout 0.0119    decision 0.9309    set_bounds 0.0773    solve 2.2993    add 0.1307    
Current (lb-rhs): -256.86285400390625
1272 domains visited
Cumulative time: 3.4628942012786865

BaB round 10
batch: 128
Average branched neurons at iteration 10:  1.0000
splitting decisions: 
split level 0: [/9, 3964] [/9, 3964] [/9, 11686] [/9, 3964] [/9, 4225] [/13, 121] [/9, 3964] [/13, 444] [/9, 9967] [/9, 3964] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.651878356933594e-05
Time: prepare 0.0175    bound 0.3766    transfer 0.0037    finalize 0.0287    func 0.4266    
Accumulated time: func 2.7254    prepare 0.1075    bound 2.4417    transfer 0.0224    finalize 0.1564    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 768
Time: pickout 0.0025    decision 0.1782    set_bounds 0.0149    solve 0.4267    add 0.0253    
Accumulated time: pickout 0.0144    decision 1.1091    set_bounds 0.0922    solve 2.7260    add 0.1560    
Current (lb-rhs): -256.86285400390625
1528 domains visited
Cumulative time: 4.110810995101929

BaB round 11
batch: 128
Average branched neurons at iteration 11:  1.0000
splitting decisions: 
split level 0: [/9, 11686] [/13, 417] [/13, 121] [/9, 4225] [/9, 3964] [/9, 4225] [/9, 8451] [/9, 9967] [/9, 3964] [/13, 124] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.628036499023438e-05
Time: prepare 0.0178    bound 0.4334    transfer 0.0037    finalize 0.0278    func 0.4832    
Accumulated time: func 3.2086    prepare 0.1256    bound 2.8751    transfer 0.0260    finalize 0.1842    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 896
Time: pickout 0.0039    decision 0.1794    set_bounds 0.0148    solve 0.4833    add 0.0271    
Accumulated time: pickout 0.0183    decision 1.2885    set_bounds 0.1070    solve 3.2093    add 0.1831    
Current (lb-rhs): -256.86285400390625
1784 domains visited
Cumulative time: 4.821402311325073

BaB round 12
batch: 128
Average branched neurons at iteration 12:  1.0000
splitting decisions: 
split level 0: [/9, 4311] [/9, 4225] [/9, 4225] [/9, 9817] [/9, 11686] [/9, 3964] [/9, 9967] [/9, 8451] [/9, 10220] [/9, 4225] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.628036499023438e-05
Time: prepare 0.0218    bound 0.4725    transfer 0.0037    finalize 0.0278    func 0.5259    
Accumulated time: func 3.7345    prepare 0.1478    bound 3.3476    transfer 0.0298    finalize 0.2120    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1024
Time: pickout 0.0026    decision 0.2155    set_bounds 0.0157    solve 0.5260    add 0.0269    
Accumulated time: pickout 0.0210    decision 1.5040    set_bounds 0.1226    solve 3.7353    add 0.2101    
Current (lb-rhs): -256.86285400390625
2040 domains visited
Cumulative time: 5.610121726989746

BaB round 13
batch: 128
Average branched neurons at iteration 13:  1.0000
splitting decisions: 
split level 0: [/9, 9817] [/9, 11686] [/9, 4509] [/9, 11686] [/9, 9817] [/9, 11686] [/9, 4225] [/13, 417] [/9, 8451] [/9, 11686] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0226    bound 0.4713    transfer 0.0037    finalize 0.0286    func 0.5263    
Accumulated time: func 4.2607    prepare 0.1707    bound 3.8189    transfer 0.0334    finalize 0.2406    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1152
Time: pickout 0.0027    decision 0.2147    set_bounds 0.0159    solve 0.5264    add 0.2718    
Accumulated time: pickout 0.0236    decision 1.7187    set_bounds 0.1385    solve 4.2617    add 0.4819    
Current (lb-rhs): -256.86285400390625
2296 domains visited
Cumulative time: 6.641922950744629

BaB round 14
batch: 128
Average branched neurons at iteration 14:  1.0000
splitting decisions: 
split level 0: [/9, 7981] [/9, 9817] [/9, 9817] [/9, 4311] [/9, 11483] [/9, 4311] [/9, 2039] [/9, 10220] [/13, 124] [/9, 4311] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.914138793945312e-05
Time: prepare 0.0187    bound 0.3995    transfer 0.0037    finalize 0.0137    func 0.4357    
Accumulated time: func 4.6964    prepare 0.1898    bound 4.2184    transfer 0.0371    finalize 0.2543    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1280
Time: pickout 0.0026    decision 0.1852    set_bounds 0.0156    solve 0.4358    add 0.0230    
Accumulated time: pickout 0.0262    decision 1.9039    set_bounds 0.1542    solve 4.6975    add 0.5048    
Current (lb-rhs): -256.86285400390625
2552 domains visited
Cumulative time: 7.30437445640564

BaB round 15
batch: 128
Average branched neurons at iteration 15:  1.0000
splitting decisions: 
split level 0: [/9, 8451] [/9, 8451] [/9, 11483] [/9, 11483] [/9, 10220] [/9, 11483] [/9, 11483] [/9, 4225] [/9, 9817] [/9, 9817] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.222724914550781e-05
Time: prepare 0.0177    bound 0.3722    transfer 0.0037    finalize 0.0136    func 0.4073    
Accumulated time: func 5.1037    prepare 0.2079    bound 4.5906    transfer 0.0408    finalize 0.2680    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1408
Time: pickout 0.0023    decision 0.1775    set_bounds 0.0149    solve 0.4074    add 0.0246    
Accumulated time: pickout 0.0285    decision 2.0814    set_bounds 0.1690    solve 5.1048    add 0.5295    
Current (lb-rhs): -256.86285400390625
2808 domains visited
Cumulative time: 7.931335210800171

BaB round 16
batch: 128
Average branched neurons at iteration 16:  1.0000
splitting decisions: 
split level 0: [/9, 10220] [/9, 10220] [/9, 8451] [/9, 8451] [/9, 8451] [/9, 8451] [/9, 7981] [/9, 4311] [/13, 444] [/9, 8451] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.842613220214844e-05
Time: prepare 0.0178    bound 0.4673    transfer 0.0037    finalize 0.0144    func 0.5033    
Accumulated time: func 5.6070    prepare 0.2259    bound 5.0579    transfer 0.0445    finalize 0.2824    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1536
Time: pickout 0.0025    decision 0.1785    set_bounds 0.0149    solve 0.5034    add 0.0246    
Accumulated time: pickout 0.0310    decision 2.2600    set_bounds 0.1839    solve 5.6082    add 0.5541    
Current (lb-rhs): -256.86285400390625
3064 domains visited
Cumulative time: 8.655572891235352

BaB round 17
batch: 128
Average branched neurons at iteration 17:  1.0000
splitting decisions: 
split level 0: [/9, 11672] [/9, 11483] [/9, 10220] [/9, 10220] [/9, 2039] [/9, 11672] [/9, 9628] [/9, 11686] [/9, 11686] [/9, 11483] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 7.128715515136719e-05
Time: prepare 0.0228    bound 0.4722    transfer 0.0038    finalize 0.0140    func 0.5128    
Accumulated time: func 6.1198    prepare 0.2490    bound 5.5301    transfer 0.0483    finalize 0.2964    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1664
Time: pickout 0.0027    decision 0.2107    set_bounds 0.0162    solve 0.5129    add 0.0293    
Accumulated time: pickout 0.0337    decision 2.4707    set_bounds 0.2001    solve 6.1211    add 0.5834    
Current (lb-rhs): -256.86285400390625
3320 domains visited
Cumulative time: 9.427851676940918

BaB round 18
batch: 128
Average branched neurons at iteration 18:  1.0000
splitting decisions: 
split level 0: [/9, 2039] [/9, 7981] [/9, 2039] [/9, 4082] [/9, 9628] [/9, 10220] [/9, 9817] [/9, 7981] [/9, 4082] [/9, 2039] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0230    bound 0.4727    transfer 0.0037    finalize 0.0140    func 0.5135    
Accumulated time: func 6.6334    prepare 0.2725    bound 6.0028    transfer 0.0520    finalize 0.3104    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1792
Time: pickout 0.0027    decision 0.2148    set_bounds 0.0153    solve 0.5136    add 0.0262    
Accumulated time: pickout 0.0363    decision 2.6855    set_bounds 0.2154    solve 6.6347    add 0.6096    
Current (lb-rhs): -256.86285400390625
3576 domains visited
Cumulative time: 10.200748443603516

BaB round 19
batch: 128
Average branched neurons at iteration 19:  1.0000
splitting decisions: 
split level 0: [/9, 4082] [/9, 2039] [/9, 7981] [/9, 2039] [/9, 7981] [/9, 7981] [/9, 4082] [/9, 11483] [/9, 4311] [/9, 10220] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.556510925292969e-05
Time: prepare 0.0231    bound 0.4717    transfer 0.0037    finalize 0.0143    func 0.5130    
Accumulated time: func 7.1463    prepare 0.2959    bound 6.4745    transfer 0.0558    finalize 0.3248    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 1920
Time: pickout 0.0027    decision 0.2163    set_bounds 0.0158    solve 0.5131    add 0.0305    
Accumulated time: pickout 0.0390    decision 2.9018    set_bounds 0.2312    solve 7.1478    add 0.6401    
Current (lb-rhs): -256.86285400390625
3832 domains visited
Cumulative time: 10.979454755783081

BaB round 20
batch: 128
Average branched neurons at iteration 20:  1.0000
splitting decisions: 
split level 0: [/9, 9628] [/9, 11672] [/9, 11672] [/9, 11672] [/9, 11672] [/9, 2039] [/9, 1713] [/13, 417] [/9, 11672] [/9, 7981] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0185    bound 0.3933    transfer 0.0037    finalize 0.0137    func 0.4292    
Accumulated time: func 7.5755    prepare 0.3148    bound 6.8678    transfer 0.0594    finalize 0.3385    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2048
Time: pickout 0.0028    decision 0.1859    set_bounds 0.0156    solve 0.4293    add 0.0224    
Accumulated time: pickout 0.0419    decision 3.0877    set_bounds 0.2468    solve 7.5771    add 0.6625    
Current (lb-rhs): -256.86285400390625
4088 domains visited
Cumulative time: 11.635897874832153

BaB round 21
batch: 128
Average branched neurons at iteration 21:  1.0000
splitting decisions: 
split level 0: [/9, 11483] [/9, 4082] [/9, 1713] [/9, 8374] [/9, 4082] [/9, 9628] [/9, 10220] [/9, 9628] [/9, 2039] [/9, 9628] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 9.679794311523438e-05
Time: prepare 0.0178    bound 0.3902    transfer 0.0039    finalize 0.0144    func 0.4264    
Accumulated time: func 8.0019    prepare 0.3331    bound 7.2580    transfer 0.0633    finalize 0.3529    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2176
Time: pickout 0.0025    decision 0.1802    set_bounds 0.0156    solve 0.4265    add 0.4852    
Accumulated time: pickout 0.0444    decision 3.2680    set_bounds 0.2624    solve 8.0036    add 1.1477    
Current (lb-rhs): -256.86285400390625
4344 domains visited
Cumulative time: 12.746334552764893

BaB round 22
batch: 128
Average branched neurons at iteration 22:  1.0000
splitting decisions: 
split level 0: [/9, 1713] [/9, 9900] [/9, 9628] [/9, 7981] [/9, 1713] [/9, 4082] [/13, 121] [/9, 9817] [/13, 121] [/9, 11672] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0179    bound 0.3730    transfer 0.0037    finalize 0.0137    func 0.4082    
Accumulated time: func 8.4101    prepare 0.3512    bound 7.6310    transfer 0.0670    finalize 0.3665    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2304
Time: pickout 0.0025    decision 0.1785    set_bounds 0.0148    solve 0.4083    add 0.0260    
Accumulated time: pickout 0.0468    decision 3.4464    set_bounds 0.2773    solve 8.4119    add 1.1737    
Current (lb-rhs): -256.86285400390625
4600 domains visited
Cumulative time: 13.376814603805542

BaB round 23
batch: 128
Average branched neurons at iteration 23:  1.0000
splitting decisions: 
split level 0: [/9, 7858] [/9, 9628] [/9, 4082] [/9, 9900] [/9, 9912] [/9, 1713] [/9, 11672] [/9, 8374] [/9, 1713] [/9, 1713] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0177    bound 0.3717    transfer 0.0037    finalize 0.0181    func 0.4117    
Accumulated time: func 8.8219    prepare 0.3692    bound 8.0027    transfer 0.0706    finalize 0.3846    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2432
Time: pickout 0.0026    decision 0.1774    set_bounds 0.0149    solve 0.4118    add 0.0289    
Accumulated time: pickout 0.0494    decision 3.6238    set_bounds 0.2922    solve 8.8237    add 1.2026    
Current (lb-rhs): -256.86285400390625
4856 domains visited
Cumulative time: 14.013612508773804

BaB round 24
batch: 128
Average branched neurons at iteration 24:  1.0000
splitting decisions: 
split level 0: [/9, 9900] [/9, 1713] [/9, 8513] [/9, 11312] [/9, 9900] [/9, 8374] [/9, 9900] [/9, 11672] [/9, 9628] [/9, 9912] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.29425048828125e-05
Time: prepare 0.0188    bound 0.3715    transfer 0.0037    finalize 0.0181    func 0.4121    
Accumulated time: func 9.2340    prepare 0.3883    bound 8.3741    transfer 0.0743    finalize 0.4028    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2560
Time: pickout 0.0024    decision 0.1774    set_bounds 0.0152    solve 0.4122    add 0.0271    
Accumulated time: pickout 0.0518    decision 3.8012    set_bounds 0.3074    solve 9.2359    add 1.2297    
Current (lb-rhs): -256.86285400390625
5112 domains visited
Cumulative time: 14.649027109146118

BaB round 25
batch: 128
Average branched neurons at iteration 25:  1.0000
splitting decisions: 
split level 0: [/9, 9912] [/9, 8374] [/9, 7858] [/9, 8513] [/9, 11312] [/9, 8513] [/9, 8513] [/9, 2039] [/9, 11312] [/9, 4082] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.341934204101562e-05
Time: prepare 0.0177    bound 0.3727    transfer 0.0037    finalize 0.0137    func 0.4078    
Accumulated time: func 9.6418    prepare 0.4063    bound 8.7468    transfer 0.0780    finalize 0.4164    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2688
Time: pickout 0.0026    decision 0.1790    set_bounds 0.0149    solve 0.4079    add 0.0270    
Accumulated time: pickout 0.0544    decision 3.9802    set_bounds 0.3223    solve 9.6438    add 1.2567    
Current (lb-rhs): -256.86285400390625
5368 domains visited
Cumulative time: 15.280783414840698

BaB round 26
batch: 128
Average branched neurons at iteration 26:  1.0000
splitting decisions: 
split level 0: [/9, 8513] [/9, 7858] [/9, 9956] [/9, 7858] [/9, 7858] [/9, 9912] [/9, 9996] [/9, 1713] [/9, 7981] [/9, 8374] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.818771362304688e-05
Time: prepare 0.0179    bound 0.3719    transfer 0.0037    finalize 0.0182    func 0.4118    
Accumulated time: func 10.0536    prepare 0.4246    bound 9.1188    transfer 0.0817    finalize 0.4346    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2816
Time: pickout 0.0024    decision 0.1775    set_bounds 0.0148    solve 0.4119    add 0.0276    
Accumulated time: pickout 0.0568    decision 4.1577    set_bounds 0.3371    solve 10.0557    add 1.2842    
Current (lb-rhs): -256.86285400390625
5624 domains visited
Cumulative time: 15.915347814559937

BaB round 27
batch: 128
Average branched neurons at iteration 27:  1.0000
splitting decisions: 
split level 0: [/9, 11312] [/9, 11312] [/9, 8260] [/9, 9996] [/9, 8260] [/9, 7858] [/9, 7858] [/9, 4082] [/9, 7858] [/9, 7858] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.604194641113281e-05
Time: prepare 0.0177    bound 0.3766    transfer 0.0037    finalize 0.0137    func 0.4118    
Accumulated time: func 10.4654    prepare 0.4426    bound 9.4954    transfer 0.0854    finalize 0.4483    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 2944
Time: pickout 0.0026    decision 0.1786    set_bounds 0.0149    solve 0.4119    add 0.0317    
Accumulated time: pickout 0.0593    decision 4.3363    set_bounds 0.3520    solve 10.4676    add 1.3159    
Current (lb-rhs): -256.86285400390625
5880 domains visited
Cumulative time: 16.55541968345642

BaB round 28
batch: 128
Average branched neurons at iteration 28:  1.0000
splitting decisions: 
split level 0: [/9, 8260] [/9, 9912] [/9, 9900] [/9, 9956] [/9, 8513] [/9, 11510] [/9, 9912] [/9, 9900] [/9, 9900] [/9, 9900] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.461143493652344e-05
Time: prepare 0.0180    bound 0.3722    transfer 0.0037    finalize 0.0143    func 0.4082    
Accumulated time: func 10.8736    prepare 0.4610    bound 9.8676    transfer 0.0890    finalize 0.4626    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3072
Time: pickout 0.0029    decision 0.1774    set_bounds 0.0149    solve 0.4083    add 0.0262    
Accumulated time: pickout 0.0622    decision 4.5137    set_bounds 0.3669    solve 10.8759    add 1.3422    
Current (lb-rhs): -256.86285400390625
6136 domains visited
Cumulative time: 17.185455560684204

BaB round 29
batch: 128
Average branched neurons at iteration 29:  1.0000
splitting decisions: 
split level 0: [/9, 9956] [/9, 8260] [/9, 11312] [/13, 124] [/9, 9956] [/9, 11312] [/13, 146] [/9, 11510] [/9, 9912] [/9, 8513] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 7.271766662597656e-05
Time: prepare 0.0176    bound 0.3998    transfer 0.0040    finalize 0.0143    func 0.4357    
Accumulated time: func 11.3093    prepare 0.4788    bound 10.2674    transfer 0.0930    finalize 0.4769    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3200
Time: pickout 0.0026    decision 0.1767    set_bounds 0.0148    solve 0.4358    add 0.0272    
Accumulated time: pickout 0.0648    decision 4.6904    set_bounds 0.3817    solve 11.3117    add 1.3693    
Current (lb-rhs): -256.86285400390625
6392 domains visited
Cumulative time: 17.84307026863098

BaB round 30
batch: 128
Average branched neurons at iteration 30:  1.0000
splitting decisions: 
split level 0: [/13, 465] [/9, 8513] [/9, 9912] [/9, 9628] [/9, 9996] [/9, 9900] [/9, 11312] [/9, 9912] [/9, 8513] [/9, 11312] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.556510925292969e-05
Time: prepare 0.0180    bound 0.3746    transfer 0.0037    finalize 0.0137    func 0.4101    
Accumulated time: func 11.7194    prepare 0.4971    bound 10.6420    transfer 0.0967    finalize 0.4907    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3328
Time: pickout 0.0038    decision 0.1783    set_bounds 0.0150    solve 0.4102    add 0.0291    
Accumulated time: pickout 0.0686    decision 4.8687    set_bounds 0.3967    solve 11.7219    add 1.3984    
Current (lb-rhs): -256.86285400390625
6648 domains visited
Cumulative time: 18.4797523021698

BaB round 31
batch: 128
Average branched neurons at iteration 31:  1.0000
splitting decisions: 
split level 0: [/9, 9996] [/9, 9996] [/9, 9539] [/9, 8260] [/9, 11397] [/9, 8260] [/9, 9956] [/9, 7858] [/9, 9956] [/13, 444] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.67572021484375e-05
Time: prepare 0.0179    bound 0.3746    transfer 0.0037    finalize 0.0138    func 0.4100    
Accumulated time: func 12.1294    prepare 0.5154    bound 11.0166    transfer 0.1003    finalize 0.5044    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3456
Time: pickout 0.0025    decision 0.1783    set_bounds 0.0148    solve 0.4100    add 0.0240    
Accumulated time: pickout 0.0712    decision 5.0470    set_bounds 0.4115    solve 12.1319    add 1.4224    
Current (lb-rhs): -256.86285400390625
6904 domains visited
Cumulative time: 19.10993266105652

BaB round 32
batch: 128
Average branched neurons at iteration 32:  1.0000
splitting decisions: 
split level 0: [/9, 4317] [/13, 146] [/9, 9996] [/9, 9912] [/9, 4317] [/9, 9956] [/9, 11116] [/9, 8513] [/13, 121] [/9, 9956] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.866455078125e-05
Time: prepare 0.0181    bound 0.3731    transfer 0.0037    finalize 0.0137    func 0.4086    
Accumulated time: func 12.5380    prepare 0.5338    bound 11.3897    transfer 0.1040    finalize 0.5181    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3584
Time: pickout 0.0027    decision 0.1789    set_bounds 0.0150    solve 0.4087    add 0.0259    
Accumulated time: pickout 0.0739    decision 5.2259    set_bounds 0.4265    solve 12.5406    add 1.4483    
Current (lb-rhs): -256.86285400390625
7160 domains visited
Cumulative time: 19.741540908813477

BaB round 33
batch: 128
Average branched neurons at iteration 33:  1.0000
splitting decisions: 
split level 0: [/9, 8091] [/9, 9956] [/9, 11116] [/9, 11116] [/9, 11116] [/13, 121] [/13, 121] [/9, 11312] [/9, 11116] [/9, 11397] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0178    bound 0.3749    transfer 0.0037    finalize 0.0138    func 0.4101    
Accumulated time: func 12.9482    prepare 0.5519    bound 11.7646    transfer 0.1076    finalize 0.5319    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3712
Time: pickout 0.0026    decision 0.1773    set_bounds 0.0154    solve 0.4102    add 0.0273    
Accumulated time: pickout 0.0765    decision 5.4032    set_bounds 0.4419    solve 12.9509    add 1.4756    
Current (lb-rhs): -256.86285400390625
7416 domains visited
Cumulative time: 20.374776363372803

BaB round 34
batch: 128
Average branched neurons at iteration 34:  1.0000
splitting decisions: 
split level 0: [/9, 11116] [/9, 11116] [/9, 11397] [/13, 444] [/9, 9539] [/9, 9996] [/9, 11397] [/9, 8260] [/9, 11397] [/9, 8260] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.699562072753906e-05
Time: prepare 0.0178    bound 0.4041    transfer 0.0037    finalize 0.0139    func 0.4395    
Accumulated time: func 13.3877    prepare 0.5701    bound 12.1686    transfer 0.1113    finalize 0.5458    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3840
Time: pickout 0.0026    decision 0.1792    set_bounds 0.0148    solve 0.4396    add 0.0264    
Accumulated time: pickout 0.0790    decision 5.5824    set_bounds 0.4567    solve 13.3905    add 1.5020    
Current (lb-rhs): -256.86285400390625
7672 domains visited
Cumulative time: 21.03786063194275

BaB round 35
batch: 128
Average branched neurons at iteration 35:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/9, 11397] [/13, 121] [/9, 4317] [/9, 7916] [/13, 121] [/9, 8260] [/9, 11116] [/9, 9539] [/9, 9996] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0178    bound 0.3733    transfer 0.0037    finalize 0.0137    func 0.4092    
Accumulated time: func 13.7969    prepare 0.5883    bound 12.5420    transfer 0.1150    finalize 0.5595    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 3968
Time: pickout 0.0028    decision 0.1795    set_bounds 0.0149    solve 0.4093    add 0.0255    
Accumulated time: pickout 0.0818    decision 5.7618    set_bounds 0.4716    solve 13.7997    add 1.5275    
Current (lb-rhs): -256.86285400390625
7928 domains visited
Cumulative time: 21.670263528823853

BaB round 36
batch: 128
Average branched neurons at iteration 36:  1.0000
splitting decisions: 
split level 0: [/9, 11397] [/9, 9539] [/9, 4317] [/13, 124] [/9, 8091] [/9, 11397] [/9, 4317] [/9, 11397] [/9, 8260] [/9, 9539] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.604194641113281e-05
Time: prepare 0.0178    bound 0.3735    transfer 0.0037    finalize 0.0137    func 0.4088    
Accumulated time: func 14.2057    prepare 0.6065    bound 12.9155    transfer 0.1186    finalize 0.5732    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4096
Time: pickout 0.0026    decision 0.2153    set_bounds 0.0151    solve 0.4089    add 0.0253    
Accumulated time: pickout 0.0844    decision 5.9771    set_bounds 0.4868    solve 14.2086    add 1.5528    
Current (lb-rhs): -256.86285400390625
8184 domains visited
Cumulative time: 22.337975025177002

BaB round 37
batch: 128
Average branched neurons at iteration 37:  1.0000
splitting decisions: 
split level 0: [/9, 9539] [/9, 4317] [/9, 8091] [/9, 8091] [/9, 10037] [/9, 7916] [/9, 8091] [/9, 4317] [/13, 121] [/9, 11116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0177    bound 0.3891    transfer 0.0037    finalize 0.0137    func 0.4242    
Accumulated time: func 14.6299    prepare 0.6245    bound 13.3045    transfer 0.1223    finalize 0.5869    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4224
Time: pickout 0.0026    decision 0.1779    set_bounds 0.0151    solve 0.4243    add 0.9332    
Accumulated time: pickout 0.0870    decision 6.1550    set_bounds 0.5019    solve 14.6329    add 2.4860    
Current (lb-rhs): -256.86285400390625
8440 domains visited
Cumulative time: 23.891575813293457

BaB round 38
batch: 128
Average branched neurons at iteration 38:  1.0000
splitting decisions: 
split level 0: [/13, 146] [/9, 10037] [/9, 2116] [/13, 465] [/9, 3991] [/9, 8091] [/9, 9539] [/9, 9539] [/9, 4317] [/9, 8091] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0179    bound 0.3740    transfer 0.0037    finalize 0.0137    func 0.4093    
Accumulated time: func 15.0392    prepare 0.6428    bound 13.6786    transfer 0.1260    finalize 0.6006    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4352
Time: pickout 0.0027    decision 0.2014    set_bounds 0.0156    solve 0.4094    add 0.0289    
Accumulated time: pickout 0.0897    decision 6.3564    set_bounds 0.5175    solve 15.0424    add 2.5149    
Current (lb-rhs): -256.86285400390625
8696 domains visited
Cumulative time: 24.550098657608032

BaB round 39
batch: 128
Average branched neurons at iteration 39:  1.0000
splitting decisions: 
split level 0: [/9, 10037] [/13, 444] [/9, 10037] [/13, 417] [/9, 8374] [/9, 4317] [/9, 10037] [/9, 10037] [/9, 8091] [/9, 4317] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.151199340820312e-05
Time: prepare 0.0179    bound 0.3722    transfer 0.0036    finalize 0.0136    func 0.4074    
Accumulated time: func 15.4466    prepare 0.6610    bound 14.0508    transfer 0.1296    finalize 0.6142    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4480
Time: pickout 0.0025    decision 0.1813    set_bounds 0.0149    solve 0.4075    add 0.0276    
Accumulated time: pickout 0.0922    decision 6.5377    set_bounds 0.5324    solve 15.4499    add 2.5425    
Current (lb-rhs): -256.86285400390625
8952 domains visited
Cumulative time: 25.18432879447937

BaB round 40
batch: 128
Average branched neurons at iteration 40:  1.0000
splitting decisions: 
split level 0: [/9, 11200] [/9, 7916] [/9, 3991] [/9, 7916] [/9, 2289] [/9, 10037] [/9, 7916] [/9, 8091] [/9, 7916] [/9, 10037] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.985664367675781e-05
Time: prepare 0.0181    bound 0.4250    transfer 0.0037    finalize 0.0141    func 0.4616    
Accumulated time: func 15.9082    prepare 0.6794    bound 14.4758    transfer 0.1333    finalize 0.6283    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4608
Time: pickout 0.0026    decision 0.1780    set_bounds 0.0148    solve 0.4617    add 0.0288    
Accumulated time: pickout 0.0948    decision 6.7157    set_bounds 0.5472    solve 15.9115    add 2.5713    
Current (lb-rhs): -256.86285400390625
9208 domains visited
Cumulative time: 25.87073063850403

BaB round 41
batch: 128
Average branched neurons at iteration 41:  1.0000
splitting decisions: 
split level 0: [/9, 3991] [/9, 8091] [/9, 7916] [/13, 124] [/9, 11622] [/13, 444] [/9, 3991] [/9, 9956] [/13, 124] [/9, 7916] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.031990051269531e-05
Time: prepare 0.0180    bound 0.3729    transfer 0.0037    finalize 0.0137    func 0.4084    
Accumulated time: func 16.3166    prepare 0.6978    bound 14.8486    transfer 0.1370    finalize 0.6420    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4736
Time: pickout 0.0029    decision 0.1976    set_bounds 0.0151    solve 0.4084    add 0.0252    
Accumulated time: pickout 0.0977    decision 6.9132    set_bounds 0.5623    solve 16.3200    add 2.5965    
Current (lb-rhs): -256.86285400390625
9464 domains visited
Cumulative time: 26.520476818084717

BaB round 42
batch: 128
Average branched neurons at iteration 42:  1.0000
splitting decisions: 
split level 0: [/9, 11622] [/13, 121] [/9, 8374] [/13, 124] [/9, 2269] [/9, 11116] [/9, 8374] [/9, 9996] [/9, 9996] [/9, 3991] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0179    bound 0.3720    transfer 0.0037    finalize 0.0137    func 0.4073    
Accumulated time: func 16.7239    prepare 0.7161    bound 15.2207    transfer 0.1407    finalize 0.6556    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4864
Time: pickout 0.0028    decision 0.1770    set_bounds 0.0149    solve 0.4074    add 0.0252    
Accumulated time: pickout 0.1005    decision 7.0902    set_bounds 0.5772    solve 16.7274    add 2.6217    
Current (lb-rhs): -256.86285400390625
9720 domains visited
Cumulative time: 27.14828324317932

BaB round 43
batch: 128
Average branched neurons at iteration 43:  1.0000
splitting decisions: 
split level 0: [/13, 146] [/9, 3991] [/13, 444] [/13, 121] [/9, 8249] [/9, 2116] [/9, 2116] [/9, 11200] [/9, 3991] [/9, 11510] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.604194641113281e-05
Time: prepare 0.0180    bound 0.3747    transfer 0.0037    finalize 0.0138    func 0.4103    
Accumulated time: func 17.1342    prepare 0.7344    bound 15.5954    transfer 0.1444    finalize 0.6694    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 4992
Time: pickout 0.0027    decision 0.1779    set_bounds 0.0148    solve 0.4104    add 0.0268    
Accumulated time: pickout 0.1031    decision 7.2682    set_bounds 0.5920    solve 17.1378    add 2.6485    
Current (lb-rhs): -256.86285400390625
9976 domains visited
Cumulative time: 27.7813663482666

BaB round 44
batch: 128
Average branched neurons at iteration 44:  1.0000
splitting decisions: 
split level 0: [/9, 8374] [/9, 2116] [/9, 11622] [/13, 124] [/9, 11510] [/9, 9539] [/9, 2269] [/13, 146] [/9, 10037] [/9, 11622] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0180    bound 0.3759    transfer 0.0037    finalize 0.0137    func 0.4114    
Accumulated time: func 17.5456    prepare 0.7527    bound 15.9714    transfer 0.1481    finalize 0.6832    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5120
Time: pickout 0.0025    decision 0.1776    set_bounds 0.0148    solve 0.4115    add 0.0257    
Accumulated time: pickout 0.1057    decision 7.4458    set_bounds 0.6068    solve 17.5493    add 2.6742    
Current (lb-rhs): -256.86285400390625
10232 domains visited
Cumulative time: 28.414083003997803

BaB round 45
batch: 128
Average branched neurons at iteration 45:  1.0000
splitting decisions: 
split level 0: [/9, 8249] [/9, 11510] [/9, 2289] [/9, 9539] [/13, 124] [/9, 3991] [/9, 11200] [/9, 7916] [/9, 9957] [/9, 2289] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.91278076171875e-05
Time: prepare 0.0178    bound 0.3730    transfer 0.0037    finalize 0.0144    func 0.4089    
Accumulated time: func 17.9545    prepare 0.7708    bound 16.3443    transfer 0.1517    finalize 0.6976    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5248
Time: pickout 0.0027    decision 0.1770    set_bounds 0.0149    solve 0.4090    add 0.0253    
Accumulated time: pickout 0.1084    decision 7.6228    set_bounds 0.6217    solve 17.9583    add 2.6995    
Current (lb-rhs): -256.86285400390625
10488 domains visited
Cumulative time: 29.043477296829224

BaB round 46
batch: 128
Average branched neurons at iteration 46:  1.0000
splitting decisions: 
split level 0: [/9, 2116] [/9, 11622] [/9, 10995] [/9, 1713] [/9, 10995] [/9, 10995] [/9, 11622] [/9, 11622] [/9, 2289] [/9, 10995] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0246    bound 0.4074    transfer 0.0037    finalize 0.0138    func 0.4495    
Accumulated time: func 18.4040    prepare 0.7957    bound 16.7517    transfer 0.1554    finalize 0.7114    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5376
Time: pickout 0.0028    decision 0.1809    set_bounds 0.0157    solve 0.4496    add 0.0256    
Accumulated time: pickout 0.1112    decision 7.8037    set_bounds 0.6373    solve 18.4079    add 2.7251    
Current (lb-rhs): -256.86285400390625
10744 domains visited
Cumulative time: 29.718519926071167

BaB round 47
batch: 128
Average branched neurons at iteration 47:  1.0000
splitting decisions: 
split level 0: [/9, 7916] [/9, 2289] [/9, 8249] [/9, 11510] [/9, 11200] [/13, 146] [/9, 2289] [/9, 2289] [/9, 2116] [/9, 2116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.270408630371094e-05
Time: prepare 0.0181    bound 0.3732    transfer 0.0037    finalize 0.0140    func 0.4090    
Accumulated time: func 18.8130    prepare 0.8142    bound 17.1249    transfer 0.1590    finalize 0.7253    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5504
Time: pickout 0.0027    decision 0.1774    set_bounds 0.0149    solve 0.4091    add 0.0254    
Accumulated time: pickout 0.1139    decision 7.9811    set_bounds 0.6522    solve 18.8169    add 2.7505    
Current (lb-rhs): -256.86285400390625
11000 domains visited
Cumulative time: 30.34846019744873

BaB round 48
batch: 128
Average branched neurons at iteration 48:  1.0000
splitting decisions: 
split level 0: [/9, 2289] [/9, 10995] [/13, 465] [/9, 3991] [/9, 9957] [/9, 2269] [/9, 10728] [/9, 2269] [/9, 8374] [/9, 8430] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0183    bound 0.3751    transfer 0.0037    finalize 0.0143    func 0.4115    
Accumulated time: func 19.2245    prepare 0.8328    bound 17.5000    transfer 0.1628    finalize 0.7396    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5632
Time: pickout 0.0027    decision 0.1783    set_bounds 0.0156    solve 0.4116    add 0.0259    
Accumulated time: pickout 0.1166    decision 8.1594    set_bounds 0.6678    solve 19.2285    add 2.7763    
Current (lb-rhs): -256.86285400390625
11256 domains visited
Cumulative time: 30.982948541641235

BaB round 49
batch: 128
Average branched neurons at iteration 49:  1.0000
splitting decisions: 
split level 0: [/9, 10995] [/13, 124] [/9, 11200] [/9, 11397] [/9, 8430] [/9, 8430] [/9, 8430] [/13, 146] [/9, 11200] [/9, 9642] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.67572021484375e-05
Time: prepare 0.0249    bound 0.4333    transfer 0.0037    finalize 0.0142    func 0.4761    
Accumulated time: func 19.7006    prepare 0.8580    bound 17.9334    transfer 0.1664    finalize 0.7537    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5760
Time: pickout 0.0027    decision 0.1776    set_bounds 0.0153    solve 0.4762    add 0.0256    
Accumulated time: pickout 0.1192    decision 8.3369    set_bounds 0.6831    solve 19.7047    add 2.8020    
Current (lb-rhs): -256.86285400390625
11512 domains visited
Cumulative time: 31.68087148666382

BaB round 50
batch: 128
Average branched neurons at iteration 50:  1.0000
splitting decisions: 
split level 0: [/9, 8430] [/9, 11200] [/13, 444] [/13, 124] [/9, 8232] [/9, 8232] [/9, 3954] [/9, 8249] [/9, 11622] [/9, 8232] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.747245788574219e-05
Time: prepare 0.0178    bound 0.3887    transfer 0.0037    finalize 0.0140    func 0.4242    
Accumulated time: func 20.1248    prepare 0.8761    bound 18.3221    transfer 0.1701    finalize 0.7677    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 5888
Time: pickout 0.0031    decision 0.2007    set_bounds 0.0156    solve 0.4243    add 0.0259    
Accumulated time: pickout 0.1224    decision 8.5376    set_bounds 0.6987    solve 20.1290    add 2.8278    
Current (lb-rhs): -256.86285400390625
11768 domains visited
Cumulative time: 32.35106897354126

BaB round 51
batch: 128
Average branched neurons at iteration 51:  1.0000
splitting decisions: 
split level 0: [/9, 8232] [/9, 8430] [/9, 3954] [/13, 444] [/9, 2116] [/13, 465] [/9, 11510] [/9, 3991] [/9, 8249] [/9, 11200] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.651878356933594e-05
Time: prepare 0.0179    bound 0.4100    transfer 0.0037    finalize 0.0142    func 0.4459    
Accumulated time: func 20.5707    prepare 0.8944    bound 18.7320    transfer 0.1738    finalize 0.7819    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6016
Time: pickout 0.0028    decision 0.1846    set_bounds 0.0148    solve 0.4459    add 0.0253    
Accumulated time: pickout 0.1252    decision 8.7222    set_bounds 0.7135    solve 20.5750    add 2.8532    
Current (lb-rhs): -256.86285400390625
12024 domains visited
Cumulative time: 33.0251350402832

BaB round 52
batch: 128
Average branched neurons at iteration 52:  1.0000
splitting decisions: 
split level 0: [/13, 417] [/9, 8249] [/9, 8430] [/9, 2116] [/9, 3954] [/9, 11622] [/9, 8249] [/9, 2116] [/13, 124] [/9, 4606] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0186    bound 0.4240    transfer 0.0037    finalize 0.0137    func 0.4609    
Accumulated time: func 21.0316    prepare 0.9133    bound 19.1560    transfer 0.1775    finalize 0.7957    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6144
Time: pickout 0.0026    decision 0.2116    set_bounds 0.0154    solve 0.4610    add 0.0268    
Accumulated time: pickout 0.1278    decision 8.9338    set_bounds 0.7289    solve 21.0360    add 2.8799    
Current (lb-rhs): -256.86285400390625
12280 domains visited
Cumulative time: 33.74308443069458

BaB round 53
batch: 128
Average branched neurons at iteration 53:  1.0000
splitting decisions: 
split level 0: [/9, 9642] [/13, 444] [/9, 4508] [/9, 2289] [/9, 1576] [/9, 2289] [/9, 8232] [/9, 3954] [/13, 417] [/13, 146] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0178    bound 0.3732    transfer 0.0037    finalize 0.0141    func 0.4088    
Accumulated time: func 21.4404    prepare 0.9315    bound 19.5292    transfer 0.1812    finalize 0.8097    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6272
Time: pickout 0.0029    decision 0.1784    set_bounds 0.0149    solve 0.4089    add 0.0255    
Accumulated time: pickout 0.1307    decision 9.1122    set_bounds 0.7438    solve 21.4449    add 2.9054    
Current (lb-rhs): -256.86285400390625
12536 domains visited
Cumulative time: 34.374358892440796

BaB round 54
batch: 128
Average branched neurons at iteration 54:  1.0000
splitting decisions: 
split level 0: [/9, 1576] [/9, 4606] [/9, 11749] [/9, 10995] [/9, 9642] [/9, 8249] [/9, 11398] [/9, 9642] [/9, 9642] [/9, 8249] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0192    bound 0.3734    transfer 0.0037    finalize 0.0141    func 0.4106    
Accumulated time: func 21.8510    prepare 0.9511    bound 19.9026    transfer 0.1849    finalize 0.8239    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6400
Time: pickout 0.0030    decision 0.1798    set_bounds 0.0156    solve 0.4107    add 0.0255    
Accumulated time: pickout 0.1337    decision 9.2920    set_bounds 0.7594    solve 21.8555    add 2.9310    
Current (lb-rhs): -256.86285400390625
12792 domains visited
Cumulative time: 35.00954747200012

BaB round 55
batch: 128
Average branched neurons at iteration 55:  1.0000
splitting decisions: 
split level 0: [/13, 465] [/9, 3954] [/9, 1576] [/9, 11622] [/13, 124] [/9, 3954] [/9, 1576] [/9, 4606] [/13, 121] [/9, 11749] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.365776062011719e-05
Time: prepare 0.0191    bound 0.3714    transfer 0.0037    finalize 0.0137    func 0.4079    
Accumulated time: func 22.2589    prepare 0.9705    bound 20.2741    transfer 0.1885    finalize 0.8376    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6528
Time: pickout 0.0027    decision 0.1790    set_bounds 0.0149    solve 0.4080    add 0.0261    
Accumulated time: pickout 0.1364    decision 9.4711    set_bounds 0.7743    solve 22.2636    add 2.9571    
Current (lb-rhs): -256.86285400390625
13048 domains visited
Cumulative time: 35.64102363586426

BaB round 56
batch: 128
Average branched neurons at iteration 56:  1.0000
splitting decisions: 
split level 0: [/9, 4508] [/9, 8232] [/9, 8232] [/9, 8430] [/9, 1601] [/9, 11200] [/13, 146] [/9, 10995] [/13, 444] [/13, 121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.0002675056457519531
Time: prepare 0.0231    bound 0.3865    transfer 0.0037    finalize 0.0141    func 0.4275    
Accumulated time: func 22.6864    prepare 0.9939    bound 20.6606    transfer 0.1923    finalize 0.8517    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6656
Time: pickout 0.0029    decision 0.2025    set_bounds 0.0153    solve 0.4276    add 0.0262    
Accumulated time: pickout 0.1393    decision 9.6735    set_bounds 0.7896    solve 22.6911    add 2.9833    
Current (lb-rhs): -256.86285400390625
13304 domains visited
Cumulative time: 36.31614708900452

BaB round 57
batch: 128
Average branched neurons at iteration 57:  1.0000
splitting decisions: 
split level 0: [/9, 11510] [/9, 9642] [/9, 4606] [/9, 8249] [/9, 4606] [/9, 9642] [/13, 146] [/9, 8430] [/9, 8430] [/9, 3954] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0181    bound 0.3724    transfer 0.0037    finalize 0.0146    func 0.4088    
Accumulated time: func 23.0952    prepare 1.0123    bound 21.0329    transfer 0.1959    finalize 0.8663    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6784
Time: pickout 0.0030    decision 0.1967    set_bounds 0.0149    solve 0.4089    add 0.0269    
Accumulated time: pickout 0.1423    decision 9.8702    set_bounds 0.8045    solve 23.1000    add 3.0102    
Current (lb-rhs): -256.86285400390625
13560 domains visited
Cumulative time: 36.967018365859985

BaB round 58
batch: 128
Average branched neurons at iteration 58:  1.0000
splitting decisions: 
split level 0: [/9, 3954] [/9, 4508] [/9, 9642] [/9, 10037] [/9, 4508] [/9, 4606] [/9, 4508] [/9, 4508] [/9, 10995] [/9, 4508] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0207    bound 0.3706    transfer 0.0037    finalize 0.0137    func 0.4088    
Accumulated time: func 23.5040    prepare 1.0333    bound 21.4036    transfer 0.1996    finalize 0.8800    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 6912
Time: pickout 0.0028    decision 0.1778    set_bounds 0.0149    solve 0.4089    add 0.0257    
Accumulated time: pickout 0.1450    decision 10.0480    set_bounds 0.8193    solve 23.5089    add 3.0358    
Current (lb-rhs): -256.86285400390625
13816 domains visited
Cumulative time: 37.59761428833008

BaB round 59
batch: 128
Average branched neurons at iteration 59:  1.0000
splitting decisions: 
split level 0: [/9, 4606] [/9, 1576] [/9, 8148] [/13, 465] [/9, 11398] [/9, 4508] [/9, 9642] [/9, 8232] [/9, 8232] [/9, 1576] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00025272369384765625
Time: prepare 0.0178    bound 0.3725    transfer 0.0037    finalize 0.0139    func 0.4081    
Accumulated time: func 23.9120    prepare 1.0514    bound 21.7761    transfer 0.2033    finalize 0.8940    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7040
Time: pickout 0.0027    decision 0.1771    set_bounds 0.0151    solve 0.4081    add 0.0262    
Accumulated time: pickout 0.1478    decision 10.2251    set_bounds 0.8344    solve 23.9170    add 3.0621    
Current (lb-rhs): -256.86285400390625
14072 domains visited
Cumulative time: 38.22749710083008

BaB round 60
batch: 128
Average branched neurons at iteration 60:  1.0000
splitting decisions: 
split level 0: [/9, 11749] [/9, 11749] [/13, 444] [/9, 3954] [/9, 8469] [/9, 11398] [/9, 9992] [/9, 1576] [/9, 4606] [/9, 8602] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0181    bound 0.3729    transfer 0.0037    finalize 0.0137    func 0.4083    
Accumulated time: func 24.3204    prepare 1.0698    bound 22.1490    transfer 0.2069    finalize 0.9077    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7168
Time: pickout 0.0028    decision 0.1771    set_bounds 0.0148    solve 0.4084    add 0.0262    
Accumulated time: pickout 0.1506    decision 10.4022    set_bounds 0.8492    solve 24.3255    add 3.0883    
Current (lb-rhs): -256.86285400390625
14328 domains visited
Cumulative time: 38.85747003555298

BaB round 61
batch: 128
Average branched neurons at iteration 61:  1.0000
splitting decisions: 
split level 0: [/9, 8602] [/9, 9957] [/9, 11510] [/9, 4606] [/13, 444] [/9, 1576] [/9, 8602] [/9, 11398] [/9, 3954] [/13, 121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0181    bound 0.3732    transfer 0.0037    finalize 0.0137    func 0.4088    
Accumulated time: func 24.7291    prepare 1.0882    bound 22.5222    transfer 0.2106    finalize 0.9214    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7296
Time: pickout 0.0026    decision 0.1776    set_bounds 0.0149    solve 0.4088    add 0.0272    
Accumulated time: pickout 0.1532    decision 10.5797    set_bounds 0.8641    solve 24.7343    add 3.1155    
Current (lb-rhs): -256.86285400390625
14584 domains visited
Cumulative time: 39.48920965194702

BaB round 62
batch: 128
Average branched neurons at iteration 62:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/9, 11398] [/9, 11398] [/9, 9642] [/9, 9992] [/9, 11749] [/9, 8469] [/9, 9992] [/9, 8602] [/9, 11398] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.0003762245178222656
Time: prepare 0.0189    bound 0.4342    transfer 0.0038    finalize 0.0142    func 0.4712    
Accumulated time: func 25.2004    prepare 1.1074    bound 22.9564    transfer 0.2144    finalize 0.9356    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7424
Time: pickout 0.0028    decision 0.1765    set_bounds 0.0159    solve 0.4713    add 0.0282    
Accumulated time: pickout 0.1559    decision 10.7563    set_bounds 0.8801    solve 25.2056    add 3.1436    
Current (lb-rhs): -256.86285400390625
14840 domains visited
Cumulative time: 40.18455219268799

BaB round 63
batch: 128
Average branched neurons at iteration 63:  1.0000
splitting decisions: 
split level 0: [/9, 11398] [/9, 1601] [/9, 8602] [/13, 124] [/13, 465] [/9, 8148] [/13, 444] [/9, 8602] [/9, 4508] [/9, 9992] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 7.152557373046875e-05
Time: prepare 0.0178    bound 0.3758    transfer 0.0038    finalize 0.0141    func 0.4115    
Accumulated time: func 25.6118    prepare 1.1256    bound 23.3322    transfer 0.2182    finalize 0.9497    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7552
Time: pickout 0.0031    decision 0.1858    set_bounds 0.0151    solve 0.4116    add 0.0254    
Accumulated time: pickout 0.1591    decision 10.9420    set_bounds 0.8952    solve 25.6172    add 3.1691    
Current (lb-rhs): -256.86285400390625
15096 domains visited
Cumulative time: 40.82619071006775

BaB round 64
batch: 128
Average branched neurons at iteration 64:  1.0000
splitting decisions: 
split level 0: [/9, 1601] [/9, 8602] [/9, 4549] [/9, 11200] [/9, 11749] [/9, 8602] [/13, 121] [/9, 1601] [/9, 11510] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0180    bound 0.3722    transfer 0.0037    finalize 0.0139    func 0.4087    
Accumulated time: func 26.0205    prepare 1.1440    bound 23.7045    transfer 0.2218    finalize 0.9635    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7680
Time: pickout 0.0029    decision 0.1782    set_bounds 0.0151    solve 0.4087    add 0.0282    
Accumulated time: pickout 0.1620    decision 11.1202    set_bounds 0.9102    solve 26.0260    add 3.1973    
Current (lb-rhs): -256.86285400390625
15352 domains visited
Cumulative time: 41.46000623703003

BaB round 65
batch: 128
Average branched neurons at iteration 65:  1.0000
splitting decisions: 
split level 0: [/13, 121] [/9, 8469] [/9, 8469] [/9, 11749] [/9, 8615] [/9, 1601] [/9, 9957] [/13, 124] [/9, 1576] [/9, 8148] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0178    bound 0.3725    transfer 0.0037    finalize 0.0137    func 0.4078    
Accumulated time: func 26.4283    prepare 1.1621    bound 24.0770    transfer 0.2255    finalize 0.9773    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7808
Time: pickout 0.0026    decision 0.1766    set_bounds 0.0149    solve 0.4079    add 0.0274    
Accumulated time: pickout 0.1646    decision 11.2969    set_bounds 0.9251    solve 26.4338    add 3.2247    
Current (lb-rhs): -256.86285400390625
15608 domains visited
Cumulative time: 42.090161085128784

BaB round 66
batch: 128
Average branched neurons at iteration 66:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 9992] [/9, 8615] [/9, 4508] [/9, 8602] [/9, 8469] [/9, 4606] [/13, 124] [/9, 11749] [/13, 4051] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.556510925292969e-05
Time: prepare 0.0179    bound 0.3761    transfer 0.0037    finalize 0.0137    func 0.4114    
Accumulated time: func 26.8397    prepare 1.1803    bound 24.4530    transfer 0.2292    finalize 0.9910    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 7936
Time: pickout 0.0028    decision 0.1774    set_bounds 0.0149    solve 0.4115    add 0.0260    
Accumulated time: pickout 0.1674    decision 11.4743    set_bounds 0.9400    solve 26.8453    add 3.2507    
Current (lb-rhs): -256.86285400390625
15864 domains visited
Cumulative time: 42.723471879959106

BaB round 67
batch: 128
Average branched neurons at iteration 67:  1.0000
splitting decisions: 
split level 0: [/13, 124] [/13, 4051] [/13, 1245] [/9, 11398] [/13, 4161] [/9, 9992] [/13, 121] [/9, 8148] [/9, 11398] [/13, 465] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.29425048828125e-05
Time: prepare 0.0179    bound 0.3710    transfer 0.0037    finalize 0.0138    func 0.4063    
Accumulated time: func 27.2460    prepare 1.1985    bound 24.8240    transfer 0.2328    finalize 1.0048    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 8064
Time: pickout 0.0028    decision 0.1764    set_bounds 0.0154    solve 0.4064    add 0.0260    
Accumulated time: pickout 0.1702    decision 11.6507    set_bounds 0.9555    solve 27.2518    add 3.2768    
Current (lb-rhs): -256.86285400390625
16120 domains visited
Cumulative time: 43.35118818283081

BaB round 68
batch: 128
Average branched neurons at iteration 68:  1.0000
splitting decisions: 
split level 0: [/9, 8615] [/9, 4053] [/9, 9992] [/9, 8232] [/9, 8148] [/9, 8615] [/9, 10995] [/9, 11749] [/9, 8469] [/13, 124] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.67572021484375e-05
Time: prepare 0.0178    bound 0.3727    transfer 0.0037    finalize 0.0139    func 0.4082    
Accumulated time: func 27.6543    prepare 1.2166    bound 25.1967    transfer 0.2365    finalize 1.0187    
Current worst splitting domains lb-rhs (depth):
-256.86285 (8), -256.86285 (8), -256.81195 (8), -256.81195 (8), -256.75833 (8), -256.74652 (8), -256.72754 (8), -256.71671 (8), -256.70782 (8), -256.70120 (8), -256.69568 (8), -256.67657 (8), -256.66977 (8), -256.66266 (8), -256.65030 (8), -256.61887 (8), -256.61404 (8), -256.61401 (8), -256.59668 (8), -256.58475 (8), 
length of domains: 8192
Time: pickout 0.0027    decision 0.1805    set_bounds 0.0150    solve 0.4083    add 0.0288    
Accumulated time: pickout 0.1729    decision 11.8312    set_bounds 0.9704    solve 27.6601    add 3.3055    
Current (lb-rhs): -256.86285400390625
16376 domains visited
Cumulative time: 43.98713660240173

BaB round 69
batch: 128
Average branched neurons at iteration 69:  1.0000
splitting decisions: 
split level 0: [/9, 9992] [/13, 121] [/13, 4161] [/9, 8148] [/9, 4549] [/9, 4549] [/9, 4549] [/9, 8469] [/9, 9992] [/9, 8615] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.532669067382812e-05
Time: prepare 0.0180    bound 0.3752    transfer 0.0037    finalize 0.0148    func 0.4802    
Accumulated time: func 28.1345    prepare 1.2350    bound 25.5720    transfer 0.2401    finalize 1.0335    
Killed
sed: can't read out.txt: No such file or directory
head: cannot open 'out.txt' for reading: No such file or directory
run_instance.sh exit code: 0, Result: no_result_in_file, Runtime: 436.288446695
Appending result 'no_result_in_file' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:26:10 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 89%   55C    P3              34W / 170W |    741MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     53MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    285MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       36MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      143MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
100%|| 1/1 [00:04<00:00,  4.26s/it]
100%|| 1/1 [00:04<00:00,  4.12s/it]
100%|| 1/1 [00:04<00:00,  4.11s/it]
100%|| 1/1 [00:04<00:00,  4.60s/it]
100%|| 1/1 [00:03<00:00,  3.96s/it]
100%|| 1/1 [00:03<00:00,  3.96s/it]
100%|| 1/1 [00:04<00:00,  4.64s/it]
100%|| 1/1 [00:04<00:00,  4.07s/it]
100%|| 1/1 [00:03<00:00,  3.96s/it]
  0%|                                                     | 0/1 [00:00<?, ?it/s]Preparation finished.
prepare_instance.sh exit code: 0, runtime: 52.151520759

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:27:01 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.3144s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.32s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  154.,   512.,   914.,   820.,   958.,   924.,   156.,   794.,
            652.,   874.,   628.,   986.,   414.,   926., -1084.,   866.,
            532.,  -516.,   212.,  1226.,   390.,    34.,    32.,   226.,
            186.,   346.,   494.,   426.,   694.,   432.,   642.,   524.,
           -150.,  2624.,   470.,  2112.,   708.,   366.,   482.,  1256.,
            640.,   108.,  -286.],
         [  154.,   512.,   914.,   820.,   958.,   924.,   156.,   794.,
            652.,   874.,   628.,   986.,   414.,   926., -1084.,   866.,
            532.,  -516.,   212.,  1226.,   390.,    34.,    32.,   226.,
            186.,   346.,   494.,   426.,   694.,   432.,   642.,   524.,
           -150.,  2624.,   470.,  2112.,   708.,   366.,   482.,  1256.,
            640.,   108.,  -286.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2470., 2112., 1710., 1804., 1666., 1700., 2468., 1830., 1972., 1750.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3341 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.55s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 4.00000000e+01,  4.22000000e+02,  8.28000000e+02,  7.22000000e+02,
           8.60000000e+02,  8.18000000e+02,  1.34000000e+02,  7.56000000e+02,
           5.26000000e+02,  9.00000000e+02,  7.18000000e+02,  1.17200000e+03,
           3.72000000e+02,  7.52000000e+02, -1.11000000e+03,  8.12000000e+02,
           5.14000000e+02, -5.26000000e+02,  2.38000000e+02,  1.40400000e+03,
           2.68000000e+02,  3.60000000e+01,  2.00000000e+00,  3.84000000e+02,
           3.20000000e+02,  3.36000000e+02,  4.56000000e+02,  4.12000000e+02,
           7.92000000e+02,  1.86000000e+02,  7.68000000e+02,  6.34000000e+02,
          -1.76000000e+02,  3.24200000e+03,  6.60000000e+02,  1.53800000e+03,
           7.30000000e+02,  4.32000000e+02,  5.28000000e+02,  1.27400000e+03,
           6.18000000e+02, -1.14000000e+02, -1.96000000e+02],
         [ 4.00000000e+01,  4.22000000e+02,  8.28000000e+02,  7.22000000e+02,
           8.60000000e+02,  8.18000000e+02,  1.34000000e+02,  7.56000000e+02,
           5.26000000e+02,  9.00000000e+02,  7.18000000e+02,  1.17200000e+03,
           3.72000000e+02,  7.52000000e+02, -1.11000000e+03,  8.12000000e+02,
           5.14000000e+02, -5.26000000e+02,  2.38000000e+02,  1.40400000e+03,
           2.68000000e+02,  3.60000000e+01,  2.00000000e+00,  3.84000000e+02,
           3.20000000e+02,  3.36000000e+02,  4.56000000e+02,  4.12000000e+02,
           7.92000000e+02,  1.86000000e+02,  7.68000000e+02,  6.34000000e+02,
          -1.76000000e+02,  3.24200000e+03,  6.60000000e+02,  1.53800000e+03,
           7.30000000e+02,  4.32000000e+02,  5.28000000e+02,  1.27400000e+03,
           6.18000000e+02, -1.14000000e+02, -1.96000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3202., 2820., 2414., 2520., 2382., 2424., 3108., 2486., 2716., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.5614 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  52.,  310.,  912.,  786.,  988.,  898.,  138.,  820.,  690.,  924.,
           646.,  996.,  532.,  872., -974.,  764.,  626., -550.,  126., 1284.,
           340.,   20.,   50.,  260.,   96.,  352.,  468.,  520.,  732.,  406.,
           632.,  594., -120., 2614.,  364., 2158.,  822.,  308.,  492., 1346.,
           682.,   30., -140.],
         [  52.,  310.,  912.,  786.,  988.,  898.,  138.,  820.,  690.,  924.,
           646.,  996.,  532.,  872., -974.,  764.,  626., -550.,  126., 1284.,
           340.,   20.,   50.,  260.,   96.,  352.,  468.,  520.,  732.,  406.,
           632.,  594., -120., 2614.,  364., 2158.,  822.,  308.,  492., 1346.,
           682.,   30., -140.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2562., 2304., 1702., 1828., 1626., 1716., 2476., 1794., 1924., 1690.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0191 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.14s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  122.,   476.,   850.,   800.,   846.,   808.,   144.,   766.,
            496.,   874.,   760.,  1130.,   382.,   762., -1140.,   766.,
            448.,  -572.,   224.,  1414.,   226.,    82.,    16.,   342.,
            366.,   374.,   426.,   302.,   794.,   288.,   762.,   732.,
           -122.,  3208.,   638.,  1548.,   724.,   350.,   522.,  1256.,
            632.,   -88.,  -242.],
         [  122.,   476.,   850.,   800.,   846.,   808.,   144.,   766.,
            496.,   874.,   760.,  1130.,   382.,   762., -1140.,   766.,
            448.,  -572.,   224.,  1414.,   226.,    82.,    16.,   342.,
            366.,   374.,   426.,   302.,   794.,   288.,   762.,   732.,
           -122.,  3208.,   638.,  1548.,   724.,   350.,   522.,  1256.,
            632.,   -88.,  -242.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3086., 2732., 2358., 2408., 2362., 2400., 3064., 2442., 2712., 2334.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1436 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.32s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 202.,  464.,  850.,  860.,  982.,  744.,  212.,  830.,  592.,  870.,
           616.,  970.,  410.,  898., -952.,  726.,  548., -532.,  196., 1278.,
           458.,   82.,   40.,  198.,  214.,  250.,  566.,  502.,  798.,  388.,
           642.,  560., -210., 2584.,  390., 2132.,  824.,  446.,  494., 1328.,
           552.,  120., -210.],
         [ 202.,  464.,  850.,  860.,  982.,  744.,  212.,  830.,  592.,  870.,
           616.,  970.,  410.,  898., -952.,  726.,  548., -532.,  196., 1278.,
           458.,   82.,   40.,  198.,  214.,  250.,  566.,  502.,  798.,  388.,
           642.,  560., -210., 2584.,  390., 2132.,  824.,  446.,  494., 1328.,
           552.,  120., -210.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2382., 2120., 1734., 1724., 1602., 1840., 2372., 1754., 1992., 1714.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3254 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   436.,   930.,   796.,   818.,   916.,   200.,   754.,
            528.,   830.,   756.,  1146.,   346.,   730., -1088.,   762.,
            468.,  -560.,   228.,  1430.,   282.,   190.,     8.,   338.,
            322.,   458.,   454.,   382.,   754.,   196.,   714.,   580.,
           -162.,  3184.,   682.,  1500.,   676.,   422.,   546.,  1244.,
            600.,  -164.,  -254.],
         [  102.,   436.,   930.,   796.,   818.,   916.,   200.,   754.,
            528.,   830.,   756.,  1146.,   346.,   730., -1088.,   762.,
            468.,  -560.,   228.,  1430.,   282.,   190.,     8.,   338.,
            322.,   458.,   454.,   382.,   754.,   196.,   714.,   580.,
           -162.,  3184.,   682.,  1500.,   676.,   422.,   546.,  1244.,
            600.,  -164.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3082., 2748., 2254., 2388., 2366., 2268., 2984., 2430., 2656., 2354.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0647 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.15s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 104.,  342.,  848.,  806., 1068.,  902.,  174.,  748.,  674.,  844.,
           678., 1000.,  388.,  872., -946.,  776.,  578., -530.,  202., 1212.,
           408.,  -16.,   10.,  396.,  304.,  324.,  572.,  448.,  712.,  322.,
           632.,  542., -176., 2546.,  452., 2054.,  834.,  356.,  468., 1254.,
           638.,   86., -168.],
         [ 104.,  342.,  848.,  806., 1068.,  902.,  174.,  748.,  674.,  844.,
           678., 1000.,  388.,  872., -946.,  776.,  578., -530.,  202., 1212.,
           408.,  -16.,   10.,  396.,  304.,  324.,  572.,  448.,  712.,  322.,
           632.,  542., -176., 2546.,  452., 2054.,  834.,  356.,  468., 1254.,
           638.,   86., -168.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2442., 2204., 1698., 1740., 1478., 1644., 2372., 1798., 1872., 1702.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1619 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  134.,   484.,   874.,   720.,   782.,   808.,   184.,   742.,
            576.,   974.,   708.,  1214.,   386.,   762., -1120.,   838.,
            400.,  -620.,   176.,  1426.,   194.,    42.,    12.,   374.,
            298.,   302.,   422.,   462.,   810.,   256.,   802.,   572.,
           -190.,  3212.,   666.,  1548.,   756.,   334.,   454.,  1136.,
            652.,  -160.,  -266.],
         [  134.,   484.,   874.,   720.,   782.,   808.,   184.,   742.,
            576.,   974.,   708.,  1214.,   386.,   762., -1120.,   838.,
            400.,  -620.,   176.,  1426.,   194.,    42.,    12.,   374.,
            298.,   302.,   422.,   462.,   810.,   256.,   802.,   572.,
           -190.,  3212.,   666.,  1548.,   756.,   334.,   454.,  1136.,
            652.,  -160.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3078., 2728., 2338., 2492., 2430., 2404., 3028., 2470., 2636., 2238.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9842 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 186.,  320.,  938.,  908.,  946.,  836.,  132.,  838.,  740.,  846.,
           652., 1082.,  490.,  902., -936.,  818.,  560., -560.,  148., 1390.,
           418.,   38.,   -4.,  298.,  182.,  270.,  462.,  518.,  822.,  492.,
           634.,  492.,  -86., 2552.,  418., 2140.,  816.,  294.,  494., 1316.,
           584.,   88., -214.],
         [ 186.,  320.,  938.,  908.,  946.,  836.,  132.,  838.,  740.,  846.,
           652., 1082.,  490.,  902., -936.,  818.,  560., -560.,  148., 1390.,
           418.,   38.,   -4.,  298.,  182.,  270.,  462.,  518.,  822.,  492.,
           634.,  492.,  -86., 2552.,  418., 2140.,  816.,  294.,  494., 1316.,
           584.,   88., -214.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2366., 2232., 1614., 1644., 1606., 1716., 2420., 1714., 1812., 1706.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0751 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   82.,   500.,   846.,   728.,   782.,   856.,   220.,   754.,
            432.,   830.,   748.,  1158.,   434.,   758., -1196.,   778.,
            516.,  -592.,   108.,  1346.,   242.,    -6.,    56.,   370.,
            282.,   402.,   470.,   398.,   770.,   248.,   754.,   652.,
           -234.,  3220.,   706.,  1528.,   740.,   386.,   426.,  1172.,
            628.,   -84.,  -202.],
         [   82.,   500.,   846.,   728.,   782.,   856.,   220.,   754.,
            432.,   830.,   748.,  1158.,   434.,   758., -1196.,   778.,
            516.,  -592.,   108.,  1346.,   242.,    -6.,    56.,   370.,
            282.,   402.,   470.,   398.,   770.,   248.,   754.,   652.,
           -234.,  3220.,   706.,  1528.,   740.,   386.,   426.,  1172.,
            628.,   -84.,  -202.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3138., 2720., 2374., 2492., 2438., 2364., 3000., 2466., 2788., 2390.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1190 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   82.,   384.,   922.,   836.,  1042.,   896.,   176.,   726.,
            716.,   890.,   620.,   990.,   306.,   922., -1004.,   890.,
            492.,  -476.,   196.,  1298.,   362.,    34.,    60.,   314.,
            238.,   330.,   462.,   466.,   738.,   420.,   610.,   504.,
           -158.,  2564.,   546.,  2160.,   932.,   454.,   478.,  1288.,
            648.,    72.,  -254.],
         [   82.,   384.,   922.,   836.,  1042.,   896.,   176.,   726.,
            716.,   890.,   620.,   990.,   306.,   922., -1004.,   890.,
            492.,  -476.,   196.,  1298.,   362.,    34.,    60.,   314.,
            238.,   330.,   462.,   466.,   738.,   420.,   610.,   504.,
           -158.,  2564.,   546.,  2160.,   932.,   454.,   478.,  1288.,
            648.,    72.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2482., 2180., 1642., 1728., 1522., 1668., 2388., 1838., 1848., 1674.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0715 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   92.,   458.,   872.,   830.,   804.,   858.,   130.,   736.,
            554.,   948.,   682.,  1232.,   532.,   800., -1098.,   776.,
            574.,  -574.,   190.,  1384.,   272.,    28.,   -82.,   432.,
            200.,   416.,   456.,   372.,   836.,   346.,   692.,   634.,
           -192.,  3198.,   660.,  1554.,   650.,   348.,   432.,  1218.,
            710.,   -78.,  -188.],
         [   92.,   458.,   872.,   830.,   804.,   858.,   130.,   736.,
            554.,   948.,   682.,  1232.,   532.,   800., -1098.,   776.,
            574.,  -574.,   190.,  1384.,   272.,    28.,   -82.,   432.,
            200.,   416.,   456.,   372.,   836.,   346.,   692.,   634.,
           -192.,  3198.,   660.,  1554.,   650.,   348.,   432.,  1218.,
            710.,   -78.,  -188.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3106., 2740., 2326., 2368., 2394., 2340., 3068., 2462., 2644., 2250.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0147 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 116.,  394.,  848.,  918.,  976.,  850.,  218.,  756.,  698.,  836.,
           602.,  972.,  428., 1004., -918.,  772.,  562., -522.,  146., 1276.,
           456.,  -36.,  142.,  292.,  184.,  312.,  572.,  396.,  780.,  450.,
           604.,  502.,  -96., 2502.,  492., 2170.,  722.,  412.,  536., 1378.,
           542.,   90., -240.],
         [ 116.,  394.,  848.,  918.,  976.,  850.,  218.,  756.,  698.,  836.,
           602.,  972.,  428., 1004., -918.,  772.,  562., -522.,  146., 1276.,
           456.,  -36.,  142.,  292.,  184.,  312.,  572.,  396.,  780.,  450.,
           604.,  502.,  -96., 2502.,  492., 2170.,  722.,  412.,  536., 1378.,
           542.,   90., -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2386., 2108., 1654., 1584., 1526., 1652., 2284., 1746., 1804., 1666.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0357 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  220.,   478.,   924.,   790.,   788.,   850.,   130.,   752.,
            450.,   804.,   734.,  1116.,   360.,   716., -1182.,   812.,
            498.,  -514.,   178.,  1408.,   160.,    96.,    58.,   408.,
            324.,   444.,   348.,   452.,   824.,   262.,   744.,   650.,
           -176.,  3146.,   704.,  1522.,   758.,   392.,   556.,  1226.,
            522.,   -62.,  -276.],
         [  220.,   478.,   924.,   790.,   788.,   850.,   130.,   752.,
            450.,   804.,   734.,  1116.,   360.,   716., -1182.,   812.,
            498.,  -514.,   178.,  1408.,   160.,    96.,    58.,   408.,
            324.,   444.,   348.,   452.,   824.,   262.,   744.,   650.,
           -176.,  3146.,   704.,  1522.,   758.,   392.,   556.,  1226.,
            522.,   -62.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2668., 2222., 2356., 2358., 2296., 3016., 2394., 2696., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0265 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   344.,   866.,   764.,   966.,   860.,   176.,   698.,
            728.,   838.,   728.,  1130.,   378.,   942., -1024.,   774.,
            572.,  -520.,   252.,  1390.,   322.,   110.,    -8.,   374.,
            290.,   218.,   510.,   454.,   762.,   376.,   714.,   440.,
            -74.,  2576.,   522.,  2076.,   800.,   314.,   382.,  1252.,
            652.,    56.,  -202.],
         [   74.,   344.,   866.,   764.,   966.,   860.,   176.,   698.,
            728.,   838.,   728.,  1130.,   378.,   942., -1024.,   774.,
            572.,  -520.,   252.,  1390.,   322.,   110.,    -8.,   374.,
            290.,   218.,   510.,   454.,   762.,   376.,   714.,   440.,
            -74.,  2576.,   522.,  2076.,   800.,   314.,   382.,  1252.,
            652.,    56.,  -202.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2502., 2232., 1710., 1812., 1610., 1716., 2400., 1878., 1848., 1738.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9732 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  132.,   462.,   860.,   754.,   860.,   842.,   102.,   740.,
            494.,   820.,   782.,  1172.,   400.,   716., -1110.,   716.,
            510.,  -586.,   154.,  1400.,   252.,   116.,   -10.,   416.,
            212.,   440.,   500.,   516.,   860.,   294.,   812.,   618.,
           -144.,  3206.,   728.,  1486.,   682.,   384.,   484.,  1186.,
            646.,   -46.,  -192.],
         [  132.,   462.,   860.,   754.,   860.,   842.,   102.,   740.,
            494.,   820.,   782.,  1172.,   400.,   716., -1110.,   716.,
            510.,  -586.,   154.,  1400.,   252.,   116.,   -10.,   416.,
            212.,   440.,   500.,   516.,   860.,   294.,   812.,   618.,
           -144.,  3206.,   728.,  1486.,   682.,   384.,   484.,  1186.,
            646.,   -46.,  -192.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3074., 2744., 2346., 2452., 2346., 2364., 3104., 2466., 2712., 2386.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0686 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 106.,  388.,  806.,  860.,  998.,  832.,  100.,  834.,  724.,  874.,
           620.,  966.,  374.,  958., -948.,  854.,  528., -484.,  140., 1318.,
           394.,    6.,   60.,  342.,  202.,  398.,  502.,  470.,  730.,  496.,
           566.,  520., -106., 2536.,  482., 2164.,  860.,  406.,  538., 1340.,
           508.,   96., -222.],
         [ 106.,  388.,  806.,  860.,  998.,  832.,  100.,  834.,  724.,  874.,
           620.,  966.,  374.,  958., -948.,  854.,  528., -484.,  140., 1318.,
           394.,    6.,   60.,  342.,  202.,  398.,  502.,  470.,  730.,  496.,
           566.,  520., -106., 2536.,  482., 2164.,  860.,  406.,  538., 1340.,
           508.,   96., -222.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2430., 2148., 1730., 1676., 1538., 1704., 2436., 1702., 1812., 1662.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0084 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.14s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  196.,   494.,   868.,   766.,   796.,   842.,   186.,   760.,
            538.,   880.,   742.,  1204.,   420.,   728., -1142.,   796.,
            458.,  -554.,   190.,  1380.,   268.,    72.,    66.,   312.,
            380.,   320.,   460.,   380.,   724.,   226.,   792.,   614.,
           -180.,  3250.,   764.,  1574.,   762.,   360.,   516.,  1166.,
            642.,  -110.,  -192.],
         [  196.,   494.,   868.,   766.,   796.,   842.,   186.,   760.,
            538.,   880.,   742.,  1204.,   420.,   728., -1142.,   796.,
            458.,  -554.,   190.,  1380.,   268.,    72.,    66.,   312.,
            380.,   320.,   460.,   380.,   724.,   226.,   792.,   614.,
           -180.,  3250.,   764.,  1574.,   762.,   360.,   516.,  1166.,
            642.,  -110.,  -192.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3054., 2756., 2382., 2484., 2454., 2408., 3064., 2490., 2712., 2370.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1467 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.09s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 102.,  364.,  834.,  844.,  954.,  844.,  164.,  834.,  644.,  894.,
           592.,  986.,  402.,  898., -960.,  762.,  532., -400.,  268., 1330.,
           410.,   10.,   44.,  266.,  214.,  286.,  494.,  418.,  718.,  480.,
           578.,  572., -146., 2536.,  474., 2080.,  828.,  454.,  494., 1364.,
           508.,  200., -262.],
         [ 102.,  364.,  834.,  844.,  954.,  844.,  164.,  834.,  644.,  894.,
           592.,  986.,  402.,  898., -960.,  762.,  532., -400.,  268., 1330.,
           410.,   10.,   44.,  266.,  214.,  286.,  494.,  418.,  718.,  480.,
           578.,  572., -146., 2536.,  474., 2080.,  828.,  454.,  494., 1364.,
           508.,  200., -262.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2434., 2172., 1702., 1692., 1582., 1692., 2372., 1702., 1892., 1642.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0976 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.19s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   78.,   496.,   906.,   732.,   842.,   828.,   196.,   814.,
            488.,   938.,   776.,  1238.,   370.,   710., -1128.,   790.,
            468.,  -596.,   184.,  1358.,   210.,    26.,    96.,   366.,
            266.,   382.,   490.,   438.,   758.,   324.,   746.,   640.,
           -190.,  3236.,   674.,  1624.,   664.,   354.,   590.,  1160.,
            576.,  -104.,  -266.],
         [   78.,   496.,   906.,   732.,   842.,   828.,   196.,   814.,
            488.,   938.,   776.,  1238.,   370.,   710., -1128.,   790.,
            468.,  -596.,   184.,  1358.,   210.,    26.,    96.,   366.,
            266.,   382.,   490.,   438.,   758.,   324.,   746.,   640.,
           -190.,  3236.,   674.,  1624.,   664.,   354.,   590.,  1160.,
            576.,  -104.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3158., 2740., 2330., 2504., 2394., 2408., 3040., 2422., 2748., 2298.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2019 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 250.,  408.,  878.,  756., 1006.,  816.,  216.,  786.,  632.,  906.,
           712., 1014.,  518.,  918., -984.,  782.,  604., -488.,  172., 1302.,
           414.,   30.,   52.,  230.,  302.,  306.,  514.,  386.,  750.,  456.,
           618.,  484., -234., 2544.,  394., 2132.,  804.,  362.,  510., 1296.,
           628.,  140., -234.],
         [ 250.,  408.,  878.,  756., 1006.,  816.,  216.,  786.,  632.,  906.,
           712., 1014.,  518.,  918., -984.,  782.,  604., -488.,  172., 1302.,
           414.,   30.,   52.,  230.,  302.,  306.,  514.,  386.,  750.,  456.,
           618.,  484., -234., 2544.,  394., 2132.,  804.,  362.,  510., 1296.,
           628.,  140., -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2294., 2136., 1666., 1788., 1538., 1728., 2328., 1758., 1912., 1638.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9924 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.06s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  144.,   430.,   888.,   790.,   844.,   866.,   182.,   788.,
            510.,   928.,   738.,  1208.,   324.,   748., -1094.,   780.,
            422.,  -574.,   170.,  1372.,   276.,   -32.,   -14.,   424.,
            292.,   320.,   500.,   388.,   696.,   294.,   788.,   610.,
           -248.,  3190.,   648.,  1514.,   738.,   452.,   472.,  1226.,
            646.,   -90.,  -200.],
         [  144.,   430.,   888.,   790.,   844.,   866.,   182.,   788.,
            510.,   928.,   738.,  1208.,   324.,   748., -1094.,   780.,
            422.,  -574.,   170.,  1372.,   276.,   -32.,   -14.,   424.,
            292.,   320.,   500.,   388.,   696.,   294.,   788.,   610.,
           -248.,  3190.,   648.,  1514.,   738.,   452.,   472.,  1226.,
            646.,   -90.,  -200.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3046., 2760., 2302., 2400., 2346., 2324., 3008., 2402., 2680., 2262.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0624 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  182.,   424.,   898.,   844.,   982.,   888.,   116.,   846.,
            572.,   906.,   656.,   946.,   442.,   954., -1004.,   834.,
            552.,  -524.,   152.,  1298.,   410.,    62.,   -36.,   270.,
            226.,   310.,   522.,   450.,   782.,   464.,   586.,   644.,
           -190.,  2564.,   458.,  2104.,   808.,   394.,   458.,  1336.,
            512.,   148.,  -270.],
         [  182.,   424.,   898.,   844.,   982.,   888.,   116.,   846.,
            572.,   906.,   656.,   946.,   442.,   954., -1004.,   834.,
            552.,  -524.,   152.,  1298.,   410.,    62.,   -36.,   270.,
            226.,   310.,   522.,   450.,   782.,   464.,   586.,   644.,
           -190.,  2564.,   458.,  2104.,   808.,   394.,   458.,  1336.,
            512.,   148.,  -270.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2382., 2140., 1666., 1720., 1582., 1676., 2448., 1718., 1992., 1658.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9721 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   484.,   906.,   740.,   750.,   968.,   160.,   834.,
            540.,   878.,   744.,  1246.,   470.,   670., -1164.,   718.,
            420.,  -612.,    36.,  1358.,   274.,   102.,     4.,   446.,
            286.,   310.,   526.,   406.,   742.,   344.,   850.,   572.,
           -206.,  3120.,   686.,  1504.,   732.,   378.,   490.,  1184.,
            600.,   -68.,  -182.],
         [  102.,   484.,   906.,   740.,   750.,   968.,   160.,   834.,
            540.,   878.,   744.,  1246.,   470.,   670., -1164.,   718.,
            420.,  -612.,    36.,  1358.,   274.,   102.,     4.,   446.,
            286.,   310.,   526.,   406.,   742.,   344.,   850.,   572.,
           -206.,  3120.,   686.,  1504.,   732.,   378.,   490.,  1184.,
            600.,   -68.,  -182.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3018., 2636., 2214., 2380., 2370., 2152., 2960., 2286., 2580., 2242.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9696 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 188.,  274.,  896.,  786.,  876.,  926.,  258.,  784.,  670.,  740.,
           590., 1012.,  428.,  876., -994.,  720.,  594., -458.,  166., 1360.,
           360.,   80.,  138.,  284.,  400.,  392.,  488.,  460.,  780.,  482.,
           748.,  486., -168., 2558.,  448., 2122.,  798.,  208.,  444., 1294.,
           570.,  -26., -240.],
         [ 188.,  274.,  896.,  786.,  876.,  926.,  258.,  784.,  670.,  740.,
           590., 1012.,  428.,  876., -994.,  720.,  594., -458.,  166., 1360.,
           360.,   80.,  138.,  284.,  400.,  392.,  488.,  460.,  780.,  482.,
           748.,  486., -168., 2558.,  448., 2122.,  798.,  208.,  444., 1294.,
           570.,  -26., -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2370., 2284., 1662., 1772., 1682., 1632., 2300., 1774., 1888., 1818.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9678 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  162.,   480.,   918.,   816.,   838.,   872.,   204.,   738.,
            528.,   846.,   744.,  1214.,   466.,   706., -1096.,   770.,
            448.,  -576.,   196.,  1418.,   286.,   170.,     0.,   370.,
            350.,   414.,   458.,   490.,   806.,   328.,   766.,   580.,
           -178.,  3160.,   686.,  1520.,   624.,   366.,   474.,  1188.,
            676.,  -168.,  -230.],
         [  162.,   480.,   918.,   816.,   838.,   872.,   204.,   738.,
            528.,   846.,   744.,  1214.,   466.,   706., -1096.,   770.,
            448.,  -576.,   196.,  1418.,   286.,   170.,     0.,   370.,
            350.,   414.,   458.,   490.,   806.,   328.,   766.,   580.,
           -178.,  3160.,   686.,  1520.,   624.,   366.,   474.,  1188.,
            676.,  -168.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2998., 2680., 2242., 2344., 2322., 2288., 2956., 2422., 2632., 2314.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0049 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 174.,  508.,  826.,  760.,  934.,  884.,  152.,  786.,  632.,  910.,
           728., 1034.,  446.,  958., -996.,  750.,  648., -504.,  144., 1334.,
           430.,   66.,  116.,  310.,  174.,  266.,  514.,  422.,  730.,  340.,
           674.,  504., -210., 2580.,  542., 2116.,  784.,  350.,  518., 1340.,
           564.,   80., -306.],
         [ 174.,  508.,  826.,  760.,  934.,  884.,  152.,  786.,  632.,  910.,
           728., 1034.,  446.,  958., -996.,  750.,  648., -504.,  144., 1334.,
           430.,   66.,  116.,  310.,  174.,  266.,  514.,  422.,  730.,  340.,
           674.,  504., -210., 2580.,  542., 2116.,  784.,  350.,  518., 1340.,
           564.,   80., -306.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2406., 2072., 1754., 1820., 1646., 1696., 2428., 1794., 1948., 1670.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0047 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   432.,   842.,   768.,   766.,   868.,   140.,   662.,
            480.,   850.,   700.,  1230.,   374.,   742., -1188.,   746.,
            476.,  -620.,   208.,  1502.,   274.,   106.,    16.,   370.,
            290.,   394.,   378.,   482.,   818.,   244.,   734.,   608.,
           -318.,  3160.,   706.,  1540.,   708.,   414.,   582.,  1180.,
            632.,  -120.,  -258.],
         [   74.,   432.,   842.,   768.,   766.,   868.,   140.,   662.,
            480.,   850.,   700.,  1230.,   374.,   742., -1188.,   746.,
            476.,  -620.,   208.,  1502.,   274.,   106.,    16.,   370.,
            290.,   394.,   378.,   482.,   818.,   244.,   734.,   608.,
           -318.,  3160.,   706.,  1540.,   708.,   414.,   582.,  1180.,
            632.,  -120.,  -258.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3086., 2728., 2318., 2392., 2394., 2292., 3020., 2498., 2680., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0297 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 114.,  324.,  902.,  824.,  966.,  832.,   92.,  718.,  704.,  882.,
           660.,  990.,  406.,  974., -912.,  774.,  528., -460.,  224., 1242.,
           478.,  -22.,    4.,  346.,  194.,  314.,  526.,  474.,  802.,  384.,
           586.,  552., -202., 2544.,  510., 2104.,  772.,  314.,  470., 1436.,
           568.,  160., -302.],
         [ 114.,  324.,  902.,  824.,  966.,  832.,   92.,  718.,  704.,  882.,
           660.,  990.,  406.,  974., -912.,  774.,  528., -460.,  224., 1242.,
           478.,  -22.,    4.,  346.,  194.,  314.,  526.,  474.,  802.,  384.,
           586.,  552., -202., 2544.,  510., 2104.,  772.,  314.,  470., 1436.,
           568.,  160., -302.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2430., 2220., 1642., 1720., 1578., 1712., 2452., 1826., 1840., 1662.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9803 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  126.,   452.,   942.,   728.,   782.,   828.,   184.,   770.,
            440.,   814.,   724.,  1214.,   410.,   734., -1192.,   786.,
            524.,  -564.,   212.,  1430.,   286.,   102.,    28.,   386.,
            354.,   362.,   386.,   454.,   838.,   232.,   762.,   572.,
           -242.,  3240.,   694.,  1552.,   676.,   338.,   510.,  1168.,
            580.,   -96.,  -222.],
         [  126.,   452.,   942.,   728.,   782.,   828.,   184.,   770.,
            440.,   814.,   724.,  1214.,   410.,   734., -1192.,   786.,
            524.,  -564.,   212.,  1430.,   286.,   102.,    28.,   386.,
            354.,   362.,   386.,   454.,   838.,   232.,   762.,   572.,
           -242.,  3240.,   694.,  1552.,   676.,   338.,   510.,  1168.,
            580.,   -96.,  -222.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3114., 2788., 2298., 2512., 2458., 2412., 3056., 2470., 2800., 2426.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9716 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.08s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  80.,  370.,  876.,  830.,  964.,  822.,  122.,  816.,  718.,  832.,
           698., 1000.,  412.,  932., -982.,  864.,  558., -510.,  178., 1280.,
           440.,   16.,   30.,  312.,  200.,  372.,  504.,  492.,  772.,  442.,
           688.,  502., -224., 2638.,  396., 2146.,  794.,  348.,  536., 1370.,
           594.,   78., -184.],
         [  80.,  370.,  876.,  830.,  964.,  822.,  122.,  816.,  718.,  832.,
           698., 1000.,  412.,  932., -982.,  864.,  558., -510.,  178., 1280.,
           440.,   16.,   30.,  312.,  200.,  372.,  504.,  492.,  772.,  442.,
           688.,  502., -224., 2638.,  396., 2146.,  794.,  348.,  536., 1370.,
           594.,   78., -184.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2558., 2268., 1762., 1808., 1674., 1816., 2516., 1822., 1920., 1806.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0874 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   94.,   388.,   822.,   688.,   874.,   904.,   232.,   870.,
            536.,   842.,   676.,  1170.,   486.,   774., -1128.,   746.,
            524.,  -568.,   188.,  1386.,   234.,    94.,     0.,   346.,
            238.,   358.,   474.,   426.,   810.,   284.,   770.,   644.,
           -234.,  3236.,   622.,  1636.,   632.,   414.,   502.,  1368.,
            572.,   -44.,  -234.],
         [   94.,   388.,   822.,   688.,   874.,   904.,   232.,   870.,
            536.,   842.,   676.,  1170.,   486.,   774., -1128.,   746.,
            524.,  -568.,   188.,  1386.,   234.,    94.,     0.,   346.,
            238.,   358.,   474.,   426.,   810.,   284.,   770.,   644.,
           -234.,  3236.,   622.,  1636.,   632.,   414.,   502.,  1368.,
            572.,   -44.,  -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2848., 2414., 2548., 2362., 2332., 3004., 2366., 2700., 2394.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9757 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 170.,  420.,  854.,  732., 1014.,  828.,  140.,  738.,  644.,  918.,
           680., 1006.,  370.,  942., -972.,  874.,  548., -500.,  120., 1302.,
           410.,    6.,   20.,  290.,  162.,  386.,  522.,  510.,  738.,  436.,
           626.,  468., -106., 2572.,  506., 2128.,  844.,  402.,  514., 1388.,
           548.,  104., -290.],
         [ 170.,  420.,  854.,  732., 1014.,  828.,  140.,  738.,  644.,  918.,
           680., 1006.,  370.,  942., -972.,  874.,  548., -500.,  120., 1302.,
           410.,    6.,   20.,  290.,  162.,  386.,  522.,  510.,  738.,  436.,
           626.,  468., -106., 2572.,  506., 2128.,  844.,  402.,  514., 1388.,
           548.,  104., -290.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2402., 2152., 1718., 1840., 1558., 1744., 2432., 1834., 1928., 1654.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9671 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   398.,   836.,   802.,   816.,   786.,    90.,   764.,
            482.,   840.,   734.,  1192.,   336.,   708., -1042.,   740.,
            482.,  -622.,   138.,  1448.,   248.,    68.,    30.,   348.,
            364.,   360.,   472.,   508.,   744.,   286.,   744.,   610.,
           -160.,  3242.,   672.,  1642.,   702.,   408.,   528.,  1222.,
            602.,   -66.,  -204.],
         [   88.,   398.,   836.,   802.,   816.,   786.,    90.,   764.,
            482.,   840.,   734.,  1192.,   336.,   708., -1042.,   740.,
            482.,  -622.,   138.,  1448.,   248.,    68.,    30.,   348.,
            364.,   360.,   472.,   508.,   744.,   286.,   744.,   610.,
           -160.,  3242.,   672.,  1642.,   702.,   408.,   528.,  1222.,
            602.,   -66.,  -204.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3154., 2844., 2406., 2440., 2426., 2456., 3152., 2478., 2760., 2402.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9697 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  162.,   372.,   830.,   852.,   954.,   812.,   256.,   730.,
            584.,   858.,   688.,   998.,   334.,   978., -1012.,   722.,
            604.,  -512.,   160.,  1438.,   318.,   218.,    40.,   338.,
            210.,   226.,   458.,   530.,   846.,   400.,   702.,   512.,
           -198.,  2656.,   442.,  2180.,   860.,   270.,   478.,  1288.,
            612.,   180.,  -206.],
         [  162.,   372.,   830.,   852.,   954.,   812.,   256.,   730.,
            584.,   858.,   688.,   998.,   334.,   978., -1012.,   722.,
            604.,  -512.,   160.,  1438.,   318.,   218.,    40.,   338.,
            210.,   226.,   458.,   530.,   846.,   400.,   702.,   512.,
           -198.,  2656.,   442.,  2180.,   860.,   270.,   478.,  1288.,
            612.,   180.,  -206.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2494., 2284., 1826., 1804., 1702., 1844., 2400., 1926., 2072., 1798.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9684 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   80.,   446.,   868.,   794.,   756.,   890.,   154.,   756.,
            510.,   872.,   734.,  1204.,   420.,   812., -1090.,   736.,
            538.,  -630.,   118.,  1364.,   248.,   132.,    -6.,   420.,
            216.,   388.,   584.,   496.,   876.,   318.,   780.,   710.,
           -232.,  3190.,   672.,  1530.,   574.,   408.,   488.,  1266.,
            626.,  -122.,  -236.],
         [   80.,   446.,   868.,   794.,   756.,   890.,   154.,   756.,
            510.,   872.,   734.,  1204.,   420.,   812., -1090.,   736.,
            538.,  -630.,   118.,  1364.,   248.,   132.,    -6.,   420.,
            216.,   388.,   584.,   496.,   876.,   318.,   780.,   710.,
           -232.,  3190.,   672.,  1530.,   574.,   408.,   488.,  1266.,
            626.,  -122.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3110., 2744., 2322., 2396., 2434., 2300., 3036., 2434., 2680., 2318.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9641 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 162.,  528.,  842.,  836., 1006.,  948.,  184.,  738.,  596.,  798.,
           652., 1018.,  434.,  974., -972.,  802.,  564., -448.,  132., 1326.,
           390.,   18.,   20.,  318.,  214.,  254.,  510.,  358.,  706.,  400.,
           674.,  580., -226., 2644.,  586., 2136.,  864.,  350.,  554., 1248.,
           596.,  112., -210.],
         [ 162.,  528.,  842.,  836., 1006.,  948.,  184.,  738.,  596.,  798.,
           652., 1018.,  434.,  974., -972.,  802.,  564., -448.,  132., 1326.,
           390.,   18.,   20.,  318.,  214.,  254.,  510.,  358.,  706.,  400.,
           674.,  580., -226., 2644.,  586., 2136.,  864.,  350.,  554., 1248.,
           596.,  112., -210.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2482., 2116., 1802., 1808., 1638., 1696., 2460., 1906., 2048., 1846.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9650 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  120.,   462.,   948.,   894.,   860.,   890.,   146.,   772.,
            434.,   904.,   674.,  1180.,   444.,   804., -1146.,   828.,
            518.,  -546.,   214.,  1328.,   308.,    12.,   -34.,   440.,
            244.,   400.,   460.,   460.,   772.,   322.,   724.,   570.,
           -148.,  3194.,   816.,  1554.,   638.,   500.,   520.,  1218.,
            578.,  -118.,  -244.],
         [  120.,   462.,   948.,   894.,   860.,   890.,   146.,   772.,
            434.,   904.,   674.,  1180.,   444.,   804., -1146.,   828.,
            518.,  -546.,   214.,  1328.,   308.,    12.,   -34.,   440.,
            244.,   400.,   460.,   460.,   772.,   322.,   724.,   570.,
           -148.,  3194.,   816.,  1554.,   638.,   500.,   520.,  1218.,
            578.,  -118.,  -244.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3074., 2732., 2246., 2300., 2334., 2304., 3048., 2422., 2760., 2290.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9663 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  56.,  362.,  848.,  870., 1036.,  802.,  146.,  828.,  638.,  800.,
           646.,  948.,  344.,  956., -938.,  824.,  426., -410.,  242., 1308.,
           428.,  140.,  102.,  324.,  188.,  324.,  528.,  472.,  708.,  398.,
           592.,  558., -140., 2582.,  560., 2142.,  866.,  376.,  408., 1382.,
           602.,  170., -264.],
         [  56.,  362.,  848.,  870., 1036.,  802.,  146.,  828.,  638.,  800.,
           646.,  948.,  344.,  956., -938.,  824.,  426., -410.,  242., 1308.,
           428.,  140.,  102.,  324.,  188.,  324.,  528.,  472.,  708.,  398.,
           592.,  558., -140., 2582.,  560., 2142.,  866.,  376.,  408., 1382.,
           602.,  170., -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2526., 2220., 1734., 1712., 1546., 1780., 2436., 1754., 1944., 1782.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9667 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.96s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  140.,   418.,   880.,   722.,   844.,   910.,   190.,   748.,
            530.,   884.,   686.,  1228.,   480.,   740., -1102.,   748.,
            486.,  -510.,   134.,  1404.,   288.,   108.,   -54.,   404.,
            264.,   372.,   508.,   420.,   752.,   390.,   856.,   590.,
           -144.,  3182.,   684.,  1506.,   698.,   276.,   444.,  1210.,
            594.,  -118.,  -100.],
         [  140.,   418.,   880.,   722.,   844.,   910.,   190.,   748.,
            530.,   884.,   686.,  1228.,   480.,   740., -1102.,   748.,
            486.,  -510.,   134.,  1404.,   288.,   108.,   -54.,   404.,
            264.,   372.,   508.,   420.,   752.,   390.,   856.,   590.,
           -144.,  3182.,   684.,  1506.,   698.,   276.,   444.,  1210.,
            594.,  -118.,  -100.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3042., 2764., 2302., 2460., 2338., 2272., 2992., 2434., 2652., 2298.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9653 seconds.
PGD attack failed
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/2): BoundBuffers(name=/2, inputs=[], perturbed=False)
  (/shape): BoundBuffers(name=/shape, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True)
  (/13): BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True)
  (/17): BoundSplit(name=/17, inputs=[/shape], perturbed=False)
  (/18): BoundSplit(name=/18, inputs=[/shape], perturbed=False)
  (/19): BoundSqueeze(name=/19, inputs=[/17], perturbed=False)
  (/20): BoundSqueeze(name=/20, inputs=[/18], perturbed=False)
  (/21): BoundUnsqueeze(name=/21, inputs=[/19], perturbed=False)
  (/22): BoundUnsqueeze(name=/22, inputs=[/20], perturbed=False)
  (/23): BoundConcat(name=/23, inputs=[/21, /22], perturbed=False)
  (/24): BoundReshape(name=/24, inputs=[/14/merge, /23], perturbed=True)
  (/25): BoundTranspose(name=/25, inputs=[/8], perturbed=False)
  (/26): BoundMatMul(name=/26, inputs=[/24, /25], perturbed=True)
  (/10/merge): BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
  (/14/merge): BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
)
Original output: tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
Split layers:
  BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True): [(BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True), 0)]
  BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True): [(BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True), 0)]
Nonlinear functions:
   BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
   BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
layer /10/merge using sparse-features alpha with shape [1322]; unstable size 1322; total size 12544 ([1, 16, 28, 28])
layer /10/merge start_node /13 using full alpha [4, 32, 1, 1322] with unstable size 31 total_size 32 output_shape 32
layer /10/merge start_node /26 using full alpha [4, 42, 1, 1322] with unstable size None total_size 42 output_shape 42
layer /14/merge using sparse-features alpha with shape [11044]; unstable size 11044; total size 23328 ([1, 32, 27, 27])
layer /14/merge start_node /26 using full alpha [4, 42, 1, 11044] with unstable size None total_size 42 output_shape 42
Optimizable variables initialized.
initial CROWN bounds: tensor([[ -8534.,  -9120.,  -9430.,  -9196.,  -9146.,  -9244.,  -8272.,  -8974.,
          -8740.,  -9162.,  -8796.,  -9102.,  -8854.,  -8866.,  -8032.,  -9270.,
          -8532.,  -8512.,  -9008.,  -9434.,  -9042.,  -8654.,  -8268.,  -8842.,
          -8222.,  -8778.,  -8946.,  -8846.,  -9330.,  -8820.,  -8782.,  -9040.,
          -8434.,  -8846.,  -9680.,  -9180.,  -8698.,  -8766., -10008.,  -8864.,
          -8756.,  -7850.]], device='cuda:0') None
best_l after optimization: -359486.03125
alpha/beta optimization time: 1.0813496112823486
initial alpha-crown bounds: tensor([[-8534.00000000, -8447.96972656, -8099.01660156, -8216.12207031,
         -8279.03417969, -8208.43945312, -8272.00000000, -8974.00000000,
         -8740.00000000, -8348.96191406, -8796.00000000, -8915.88085938,
         -8854.00000000, -8866.00000000, -8032.00000000, -8136.18505859,
         -8532.00000000, -8512.00000000, -8881.83984375, -8319.00488281,
         -8694.54199219, -8654.00000000, -8268.00000000, -8842.00000000,
         -8222.00000000, -8778.00000000, -8845.07226562, -8846.00000000,
         -8233.36816406, -8820.00000000, -8782.00000000, -8919.04882812,
         -8434.00000000, -8846.00000000, -8436.19335938, -8294.70410156,
         -8698.00000000, -8766.00000000, -8672.63769531, -8864.00000000,
         -8756.00000000, -7850.00000000]], device='cuda:0')
Worst class: (+ rhs) -8974.0
Total VNNLIB file length: 42, max property batch size: 1, total number of batches: 42
lA shape: [torch.Size([42, 1, 16, 28, 28]), torch.Size([42, 1, 32, 27, 27])]

Properties batch 0, size 1
Remaining timeout: 835.416749715805
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-8534.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
setting alpha for layer /10/merge start_node /26 with alignment adjustment
setting alpha for layer /14/merge start_node /26 with alignment adjustment
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-8534.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 14011] 
split level 1: [/13, 11149] 
split level 2: [/13, 3103] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 0.00010967254638671875
Time: prepare 0.0008    bound 0.2555    transfer 0.0003    finalize 0.0008    func 0.2574    
Accumulated time: func 0.2574    prepare 0.0014    bound 0.2555    transfer 0.0003    finalize 0.0008    
Current worst splitting domains lb-rhs (depth):
-7068.63281 (3), -7068.56299 (3), -7068.33154 (3), -7068.23730 (3), -7067.65820 (3), -7067.59717 (3), -7067.53320 (3), -7067.48584 (3), 
length of domains: 8
Time: pickout 0.0003    decision 0.2282    set_bounds 0.0022    solve 0.2574    add 0.0203    
Accumulated time: pickout 0.0003    decision 0.2282    set_bounds 0.0022    solve 0.2574    add 0.0203    
Current (lb-rhs): -7068.6328125
8 domains visited
Cumulative time: 0.6677215099334717

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8149] [/9, 8515] [/9, 8004] [/9, 8515] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 5.364418029785156e-05
Time: prepare 0.0022    bound 0.0830    transfer 0.0003    finalize 0.0011    func 0.0867    
Accumulated time: func 0.3440    prepare 0.0042    bound 0.3385    transfer 0.0006    finalize 0.0019    
Current worst splitting domains lb-rhs (depth):
-6782.29102 (4), -6782.27881 (4), -6781.95752 (4), -6781.89404 (4), -6780.96631 (4), -6780.08105 (4), -6780.06250 (4), -6779.86133 (4), -6779.81641 (4), -6779.78662 (4), -6779.72314 (4), -6779.33789 (4), -6777.91016 (4), -6777.89258 (4), -6777.69092 (4), -6777.64551 (4), 
length of domains: 16
Time: pickout 0.0006    decision 0.0336    set_bounds 0.0023    solve 0.0867    add 0.0019    
Accumulated time: pickout 0.0009    decision 0.2618    set_bounds 0.0046    solve 0.3441    add 0.0221    
Current (lb-rhs): -6782.291015625
24 domains visited
Cumulative time: 0.7929542064666748

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/9, 11622] [/9, 11622] [/9, 11622] [/13, 5412] [/9, 8515] [/9, 11622] [/9, 8515] [/9, 11622] [/9, 11622] [/9, 11622] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 5.5789947509765625e-05
Time: prepare 0.0023    bound 0.0818    transfer 0.0006    finalize 0.0021    func 0.0867    
Accumulated time: func 0.4307    prepare 0.0068    bound 0.4203    transfer 0.0011    finalize 0.0039    
Current worst splitting domains lb-rhs (depth):
-6742.26318 (5), -6742.16992 (5), -6741.80957 (5), -6741.79883 (5), -6741.66895 (5), -6741.65820 (5), -6741.02832 (5), -6740.37842 (5), -6740.28467 (5), -6740.11816 (5), -6740.11621 (5), -6740.10693 (5), -6740.10498 (5), -6739.87939 (5), -6739.81543 (5), -6739.80469 (5), -6739.73877 (5), -6739.73682 (5), -6739.73682 (5), -6739.47900 (5), 
length of domains: 32
Time: pickout 0.0006    decision 0.0297    set_bounds 0.0025    solve 0.0867    add 0.0038    
Accumulated time: pickout 0.0015    decision 0.2915    set_bounds 0.0070    solve 0.4309    add 0.0259    
Current (lb-rhs): -6742.26318359375
56 domains visited
Cumulative time: 0.9163715839385986

BaB round 4
batch: 32
Average branched neurons at iteration 4:  1.0000
splitting decisions: 
split level 0: [/9, 8004] [/9, 8004] [/9, 8004] [/9, 11622] [/9, 11622] [/9, 8004] [/9, 11622] [/13, 5412] [/9, 8004] [/9, 8004] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 5.555152893066406e-05
Time: prepare 0.0045    bound 0.1275    transfer 0.0010    finalize 0.0069    func 0.1399    
Accumulated time: func 0.5706    prepare 0.0115    bound 0.5478    transfer 0.0021    finalize 0.0108    
Current worst splitting domains lb-rhs (depth):
-6732.12939 (6), -6732.09814 (6), -6732.00732 (6), -6731.97559 (6), -6731.62695 (6), -6731.62305 (6), -6731.24658 (6), -6731.24219 (6), -6731.24219 (6), -6730.75293 (6), -6730.72168 (6), -6730.46289 (6), -6730.45850 (6), -6730.30762 (6), -6730.18555 (6), -6730.09180 (6), -6730.08691 (6), -6730.06738 (6), -6729.91016 (6), -6729.90527 (6), 
length of domains: 64
Time: pickout 0.0009    decision 0.0516    set_bounds 0.0043    solve 0.1400    add 0.0074    
Accumulated time: pickout 0.0024    decision 0.3431    set_bounds 0.0113    solve 0.5708    add 0.0332    
Current (lb-rhs): -6732.12939453125
120 domains visited
Cumulative time: 1.1206355094909668

BaB round 5
batch: 64
Average branched neurons at iteration 5:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8004] [/9, 8004] [/9, 8469] [/9, 8469] [/9, 8004] [/9, 8469] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0087    bound 0.2352    transfer 0.0019    finalize 0.0133    func 0.2591    
Accumulated time: func 0.8297    prepare 0.0205    bound 0.7831    transfer 0.0040    finalize 0.0240    
Current worst splitting domains lb-rhs (depth):
-6730.90918 (7), -6730.88867 (7), -6730.86768 (7), -6730.84619 (7), -6730.82227 (7), -6730.80176 (7), -6730.40479 (7), -6730.35938 (7), -6730.33008 (7), -6730.28467 (7), -6730.08350 (7), -6730.08350 (7), -6730.00879 (7), -6729.96338 (7), -6729.77832 (7), -6729.75781 (7), -6729.52686 (7), -6729.50635 (7), -6729.48193 (7), -6729.46143 (7), 
length of domains: 128
Time: pickout 0.0026    decision 0.0939    set_bounds 0.0079    solve 0.2592    add 0.0140    
Accumulated time: pickout 0.0051    decision 0.4370    set_bounds 0.0191    solve 0.8300    add 0.0472    
Current (lb-rhs): -6730.9091796875
248 domains visited
Cumulative time: 1.4984838962554932

BaB round 6
batch: 128
Average branched neurons at iteration 6:  1.0000
splitting decisions: 
split level 0: [/9, 8439] [/13, 5689] [/9, 8439] [/9, 8469] [/9, 8469] [/9, 8439] [/9, 8439] [/9, 8469] [/9, 8439] [/9, 8439] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0172    bound 0.4353    transfer 0.0036    finalize 0.0289    func 0.4853    
Accumulated time: func 1.3150    prepare 0.0380    bound 1.2184    transfer 0.0077    finalize 0.0529    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.13721 (8), -6730.12891 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.36572 (8), -6729.35449 (8), -6729.34229 (8), -6729.32715 (8), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), 
length of domains: 256
Time: pickout 0.0063    decision 0.1805    set_bounds 0.0151    solve 0.4854    add 0.0361    
Accumulated time: pickout 0.0113    decision 0.6176    set_bounds 0.0342    solve 1.3153    add 0.0833    
Current (lb-rhs): -6730.1533203125
504 domains visited
Cumulative time: 2.2233474254608154

BaB round 7
batch: 128
Average branched neurons at iteration 7:  1.0000
splitting decisions: 
split level 0: [/9, 4644] [/9, 8439] [/9, 4644] [/9, 8439] [/9, 1857] [/13, 5362] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.841255187988281e-05
Time: prepare 0.0174    bound 0.4342    transfer 0.0036    finalize 0.0291    func 0.4844    
Accumulated time: func 1.7994    prepare 0.0558    bound 1.6526    transfer 0.0113    finalize 0.0820    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.70020 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6728.94775 (9), -6728.93945 (8), -6728.93115 (8), 
length of domains: 384
Time: pickout 0.0086    decision 0.1828    set_bounds 0.0153    solve 0.4845    add 0.0303    
Accumulated time: pickout 0.0200    decision 0.8004    set_bounds 0.0495    solve 1.7998    add 0.1137    
Current (lb-rhs): -6730.1533203125
760 domains visited
Cumulative time: 2.9452309608459473

BaB round 8
batch: 128
Average branched neurons at iteration 8:  1.0000
splitting decisions: 
split level 0: [/9, 4355] [/9, 4644] [/9, 4355] [/9, 4644] [/9, 8439] [/9, 4644] [/9, 4355] [/9, 8439] [/9, 4355] [/9, 4355] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.127357482910156e-05
Time: prepare 0.0171    bound 0.4380    transfer 0.0082    finalize 0.0312    func 0.4944    
Accumulated time: func 2.2939    prepare 0.0732    bound 2.0906    transfer 0.0195    finalize 0.1132    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 512
Time: pickout 0.0059    decision 0.1802    set_bounds 0.0152    solve 0.4945    add 0.0326    
Accumulated time: pickout 0.0259    decision 0.9806    set_bounds 0.0648    solve 2.2944    add 0.1462    
Current (lb-rhs): -6730.1533203125
1016 domains visited
Cumulative time: 3.673995018005371

BaB round 9
batch: 128
Average branched neurons at iteration 9:  1.0000
splitting decisions: 
split level 0: [/9, 1857] [/9, 4355] [/9, 1857] [/9, 1857] [/9, 4644] [/9, 4355] [/9, 1857] [/9, 4355] [/9, 1857] [/9, 1857] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.341934204101562e-05
Time: prepare 0.0172    bound 0.4359    transfer 0.0084    finalize 0.0312    func 0.4927    
Accumulated time: func 2.7866    prepare 0.0908    bound 2.5265    transfer 0.0278    finalize 0.1444    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 640
Time: pickout 0.0060    decision 0.1813    set_bounds 0.0151    solve 0.4928    add 0.0312    
Accumulated time: pickout 0.0319    decision 1.1618    set_bounds 0.0799    solve 2.7872    add 0.1775    
Current (lb-rhs): -6730.1533203125
1272 domains visited
Cumulative time: 4.402389049530029

BaB round 10
batch: 128
Average branched neurons at iteration 10:  1.0000
splitting decisions: 
split level 0: [/9, 8003] [/9, 1857] [/9, 7881] [/9, 4355] [/9, 4355] [/9, 1857] [/9, 8003] [/9, 1857] [/9, 7881] [/9, 7881] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.9604644775390625e-05
Time: prepare 0.0173    bound 0.4338    transfer 0.0036    finalize 0.0311    func 0.4859    
Accumulated time: func 3.2725    prepare 0.1084    bound 2.9603    transfer 0.0315    finalize 0.1755    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 768
Time: pickout 0.0065    decision 0.1798    set_bounds 0.0152    solve 0.4860    add 0.0311    
Accumulated time: pickout 0.0384    decision 1.3417    set_bounds 0.0950    solve 3.2732    add 0.2085    
Current (lb-rhs): -6730.1533203125
1528 domains visited
Cumulative time: 5.123058557510376

BaB round 11
batch: 128
Average branched neurons at iteration 11:  1.0000
splitting decisions: 
split level 0: [/9, 7881] [/9, 7881] [/9, 8003] [/9, 7881] [/9, 8003] [/9, 7881] [/9, 7881] [/9, 7881] [/9, 8003] [/9, 8003] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0189    bound 0.4305    transfer 0.0036    finalize 0.0314    func 0.4846    
Accumulated time: func 3.7571    prepare 0.1276    bound 3.3908    transfer 0.0351    finalize 0.2070    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 896
Time: pickout 0.0062    decision 0.1828    set_bounds 0.0152    solve 0.4847    add 0.0315    
Accumulated time: pickout 0.0445    decision 1.5245    set_bounds 0.1102    solve 3.7579    add 0.2400    
Current (lb-rhs): -6730.1533203125
1784 domains visited
Cumulative time: 5.845514297485352

BaB round 12
batch: 128
Average branched neurons at iteration 12:  1.0000
splitting decisions: 
split level 0: [/9, 8149] [/9, 8003] [/9, 8149] [/9, 8003] [/9, 7881] [/9, 8003] [/9, 11140] [/9, 8003] [/9, 8516] [/9, 8516] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.198883056640625e-05
Time: prepare 0.0175    bound 0.4363    transfer 0.0037    finalize 0.0312    func 0.4886    
Accumulated time: func 4.2457    prepare 0.1454    bound 3.8271    transfer 0.0388    finalize 0.2381    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1024
Time: pickout 0.0059    decision 0.1803    set_bounds 0.0151    solve 0.4887    add 0.0320    
Accumulated time: pickout 0.0504    decision 1.7049    set_bounds 0.1254    solve 4.2466    add 0.2720    
Current (lb-rhs): -6730.1533203125
2040 domains visited
Cumulative time: 6.567900657653809

BaB round 13
batch: 128
Average branched neurons at iteration 13:  1.0000
splitting decisions: 
split level 0: [/9, 8516] [/9, 8516] [/9, 8516] [/9, 8516] [/9, 11140] [/9, 8516] [/9, 8149] [/9, 8516] [/9, 8149] [/9, 8149] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.936622619628906e-05
Time: prepare 0.0172    bound 0.4335    transfer 0.0036    finalize 0.0153    func 0.4698    
Accumulated time: func 4.7155    prepare 0.1629    bound 4.2607    transfer 0.0424    finalize 0.2535    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1152
Time: pickout 0.0059    decision 0.1808    set_bounds 0.0152    solve 0.4699    add 0.3844    
Accumulated time: pickout 0.0563    decision 1.8857    set_bounds 0.1406    solve 4.7165    add 0.6564    
Current (lb-rhs): -6730.1533203125
2296 domains visited
Cumulative time: 7.624340534210205

BaB round 14
batch: 128
Average branched neurons at iteration 14:  1.0000
splitting decisions: 
split level 0: [/9, 11066] [/9, 8149] [/9, 11066] [/9, 8149] [/9, 8516] [/9, 8149] [/9, 8516] [/9, 8149] [/9, 11066] [/9, 11066] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0174    bound 0.4342    transfer 0.0037    finalize 0.0154    func 0.4707    
Accumulated time: func 5.1862    prepare 0.1806    bound 4.6949    transfer 0.0461    finalize 0.2689    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1280
Time: pickout 0.0059    decision 0.1808    set_bounds 0.0152    solve 0.4708    add 0.0293    
Accumulated time: pickout 0.0622    decision 2.0664    set_bounds 0.1558    solve 5.1873    add 0.6857    
Current (lb-rhs): -6730.1533203125
2552 domains visited
Cumulative time: 8.326613664627075

BaB round 15
batch: 128
Average branched neurons at iteration 15:  1.0000
splitting decisions: 
split level 0: [/9, 11621] [/9, 11066] [/9, 11621] [/9, 11066] [/9, 11066] [/9, 11066] [/9, 11066] [/9, 11066] [/9, 11621] [/9, 11621] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.9604644775390625e-05
Time: prepare 0.0173    bound 0.4325    transfer 0.0037    finalize 0.0155    func 0.4690    
Accumulated time: func 5.6552    prepare 0.1982    bound 5.1274    transfer 0.0497    finalize 0.2844    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1408
Time: pickout 0.0063    decision 0.1789    set_bounds 0.0152    solve 0.4690    add 0.0289    
Accumulated time: pickout 0.0685    decision 2.2453    set_bounds 0.1709    solve 5.6563    add 0.7146    
Current (lb-rhs): -6730.1533203125
2808 domains visited
Cumulative time: 9.025254964828491

BaB round 16
batch: 128
Average branched neurons at iteration 16:  1.0000
splitting decisions: 
split level 0: [/9, 8513] [/9, 2039] [/9, 2039] [/9, 11621] [/9, 8032] [/9, 11621] [/9, 11621] [/9, 11621] [/9, 8513] [/9, 2039] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.103515625e-05
Time: prepare 0.0201    bound 0.4327    transfer 0.0036    finalize 0.0155    func 0.4720    
Accumulated time: func 6.1272    prepare 0.2186    bound 5.5601    transfer 0.0534    finalize 0.2999    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1536
Time: pickout 0.0060    decision 0.1803    set_bounds 0.0155    solve 0.4721    add 0.0288    
Accumulated time: pickout 0.0745    decision 2.4256    set_bounds 0.1864    solve 6.1284    add 0.7434    
Current (lb-rhs): -6730.1533203125
3064 domains visited
Cumulative time: 9.728380918502808

BaB round 17
batch: 128
Average branched neurons at iteration 17:  1.0000
splitting decisions: 
split level 0: [/9, 2039] [/9, 11621] [/9, 8513] [/9, 7894] [/9, 11621] [/9, 2039] [/9, 7894] [/9, 7894] [/9, 8032] [/9, 7894] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0175    bound 0.4345    transfer 0.0037    finalize 0.0154    func 0.4711    
Accumulated time: func 6.5983    prepare 0.2364    bound 5.9946    transfer 0.0570    finalize 0.3153    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1664
Time: pickout 0.0056    decision 0.1809    set_bounds 0.0153    solve 0.4712    add 0.0333    
Accumulated time: pickout 0.0802    decision 2.6065    set_bounds 0.2017    solve 6.5996    add 0.7767    
Current (lb-rhs): -6730.1533203125
3320 domains visited
Cumulative time: 10.435012102127075

BaB round 18
batch: 128
Average branched neurons at iteration 18:  1.0000
splitting decisions: 
split level 0: [/9, 8032] [/9, 7894] [/9, 8032] [/9, 2039] [/9, 7894] [/9, 7894] [/9, 8513] [/9, 8513] [/9, 2039] [/9, 8513] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0174    bound 0.4323    transfer 0.0037    finalize 0.0153    func 0.4687    
Accumulated time: func 7.0670    prepare 0.2541    bound 6.4269    transfer 0.0607    finalize 0.3306    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1792
Time: pickout 0.0065    decision 0.1795    set_bounds 0.0152    solve 0.4692    add 0.0307    
Accumulated time: pickout 0.0867    decision 2.7861    set_bounds 0.2169    solve 7.0688    add 0.8074    
Current (lb-rhs): -6730.1533203125
3576 domains visited
Cumulative time: 11.136425018310547

BaB round 19
batch: 128
Average branched neurons at iteration 19:  1.0000
splitting decisions: 
split level 0: [/9, 11653] [/9, 8513] [/9, 11653] [/9, 8513] [/9, 2039] [/9, 8513] [/9, 2039] [/9, 2039] [/9, 11653] [/9, 8032] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0201    bound 0.4317    transfer 0.0036    finalize 0.0153    func 0.4708    
Accumulated time: func 7.5378    prepare 0.2746    bound 6.8586    transfer 0.0643    finalize 0.3459    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 1920
Time: pickout 0.0061    decision 0.1808    set_bounds 0.0154    solve 0.4709    add 0.0309    
Accumulated time: pickout 0.0928    decision 2.9668    set_bounds 0.2322    solve 7.5397    add 0.8383    
Current (lb-rhs): -6730.1533203125
3832 domains visited
Cumulative time: 11.840875148773193

BaB round 20
batch: 128
Average branched neurons at iteration 20:  1.0000
splitting decisions: 
split level 0: [/9, 11140] [/9, 8032] [/9, 11140] [/9, 8032] [/9, 8513] [/9, 11653] [/9, 11653] [/9, 11653] [/9, 11140] [/9, 11653] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0176    bound 0.4361    transfer 0.0036    finalize 0.0155    func 0.4729    
Accumulated time: func 8.0107    prepare 0.2925    bound 7.2947    transfer 0.0680    finalize 0.3614    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2048
Time: pickout 0.0061    decision 0.1794    set_bounds 0.0153    solve 0.4730    add 0.0293    
Accumulated time: pickout 0.0989    decision 3.1463    set_bounds 0.2475    solve 8.0127    add 0.8676    
Current (lb-rhs): -6730.1533203125
4088 domains visited
Cumulative time: 12.544341087341309

BaB round 21
batch: 128
Average branched neurons at iteration 21:  1.0000
splitting decisions: 
split level 0: [/9, 4568] [/9, 11653] [/9, 4568] [/9, 11653] [/9, 11653] [/9, 8032] [/9, 8032] [/9, 8032] [/9, 10019] [/9, 11140] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0174    bound 0.4345    transfer 0.0037    finalize 0.0153    func 0.4709    
Accumulated time: func 8.4816    prepare 0.3102    bound 7.7292    transfer 0.0716    finalize 0.3768    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2176
Time: pickout 0.0060    decision 0.1803    set_bounds 0.0152    solve 0.4710    add 0.6496    
Accumulated time: pickout 0.1049    decision 3.3266    set_bounds 0.2627    solve 8.4837    add 1.5172    
Current (lb-rhs): -6730.1533203125
4344 domains visited
Cumulative time: 13.86682915687561

BaB round 22
batch: 128
Average branched neurons at iteration 22:  1.0000
splitting decisions: 
split level 0: [/9, 2116] [/9, 11140] [/9, 10019] [/9, 11140] [/9, 4568] [/9, 11140] [/9, 4568] [/9, 11140] [/9, 2116] [/9, 10019] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.771087646484375e-05
Time: prepare 0.0174    bound 0.4440    transfer 0.0036    finalize 0.0154    func 0.4805    
Accumulated time: func 8.9621    prepare 0.3279    bound 8.1732    transfer 0.0753    finalize 0.3922    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2304
Time: pickout 0.0063    decision 0.1866    set_bounds 0.0160    solve 0.4806    add 0.0360    
Accumulated time: pickout 0.1112    decision 3.5132    set_bounds 0.2788    solve 8.9643    add 1.5532    
Current (lb-rhs): -6730.1533203125
4600 domains visited
Cumulative time: 14.592832088470459

BaB round 23
batch: 128
Average branched neurons at iteration 23:  1.0000
splitting decisions: 
split level 0: [/9, 10019] [/9, 4568] [/9, 8121] [/9, 4568] [/9, 11168] [/9, 8033] [/9, 2116] [/9, 8033] [/9, 8121] [/9, 2116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0176    bound 0.4394    transfer 0.0037    finalize 0.0160    func 0.4767    
Accumulated time: func 9.4388    prepare 0.3458    bound 8.6127    transfer 0.0790    finalize 0.4082    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2432
Time: pickout 0.0061    decision 0.1800    set_bounds 0.0152    solve 0.4768    add 0.0364    
Accumulated time: pickout 0.1172    decision 3.6932    set_bounds 0.2940    solve 9.4411    add 1.5896    
Current (lb-rhs): -6730.1533203125
4856 domains visited
Cumulative time: 15.3086519241333

BaB round 24
batch: 128
Average branched neurons at iteration 24:  1.0000
splitting decisions: 
split level 0: [/9, 8121] [/9, 10019] [/9, 2116] [/9, 2116] [/9, 2116] [/9, 4568] [/9, 10019] [/13, 5663] [/9, 7894] [/9, 8121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.818771362304688e-05
Time: prepare 0.0176    bound 0.4458    transfer 0.0037    finalize 0.0155    func 0.4826    
Accumulated time: func 9.9215    prepare 0.3638    bound 9.0585    transfer 0.0827    finalize 0.4236    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2560
Time: pickout 0.0058    decision 0.1838    set_bounds 0.0153    solve 0.4827    add 0.0356    
Accumulated time: pickout 0.1231    decision 3.8770    set_bounds 0.3093    solve 9.9238    add 1.6252    
Current (lb-rhs): -6730.1533203125
5112 domains visited
Cumulative time: 16.03331160545349

BaB round 25
batch: 128
Average branched neurons at iteration 25:  1.0000
splitting decisions: 
split level 0: [/9, 7894] [/9, 2116] [/9, 7894] [/9, 8121] [/9, 10019] [/9, 10019] [/9, 11168] [/9, 4568] [/9, 4329] [/9, 8553] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.556510925292969e-05
Time: prepare 0.0174    bound 0.4386    transfer 0.0036    finalize 0.0247    func 0.4843    
Accumulated time: func 10.4058    prepare 0.3816    bound 9.4971    transfer 0.0863    finalize 0.4483    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2688
Time: pickout 0.0060    decision 0.1830    set_bounds 0.0156    solve 0.4844    add 0.0336    
Accumulated time: pickout 0.1291    decision 4.0600    set_bounds 0.3249    solve 10.4083    add 1.6588    
Current (lb-rhs): -6730.1533203125
5368 domains visited
Cumulative time: 16.757137537002563

BaB round 26
batch: 128
Average branched neurons at iteration 26:  1.0000
splitting decisions: 
split level 0: [/9, 4516] [/9, 8121] [/9, 8553] [/9, 10019] [/9, 8148] [/9, 2116] [/9, 8121] [/13, 5362] [/9, 8260] [/9, 4329] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.580352783203125e-05
Time: prepare 0.0174    bound 0.4436    transfer 0.0037    finalize 0.0160    func 0.4807    
Accumulated time: func 10.8865    prepare 0.3994    bound 9.9407    transfer 0.0900    finalize 0.4643    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2816
Time: pickout 0.0069    decision 0.1838    set_bounds 0.0154    solve 0.4808    add 0.0364    
Accumulated time: pickout 0.1360    decision 4.2437    set_bounds 0.3403    solve 10.8891    add 1.6952    
Current (lb-rhs): -6730.1533203125
5624 domains visited
Cumulative time: 17.481637477874756

BaB round 27
batch: 128
Average branched neurons at iteration 27:  1.0000
splitting decisions: 
split level 0: [/9, 4329] [/9, 4516] [/9, 4516] [/9, 4516] [/9, 8121] [/9, 8260] [/9, 4516] [/13, 5583] [/9, 11121] [/9, 11121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0175    bound 0.4323    transfer 0.0036    finalize 0.0202    func 0.4737    
Accumulated time: func 11.3602    prepare 0.4172    bound 10.3730    transfer 0.0936    finalize 0.4845    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 2944
Time: pickout 0.0060    decision 0.1837    set_bounds 0.0153    solve 0.4738    add 0.0351    
Accumulated time: pickout 0.1420    decision 4.4274    set_bounds 0.3557    solve 11.3629    add 1.7303    
Current (lb-rhs): -6730.1533203125
5880 domains visited
Cumulative time: 18.196969270706177

BaB round 28
batch: 128
Average branched neurons at iteration 28:  1.0000
splitting decisions: 
split level 0: [/9, 11684] [/9, 4329] [/9, 11121] [/9, 4329] [/9, 4516] [/9, 8121] [/9, 8553] [/9, 8121] [/9, 8553] [/9, 8260] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0193    bound 0.4305    transfer 0.0037    finalize 0.0202    func 0.4736    
Accumulated time: func 11.8338    prepare 0.4368    bound 10.8035    transfer 0.0973    finalize 0.5047    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3072
Time: pickout 0.0060    decision 0.1814    set_bounds 0.0158    solve 0.4737    add 0.0332    
Accumulated time: pickout 0.1480    decision 4.6088    set_bounds 0.3715    solve 11.8366    add 1.7635    
Current (lb-rhs): -6730.1533203125
6136 domains visited
Cumulative time: 18.9076247215271

BaB round 29
batch: 128
Average branched neurons at iteration 29:  1.0000
splitting decisions: 
split level 0: [/9, 11121] [/9, 2108] [/9, 4329] [/9, 8553] [/9, 8553] [/9, 4516] [/9, 4329] [/9, 2116] [/9, 4516] [/9, 4516] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.532669067382812e-05
Time: prepare 0.0173    bound 0.4379    transfer 0.0036    finalize 0.0201    func 0.4790    
Accumulated time: func 12.3128    prepare 0.4544    bound 11.2414    transfer 0.1009    finalize 0.5248    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3200
Time: pickout 0.0062    decision 0.1818    set_bounds 0.0152    solve 0.4791    add 0.0346    
Accumulated time: pickout 0.1542    decision 4.7907    set_bounds 0.3867    solve 12.3157    add 1.7981    
Current (lb-rhs): -6730.1533203125
6392 domains visited
Cumulative time: 19.625911474227905

BaB round 30
batch: 128
Average branched neurons at iteration 30:  1.0000
splitting decisions: 
split level 0: [/9, 2108] [/9, 8553] [/9, 8198] [/9, 11684] [/9, 8033] [/9, 8553] [/9, 11684] [/9, 10019] [/9, 8198] [/9, 2108] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0176    bound 0.4348    transfer 0.0036    finalize 0.0207    func 0.4768    
Accumulated time: func 12.7896    prepare 0.4725    bound 11.6762    transfer 0.1046    finalize 0.5454    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3328
Time: pickout 0.0062    decision 0.1824    set_bounds 0.0156    solve 0.4774    add 0.0373    
Accumulated time: pickout 0.1604    decision 4.9731    set_bounds 0.4024    solve 12.7931    add 1.8354    
Current (lb-rhs): -6730.1533203125
6648 domains visited
Cumulative time: 20.347817420959473

BaB round 31
batch: 128
Average branched neurons at iteration 31:  1.0000
splitting decisions: 
split level 0: [/9, 8553] [/9, 11684] [/9, 11044] [/9, 8198] [/9, 4329] [/9, 4329] [/9, 2108] [/9, 4516] [/9, 2108] [/9, 11044] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00032782554626464844
Time: prepare 0.0196    bound 0.4758    transfer 0.0041    finalize 0.0218    func 0.5212    
Accumulated time: func 13.3109    prepare 0.4924    bound 12.1520    transfer 0.1087    finalize 0.5672    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3456
Time: pickout 0.0070    decision 0.1848    set_bounds 0.0153    solve 0.5214    add 0.0380    
Accumulated time: pickout 0.1674    decision 5.1579    set_bounds 0.4177    solve 13.3145    add 1.8734    
Current (lb-rhs): -6730.1533203125
6904 domains visited
Cumulative time: 21.11621356010437

BaB round 32
batch: 128
Average branched neurons at iteration 32:  1.0000
splitting decisions: 
split level 0: [/9, 8260] [/9, 11121] [/9, 2108] [/9, 2108] [/9, 11684] [/9, 11684] [/9, 11121] [/9, 4329] [/9, 11044] [/9, 8198] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.508827209472656e-05
Time: prepare 0.0175    bound 0.4395    transfer 0.0038    finalize 0.0205    func 0.4814    
Accumulated time: func 13.7922    prepare 0.5104    bound 12.5915    transfer 0.1125    finalize 0.5877    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3584
Time: pickout 0.0065    decision 0.2093    set_bounds 0.0156    solve 0.4815    add 0.0356    
Accumulated time: pickout 0.1738    decision 5.3671    set_bounds 0.4332    solve 13.7960    add 1.9090    
Current (lb-rhs): -6730.1533203125
7160 domains visited
Cumulative time: 21.86499285697937

BaB round 33
batch: 128
Average branched neurons at iteration 33:  1.0000
splitting decisions: 
split level 0: [/9, 11044] [/13, 5362] [/9, 11684] [/9, 11121] [/9, 2108] [/9, 2108] [/9, 8260] [/9, 11121] [/9, 7864] [/9, 7864] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0186    bound 0.4417    transfer 0.0037    finalize 0.0206    func 0.4847    
Accumulated time: func 14.2769    prepare 0.5294    bound 13.0333    transfer 0.1161    finalize 0.6083    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3712
Time: pickout 0.0076    decision 0.1888    set_bounds 0.0160    solve 0.4848    add 0.0340    
Accumulated time: pickout 0.1815    decision 5.5559    set_bounds 0.4492    solve 14.2807    add 1.9430    
Current (lb-rhs): -6730.1533203125
7416 domains visited
Cumulative time: 22.597912311553955

BaB round 34
batch: 128
Average branched neurons at iteration 34:  1.0000
splitting decisions: 
split level 0: [/9, 8198] [/9, 8260] [/9, 8260] [/9, 8260] [/9, 11121] [/9, 11121] [/9, 8198] [/9, 2108] [/9, 11027] [/9, 11168] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0175    bound 0.4350    transfer 0.0037    finalize 0.0205    func 0.4767    
Accumulated time: func 14.7536    prepare 0.5473    bound 13.4683    transfer 0.1198    finalize 0.6288    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3840
Time: pickout 0.0060    decision 0.1847    set_bounds 0.0154    solve 0.4768    add 0.0338    
Accumulated time: pickout 0.1875    decision 5.7406    set_bounds 0.4646    solve 14.7576    add 1.9768    
Current (lb-rhs): -6730.1533203125
7672 domains visited
Cumulative time: 23.315029621124268

BaB round 35
batch: 128
Average branched neurons at iteration 35:  1.0000
splitting decisions: 
split level 0: [/9, 7864] [/9, 8198] [/9, 4082] [/9, 11044] [/9, 8260] [/9, 8198] [/9, 11044] [/9, 8553] [/9, 11168] [/9, 11027] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.866455078125e-05
Time: prepare 0.0174    bound 0.4412    transfer 0.0037    finalize 0.0163    func 0.4786    
Accumulated time: func 15.2322    prepare 0.5650    bound 13.9095    transfer 0.1235    finalize 0.6451    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 3968
Time: pickout 0.0063    decision 0.1841    set_bounds 0.0155    solve 0.5326    add 0.0383    
Accumulated time: pickout 0.1938    decision 5.9247    set_bounds 0.4800    solve 15.2901    add 2.0151    
Current (lb-rhs): -6730.1533203125
7928 domains visited
Cumulative time: 24.09322738647461

BaB round 36
batch: 128
Average branched neurons at iteration 36:  1.0000
splitting decisions: 
split level 0: [/9, 11027] [/9, 11044] [/9, 7864] [/9, 7864] [/9, 8198] [/9, 11044] [/9, 8033] [/9, 7864] [/9, 4082] [/9, 8523] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 7.2479248046875e-05
Time: prepare 0.0175    bound 0.4481    transfer 0.0037    finalize 0.0156    func 0.4850    
Accumulated time: func 15.7172    prepare 0.5830    bound 14.3576    transfer 0.1272    finalize 0.6607    
Current worst splitting domains lb-rhs (depth):
-6730.15332 (8), -6730.14502 (8), -6730.04199 (8), -6730.03320 (8), -6730.02930 (8), -6730.02100 (8), -6729.70557 (8), -6729.70410 (9), -6729.69727 (8), -6729.69287 (8), -6729.68408 (8), -6729.63623 (9), -6729.27979 (8), -6729.27490 (8), -6729.27490 (8), -6729.26660 (8), -6729.18994 (10), -6728.93945 (8), -6728.93115 (8), -6728.83789 (9), 
length of domains: 4096
Time: pickout 0.0063    decision 0.1841    set_bounds 0.0153    solve 0.4851    add 0.0369    
Accumulated time: pickout 0.2001    decision 6.1088    set_bounds 0.4953    solve 15.7752    add 2.0520    
Current (lb-rhs): -6730.1533203125
8184 domains visited
Cumulative time: 24.82282018661499

BaB round 37
batch: 128
Average branched neurons at iteration 37:  1.0000
splitting decisions: 
split level 0: [/9, 11168] [/9, 7864] [/9, 11027] [/9, 11027] [/9, 11044] [/9, 7864] [/9, 7864] [/9, 11684] [/9, 8523] [/9, 11684] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.532669067382812e-05
Time: prepare 0.0176    bound 0.4418    transfer 0.0037    finalize 0.0205    func 0.4835    
Accumulated time: func 16.2008    prepare 0.6010    bound 14.7994    transfer 0.1308    finalize 0.6812    
Killed
exit code: 138
head: cannot open 'out.txt' for reading: No such file or directory

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example --bound_prop_method crown --apply_output_constraints_to
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:30:18 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.9445s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.26s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  154.,   512.,   914.,   820.,   958.,   924.,   156.,   794.,
            652.,   874.,   628.,   986.,   414.,   926., -1084.,   866.,
            532.,  -516.,   212.,  1226.,   390.,    34.,    32.,   226.,
            186.,   346.,   494.,   426.,   694.,   432.,   642.,   524.,
           -150.,  2624.,   470.,  2112.,   708.,   366.,   482.,  1256.,
            640.,   108.,  -286.],
         [  154.,   512.,   914.,   820.,   958.,   924.,   156.,   794.,
            652.,   874.,   628.,   986.,   414.,   926., -1084.,   866.,
            532.,  -516.,   212.,  1226.,   390.,    34.,    32.,   226.,
            186.,   346.,   494.,   426.,   694.,   432.,   642.,   524.,
           -150.,  2624.,   470.,  2112.,   708.,   366.,   482.,  1256.,
            640.,   108.,  -286.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2470., 2112., 1710., 1804., 1666., 1700., 2468., 1830., 1972., 1750.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2791 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.98s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 4.00000000e+01,  4.22000000e+02,  8.28000000e+02,  7.22000000e+02,
           8.60000000e+02,  8.18000000e+02,  1.34000000e+02,  7.56000000e+02,
           5.26000000e+02,  9.00000000e+02,  7.18000000e+02,  1.17200000e+03,
           3.72000000e+02,  7.52000000e+02, -1.11000000e+03,  8.12000000e+02,
           5.14000000e+02, -5.26000000e+02,  2.38000000e+02,  1.40400000e+03,
           2.68000000e+02,  3.60000000e+01,  2.00000000e+00,  3.84000000e+02,
           3.20000000e+02,  3.36000000e+02,  4.56000000e+02,  4.12000000e+02,
           7.92000000e+02,  1.86000000e+02,  7.68000000e+02,  6.34000000e+02,
          -1.76000000e+02,  3.24200000e+03,  6.60000000e+02,  1.53800000e+03,
           7.30000000e+02,  4.32000000e+02,  5.28000000e+02,  1.27400000e+03,
           6.18000000e+02, -1.14000000e+02, -1.96000000e+02],
         [ 4.00000000e+01,  4.22000000e+02,  8.28000000e+02,  7.22000000e+02,
           8.60000000e+02,  8.18000000e+02,  1.34000000e+02,  7.56000000e+02,
           5.26000000e+02,  9.00000000e+02,  7.18000000e+02,  1.17200000e+03,
           3.72000000e+02,  7.52000000e+02, -1.11000000e+03,  8.12000000e+02,
           5.14000000e+02, -5.26000000e+02,  2.38000000e+02,  1.40400000e+03,
           2.68000000e+02,  3.60000000e+01,  2.00000000e+00,  3.84000000e+02,
           3.20000000e+02,  3.36000000e+02,  4.56000000e+02,  4.12000000e+02,
           7.92000000e+02,  1.86000000e+02,  7.68000000e+02,  6.34000000e+02,
          -1.76000000e+02,  3.24200000e+03,  6.60000000e+02,  1.53800000e+03,
           7.30000000e+02,  4.32000000e+02,  5.28000000e+02,  1.27400000e+03,
           6.18000000e+02, -1.14000000e+02, -1.96000000e+02]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3202., 2820., 2414., 2520., 2382., 2424., 3108., 2486., 2716., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9869 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.03s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  52.,  310.,  912.,  786.,  988.,  898.,  138.,  820.,  690.,  924.,
           646.,  996.,  532.,  872., -974.,  764.,  626., -550.,  126., 1284.,
           340.,   20.,   50.,  260.,   96.,  352.,  468.,  520.,  732.,  406.,
           632.,  594., -120., 2614.,  364., 2158.,  822.,  308.,  492., 1346.,
           682.,   30., -140.],
         [  52.,  310.,  912.,  786.,  988.,  898.,  138.,  820.,  690.,  924.,
           646.,  996.,  532.,  872., -974.,  764.,  626., -550.,  126., 1284.,
           340.,   20.,   50.,  260.,   96.,  352.,  468.,  520.,  732.,  406.,
           632.,  594., -120., 2614.,  364., 2158.,  822.,  308.,  492., 1346.,
           682.,   30., -140.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2562., 2304., 1702., 1828., 1626., 1716., 2476., 1794., 1924., 1690.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0331 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  122.,   476.,   850.,   800.,   846.,   808.,   144.,   766.,
            496.,   874.,   760.,  1130.,   382.,   762., -1140.,   766.,
            448.,  -572.,   224.,  1414.,   226.,    82.,    16.,   342.,
            366.,   374.,   426.,   302.,   794.,   288.,   762.,   732.,
           -122.,  3208.,   638.,  1548.,   724.,   350.,   522.,  1256.,
            632.,   -88.,  -242.],
         [  122.,   476.,   850.,   800.,   846.,   808.,   144.,   766.,
            496.,   874.,   760.,  1130.,   382.,   762., -1140.,   766.,
            448.,  -572.,   224.,  1414.,   226.,    82.,    16.,   342.,
            366.,   374.,   426.,   302.,   794.,   288.,   762.,   732.,
           -122.,  3208.,   638.,  1548.,   724.,   350.,   522.,  1256.,
            632.,   -88.,  -242.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3086., 2732., 2358., 2408., 2362., 2400., 3064., 2442., 2712., 2334.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0236 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 202.,  464.,  850.,  860.,  982.,  744.,  212.,  830.,  592.,  870.,
           616.,  970.,  410.,  898., -952.,  726.,  548., -532.,  196., 1278.,
           458.,   82.,   40.,  198.,  214.,  250.,  566.,  502.,  798.,  388.,
           642.,  560., -210., 2584.,  390., 2132.,  824.,  446.,  494., 1328.,
           552.,  120., -210.],
         [ 202.,  464.,  850.,  860.,  982.,  744.,  212.,  830.,  592.,  870.,
           616.,  970.,  410.,  898., -952.,  726.,  548., -532.,  196., 1278.,
           458.,   82.,   40.,  198.,  214.,  250.,  566.,  502.,  798.,  388.,
           642.,  560., -210., 2584.,  390., 2132.,  824.,  446.,  494., 1328.,
           552.,  120., -210.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2382., 2120., 1734., 1724., 1602., 1840., 2372., 1754., 1992., 1714.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0128 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.97s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   436.,   930.,   796.,   818.,   916.,   200.,   754.,
            528.,   830.,   756.,  1146.,   346.,   730., -1088.,   762.,
            468.,  -560.,   228.,  1430.,   282.,   190.,     8.,   338.,
            322.,   458.,   454.,   382.,   754.,   196.,   714.,   580.,
           -162.,  3184.,   682.,  1500.,   676.,   422.,   546.,  1244.,
            600.,  -164.,  -254.],
         [  102.,   436.,   930.,   796.,   818.,   916.,   200.,   754.,
            528.,   830.,   756.,  1146.,   346.,   730., -1088.,   762.,
            468.,  -560.,   228.,  1430.,   282.,   190.,     8.,   338.,
            322.,   458.,   454.,   382.,   754.,   196.,   714.,   580.,
           -162.,  3184.,   682.,  1500.,   676.,   422.,   546.,  1244.,
            600.,  -164.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3082., 2748., 2254., 2388., 2366., 2268., 2984., 2430., 2656., 2354.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9810 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.05s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 104.,  342.,  848.,  806., 1068.,  902.,  174.,  748.,  674.,  844.,
           678., 1000.,  388.,  872., -946.,  776.,  578., -530.,  202., 1212.,
           408.,  -16.,   10.,  396.,  304.,  324.,  572.,  448.,  712.,  322.,
           632.,  542., -176., 2546.,  452., 2054.,  834.,  356.,  468., 1254.,
           638.,   86., -168.],
         [ 104.,  342.,  848.,  806., 1068.,  902.,  174.,  748.,  674.,  844.,
           678., 1000.,  388.,  872., -946.,  776.,  578., -530.,  202., 1212.,
           408.,  -16.,   10.,  396.,  304.,  324.,  572.,  448.,  712.,  322.,
           632.,  542., -176., 2546.,  452., 2054.,  834.,  356.,  468., 1254.,
           638.,   86., -168.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2442., 2204., 1698., 1740., 1478., 1644., 2372., 1798., 1872., 1702.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0561 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.18s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  134.,   484.,   874.,   720.,   782.,   808.,   184.,   742.,
            576.,   974.,   708.,  1214.,   386.,   762., -1120.,   838.,
            400.,  -620.,   176.,  1426.,   194.,    42.,    12.,   374.,
            298.,   302.,   422.,   462.,   810.,   256.,   802.,   572.,
           -190.,  3212.,   666.,  1548.,   756.,   334.,   454.,  1136.,
            652.,  -160.,  -266.],
         [  134.,   484.,   874.,   720.,   782.,   808.,   184.,   742.,
            576.,   974.,   708.,  1214.,   386.,   762., -1120.,   838.,
            400.,  -620.,   176.,  1426.,   194.,    42.,    12.,   374.,
            298.,   302.,   422.,   462.,   810.,   256.,   802.,   572.,
           -190.,  3212.,   666.,  1548.,   756.,   334.,   454.,  1136.,
            652.,  -160.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3078., 2728., 2338., 2492., 2430., 2404., 3028., 2470., 2636., 2238.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1827 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.34s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 186.,  320.,  938.,  908.,  946.,  836.,  132.,  838.,  740.,  846.,
           652., 1082.,  490.,  902., -936.,  818.,  560., -560.,  148., 1390.,
           418.,   38.,   -4.,  298.,  182.,  270.,  462.,  518.,  822.,  492.,
           634.,  492.,  -86., 2552.,  418., 2140.,  816.,  294.,  494., 1316.,
           584.,   88., -214.],
         [ 186.,  320.,  938.,  908.,  946.,  836.,  132.,  838.,  740.,  846.,
           652., 1082.,  490.,  902., -936.,  818.,  560., -560.,  148., 1390.,
           418.,   38.,   -4.,  298.,  182.,  270.,  462.,  518.,  822.,  492.,
           634.,  492.,  -86., 2552.,  418., 2140.,  816.,  294.,  494., 1316.,
           584.,   88., -214.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2366., 2232., 1614., 1644., 1606., 1716., 2420., 1714., 1812., 1706.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3483 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.17s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   82.,   500.,   846.,   728.,   782.,   856.,   220.,   754.,
            432.,   830.,   748.,  1158.,   434.,   758., -1196.,   778.,
            516.,  -592.,   108.,  1346.,   242.,    -6.,    56.,   370.,
            282.,   402.,   470.,   398.,   770.,   248.,   754.,   652.,
           -234.,  3220.,   706.,  1528.,   740.,   386.,   426.,  1172.,
            628.,   -84.,  -202.],
         [   82.,   500.,   846.,   728.,   782.,   856.,   220.,   754.,
            432.,   830.,   748.,  1158.,   434.,   758., -1196.,   778.,
            516.,  -592.,   108.,  1346.,   242.,    -6.,    56.,   370.,
            282.,   402.,   470.,   398.,   770.,   248.,   754.,   652.,
           -234.,  3220.,   706.,  1528.,   740.,   386.,   426.,  1172.,
            628.,   -84.,  -202.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3138., 2720., 2374., 2492., 2438., 2364., 3000., 2466., 2788., 2390.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1773 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.20s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   82.,   384.,   922.,   836.,  1042.,   896.,   176.,   726.,
            716.,   890.,   620.,   990.,   306.,   922., -1004.,   890.,
            492.,  -476.,   196.,  1298.,   362.,    34.,    60.,   314.,
            238.,   330.,   462.,   466.,   738.,   420.,   610.,   504.,
           -158.,  2564.,   546.,  2160.,   932.,   454.,   478.,  1288.,
            648.,    72.,  -254.],
         [   82.,   384.,   922.,   836.,  1042.,   896.,   176.,   726.,
            716.,   890.,   620.,   990.,   306.,   922., -1004.,   890.,
            492.,  -476.,   196.,  1298.,   362.,    34.,    60.,   314.,
            238.,   330.,   462.,   466.,   738.,   420.,   610.,   504.,
           -158.,  2564.,   546.,  2160.,   932.,   454.,   478.,  1288.,
            648.,    72.,  -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2482., 2180., 1642., 1728., 1522., 1668., 2388., 1838., 1848., 1674.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2050 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.16s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   92.,   458.,   872.,   830.,   804.,   858.,   130.,   736.,
            554.,   948.,   682.,  1232.,   532.,   800., -1098.,   776.,
            574.,  -574.,   190.,  1384.,   272.,    28.,   -82.,   432.,
            200.,   416.,   456.,   372.,   836.,   346.,   692.,   634.,
           -192.,  3198.,   660.,  1554.,   650.,   348.,   432.,  1218.,
            710.,   -78.,  -188.],
         [   92.,   458.,   872.,   830.,   804.,   858.,   130.,   736.,
            554.,   948.,   682.,  1232.,   532.,   800., -1098.,   776.,
            574.,  -574.,   190.,  1384.,   272.,    28.,   -82.,   432.,
            200.,   416.,   456.,   372.,   836.,   346.,   692.,   634.,
           -192.,  3198.,   660.,  1554.,   650.,   348.,   432.,  1218.,
            710.,   -78.,  -188.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3106., 2740., 2326., 2368., 2394., 2340., 3068., 2462., 2644., 2250.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1681 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 116.,  394.,  848.,  918.,  976.,  850.,  218.,  756.,  698.,  836.,
           602.,  972.,  428., 1004., -918.,  772.,  562., -522.,  146., 1276.,
           456.,  -36.,  142.,  292.,  184.,  312.,  572.,  396.,  780.,  450.,
           604.,  502.,  -96., 2502.,  492., 2170.,  722.,  412.,  536., 1378.,
           542.,   90., -240.],
         [ 116.,  394.,  848.,  918.,  976.,  850.,  218.,  756.,  698.,  836.,
           602.,  972.,  428., 1004., -918.,  772.,  562., -522.,  146., 1276.,
           456.,  -36.,  142.,  292.,  184.,  312.,  572.,  396.,  780.,  450.,
           604.,  502.,  -96., 2502.,  492., 2170.,  722.,  412.,  536., 1378.,
           542.,   90., -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2386., 2108., 1654., 1584., 1526., 1652., 2284., 1746., 1804., 1666.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0065 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  220.,   478.,   924.,   790.,   788.,   850.,   130.,   752.,
            450.,   804.,   734.,  1116.,   360.,   716., -1182.,   812.,
            498.,  -514.,   178.,  1408.,   160.,    96.,    58.,   408.,
            324.,   444.,   348.,   452.,   824.,   262.,   744.,   650.,
           -176.,  3146.,   704.,  1522.,   758.,   392.,   556.,  1226.,
            522.,   -62.,  -276.],
         [  220.,   478.,   924.,   790.,   788.,   850.,   130.,   752.,
            450.,   804.,   734.,  1116.,   360.,   716., -1182.,   812.,
            498.,  -514.,   178.,  1408.,   160.,    96.,    58.,   408.,
            324.,   444.,   348.,   452.,   824.,   262.,   744.,   650.,
           -176.,  3146.,   704.,  1522.,   758.,   392.,   556.,  1226.,
            522.,   -62.,  -276.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2926., 2668., 2222., 2356., 2358., 2296., 3016., 2394., 2696., 2342.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0222 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.29s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  36.,  318.,  988.,  898.,  968.,  810.,  154.,  824.,  718.,  756.,
           690., 1020.,  328.,  888., -978.,  848.,  530., -590.,  226., 1240.,
           452.,   12.,   22.,  324.,   92.,  332.,  508.,  576.,  780.,  478.,
           572.,  538., -132., 2570.,  436., 2118.,  730.,  412.,  492., 1330.,
           558.,   42., -140.],
         [  36.,  318.,  988.,  898.,  968.,  810.,  154.,  824.,  718.,  756.,
           690., 1020.,  328.,  888., -978.,  848.,  530., -590.,  226., 1240.,
           452.,   12.,   22.,  324.,   92.,  332.,  508.,  576.,  780.,  478.,
           572.,  538., -132., 2570.,  436., 2118.,  730.,  412.,  492., 1330.,
           558.,   42., -140.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2534., 2252., 1582., 1672., 1602., 1760., 2416., 1746., 1852., 1814.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2990 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.27s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  132.,   462.,   860.,   754.,   860.,   842.,   102.,   740.,
            494.,   820.,   782.,  1172.,   400.,   716., -1110.,   716.,
            510.,  -586.,   154.,  1400.,   252.,   116.,   -10.,   416.,
            212.,   440.,   500.,   516.,   860.,   294.,   812.,   618.,
           -144.,  3206.,   728.,  1486.,   682.,   384.,   484.,  1186.,
            646.,   -46.,  -192.],
         [  132.,   462.,   860.,   754.,   860.,   842.,   102.,   740.,
            494.,   820.,   782.,  1172.,   400.,   716., -1110.,   716.,
            510.,  -586.,   154.,  1400.,   252.,   116.,   -10.,   416.,
            212.,   440.,   500.,   516.,   860.,   294.,   812.,   618.,
           -144.,  3206.,   728.,  1486.,   682.,   384.,   484.,  1186.,
            646.,   -46.,  -192.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3074., 2744., 2346., 2452., 2346., 2364., 3104., 2466., 2712., 2386.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2903 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 106.,  388.,  806.,  860.,  998.,  832.,  100.,  834.,  724.,  874.,
           620.,  966.,  374.,  958., -948.,  854.,  528., -484.,  140., 1318.,
           394.,    6.,   60.,  342.,  202.,  398.,  502.,  470.,  730.,  496.,
           566.,  520., -106., 2536.,  482., 2164.,  860.,  406.,  538., 1340.,
           508.,   96., -222.],
         [ 106.,  388.,  806.,  860.,  998.,  832.,  100.,  834.,  724.,  874.,
           620.,  966.,  374.,  958., -948.,  854.,  528., -484.,  140., 1318.,
           394.,    6.,   60.,  342.,  202.,  398.,  502.,  470.,  730.,  496.,
           566.,  520., -106., 2536.,  482., 2164.,  860.,  406.,  538., 1340.,
           508.,   96., -222.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2430., 2148., 1730., 1676., 1538., 1704., 2436., 1702., 1812., 1662.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1217 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.24s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  196.,   494.,   868.,   766.,   796.,   842.,   186.,   760.,
            538.,   880.,   742.,  1204.,   420.,   728., -1142.,   796.,
            458.,  -554.,   190.,  1380.,   268.,    72.,    66.,   312.,
            380.,   320.,   460.,   380.,   724.,   226.,   792.,   614.,
           -180.,  3250.,   764.,  1574.,   762.,   360.,   516.,  1166.,
            642.,  -110.,  -192.],
         [  196.,   494.,   868.,   766.,   796.,   842.,   186.,   760.,
            538.,   880.,   742.,  1204.,   420.,   728., -1142.,   796.,
            458.,  -554.,   190.,  1380.,   268.,    72.,    66.,   312.,
            380.,   320.,   460.,   380.,   724.,   226.,   792.,   614.,
           -180.,  3250.,   764.,  1574.,   762.,   360.,   516.,  1166.,
            642.,  -110.,  -192.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3054., 2756., 2382., 2484., 2454., 2408., 3064., 2490., 2712., 2370.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2477 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 102.,  364.,  834.,  844.,  954.,  844.,  164.,  834.,  644.,  894.,
           592.,  986.,  402.,  898., -960.,  762.,  532., -400.,  268., 1330.,
           410.,   10.,   44.,  266.,  214.,  286.,  494.,  418.,  718.,  480.,
           578.,  572., -146., 2536.,  474., 2080.,  828.,  454.,  494., 1364.,
           508.,  200., -262.],
         [ 102.,  364.,  834.,  844.,  954.,  844.,  164.,  834.,  644.,  894.,
           592.,  986.,  402.,  898., -960.,  762.,  532., -400.,  268., 1330.,
           410.,   10.,   44.,  266.,  214.,  286.,  494.,  418.,  718.,  480.,
           578.,  572., -146., 2536.,  474., 2080.,  828.,  454.,  494., 1364.,
           508.,  200., -262.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2434., 2172., 1702., 1692., 1582., 1692., 2372., 1702., 1892., 1642.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0192 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.12s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   78.,   496.,   906.,   732.,   842.,   828.,   196.,   814.,
            488.,   938.,   776.,  1238.,   370.,   710., -1128.,   790.,
            468.,  -596.,   184.,  1358.,   210.,    26.,    96.,   366.,
            266.,   382.,   490.,   438.,   758.,   324.,   746.,   640.,
           -190.,  3236.,   674.,  1624.,   664.,   354.,   590.,  1160.,
            576.,  -104.,  -266.],
         [   78.,   496.,   906.,   732.,   842.,   828.,   196.,   814.,
            488.,   938.,   776.,  1238.,   370.,   710., -1128.,   790.,
            468.,  -596.,   184.,  1358.,   210.,    26.,    96.,   366.,
            266.,   382.,   490.,   438.,   758.,   324.,   746.,   640.,
           -190.,  3236.,   674.,  1624.,   664.,   354.,   590.,  1160.,
            576.,  -104.,  -266.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3158., 2740., 2330., 2504., 2394., 2408., 3040., 2422., 2748., 2298.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1255 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 226.,  400.,  870.,  760., 1010.,  816.,  204.,  786.,  616.,  914.,
           696., 1018.,  506.,  922., -984.,  790.,  608., -480.,  180., 1294.,
           402.,   42.,   52.,  222.,  290.,  306.,  534.,  410.,  746.,  460.,
           602.,  496., -230., 2536.,  394., 2120.,  824.,  366.,  534., 1288.,
           628.,  144., -234.],
         [ 226.,  400.,  870.,  760., 1010.,  816.,  204.,  786.,  616.,  914.,
           696., 1018.,  506.,  922., -984.,  790.,  608., -480.,  180., 1294.,
           402.,   42.,   52.,  222.,  290.,  306.,  534.,  410.,  746.,  460.,
           602.,  496., -230., 2536.,  394., 2120.,  824.,  366.,  534., 1288.,
           628.,  144., -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2310., 2136., 1666., 1776., 1526., 1720., 2332., 1750., 1920., 1622.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0185 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.99s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  144.,   430.,   888.,   790.,   844.,   866.,   182.,   788.,
            510.,   928.,   738.,  1208.,   324.,   748., -1094.,   780.,
            422.,  -574.,   170.,  1372.,   276.,   -32.,   -14.,   424.,
            292.,   320.,   500.,   388.,   696.,   294.,   788.,   610.,
           -248.,  3190.,   648.,  1514.,   738.,   452.,   472.,  1226.,
            646.,   -90.,  -200.],
         [  144.,   430.,   888.,   790.,   844.,   866.,   182.,   788.,
            510.,   928.,   738.,  1208.,   324.,   748., -1094.,   780.,
            422.,  -574.,   170.,  1372.,   276.,   -32.,   -14.,   424.,
            292.,   320.,   500.,   388.,   696.,   294.,   788.,   610.,
           -248.,  3190.,   648.,  1514.,   738.,   452.,   472.,  1226.,
            646.,   -90.,  -200.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3046., 2760., 2302., 2400., 2346., 2324., 3008., 2402., 2680., 2262.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9998 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.12s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  182.,   424.,   898.,   844.,   982.,   888.,   116.,   846.,
            572.,   906.,   656.,   946.,   442.,   954., -1004.,   834.,
            552.,  -524.,   152.,  1298.,   410.,    62.,   -36.,   270.,
            226.,   310.,   522.,   450.,   782.,   464.,   586.,   644.,
           -190.,  2564.,   458.,  2104.,   808.,   394.,   458.,  1336.,
            512.,   148.,  -270.],
         [  182.,   424.,   898.,   844.,   982.,   888.,   116.,   846.,
            572.,   906.,   656.,   946.,   442.,   954., -1004.,   834.,
            552.,  -524.,   152.,  1298.,   410.,    62.,   -36.,   270.,
            226.,   310.,   522.,   450.,   782.,   464.,   586.,   644.,
           -190.,  2564.,   458.,  2104.,   808.,   394.,   458.,  1336.,
            512.,   148.,  -270.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2382., 2140., 1666., 1720., 1582., 1676., 2448., 1718., 1992., 1658.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1288 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.00s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  102.,   484.,   906.,   740.,   750.,   968.,   160.,   834.,
            540.,   878.,   744.,  1246.,   470.,   670., -1164.,   718.,
            420.,  -612.,    36.,  1358.,   274.,   102.,     4.,   446.,
            286.,   310.,   526.,   406.,   742.,   344.,   850.,   572.,
           -206.,  3120.,   686.,  1504.,   732.,   378.,   490.,  1184.,
            600.,   -68.,  -182.],
         [  102.,   484.,   906.,   740.,   750.,   968.,   160.,   834.,
            540.,   878.,   744.,  1246.,   470.,   670., -1164.,   718.,
            420.,  -612.,    36.,  1358.,   274.,   102.,     4.,   446.,
            286.,   310.,   526.,   406.,   742.,   344.,   850.,   572.,
           -206.,  3120.,   686.,  1504.,   732.,   378.,   490.,  1184.,
            600.,   -68.,  -182.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3018., 2636., 2214., 2380., 2370., 2152., 2960., 2286., 2580., 2242.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0104 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.29s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 198.,  288.,  910.,  808.,  894.,  904.,  264.,  782.,  676.,  746.,
           568.,  990.,  454.,  870., -988.,  726.,  584., -488.,  136., 1342.,
           338.,  114.,  136.,  270.,  422.,  382.,  478.,  418.,  794.,  496.,
           750.,  460., -170., 2564.,  482., 2124.,  776.,  198.,  446., 1260.,
           552.,  -44., -254.],
         [ 198.,  288.,  910.,  808.,  894.,  904.,  264.,  782.,  676.,  746.,
           568.,  990.,  454.,  870., -988.,  726.,  584., -488.,  136., 1342.,
           338.,  114.,  136.,  270.,  422.,  382.,  478.,  418.,  794.,  496.,
           750.,  460., -170., 2564.,  482., 2124.,  776.,  198.,  446., 1260.,
           552.,  -44., -254.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2366., 2276., 1654., 1756., 1670., 1660., 2300., 1782., 1888., 1818.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3014 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.33s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  162.,   480.,   918.,   816.,   838.,   872.,   204.,   738.,
            528.,   846.,   744.,  1214.,   466.,   706., -1096.,   770.,
            448.,  -576.,   196.,  1418.,   286.,   170.,     0.,   370.,
            350.,   414.,   458.,   490.,   806.,   328.,   766.,   580.,
           -178.,  3160.,   686.,  1520.,   624.,   366.,   474.,  1188.,
            676.,  -168.,  -230.],
         [  162.,   480.,   918.,   816.,   838.,   872.,   204.,   738.,
            528.,   846.,   744.,  1214.,   466.,   706., -1096.,   770.,
            448.,  -576.,   196.,  1418.,   286.,   170.,     0.,   370.,
            350.,   414.,   458.,   490.,   806.,   328.,   766.,   580.,
           -178.,  3160.,   686.,  1520.,   624.,   366.,   474.,  1188.,
            676.,  -168.,  -230.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2998., 2680., 2242., 2344., 2322., 2288., 2956., 2422., 2632., 2314.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3437 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.17s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 192.,  514.,  824.,  770.,  932.,  866.,  134.,  776.,  618.,  924.,
           714., 1012.,  472.,  968., -982.,  752.,  630., -530.,  158., 1332.,
           408.,   92.,  106.,  300.,  172.,  292.,  512.,  388.,  748.,  366.,
           672.,  498., -208., 2550.,  524., 2094.,  766.,  352.,  528., 1322.,
           554.,   86., -304.],
         [ 192.,  514.,  824.,  770.,  932.,  866.,  134.,  776.,  618.,  924.,
           714., 1012.,  472.,  968., -982.,  752.,  630., -530.,  158., 1332.,
           408.,   92.,  106.,  300.,  172.,  292.,  512.,  388.,  748.,  366.,
           672.,  498., -208., 2550.,  524., 2094.,  766.,  352.,  528., 1322.,
           554.,   86., -304.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2358., 2036., 1726., 1780., 1618., 1684., 2416., 1774., 1932., 1626.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1736 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.19s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   74.,   432.,   842.,   768.,   766.,   868.,   140.,   662.,
            480.,   850.,   700.,  1230.,   374.,   742., -1188.,   746.,
            476.,  -620.,   208.,  1502.,   274.,   106.,    16.,   370.,
            290.,   394.,   378.,   482.,   818.,   244.,   734.,   608.,
           -318.,  3160.,   706.,  1540.,   708.,   414.,   582.,  1180.,
            632.,  -120.,  -258.],
         [   74.,   432.,   842.,   768.,   766.,   868.,   140.,   662.,
            480.,   850.,   700.,  1230.,   374.,   742., -1188.,   746.,
            476.,  -620.,   208.,  1502.,   274.,   106.,    16.,   370.,
            290.,   394.,   378.,   482.,   818.,   244.,   734.,   608.,
           -318.,  3160.,   706.,  1540.,   708.,   414.,   582.,  1180.,
            632.,  -120.,  -258.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3086., 2728., 2318., 2392., 2394., 2292., 3020., 2498., 2680., 2310.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2004 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.28s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 114.,  324.,  902.,  824.,  966.,  832.,   92.,  718.,  704.,  882.,
           660.,  990.,  406.,  974., -912.,  774.,  528., -460.,  224., 1242.,
           478.,  -22.,    4.,  346.,  194.,  314.,  526.,  474.,  802.,  384.,
           586.,  552., -202., 2544.,  510., 2104.,  772.,  314.,  470., 1436.,
           568.,  160., -302.],
         [ 114.,  324.,  902.,  824.,  966.,  832.,   92.,  718.,  704.,  882.,
           660.,  990.,  406.,  974., -912.,  774.,  528., -460.,  224., 1242.,
           478.,  -22.,    4.,  346.,  194.,  314.,  526.,  474.,  802.,  384.,
           586.,  552., -202., 2544.,  510., 2104.,  772.,  314.,  470., 1436.,
           568.,  160., -302.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2430., 2220., 1642., 1720., 1578., 1712., 2452., 1826., 1840., 1662.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2853 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.10s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  126.,   452.,   942.,   728.,   782.,   828.,   184.,   770.,
            440.,   814.,   724.,  1214.,   410.,   734., -1192.,   786.,
            524.,  -564.,   212.,  1430.,   286.,   102.,    28.,   386.,
            354.,   362.,   386.,   454.,   838.,   232.,   762.,   572.,
           -242.,  3240.,   694.,  1552.,   676.,   338.,   510.,  1168.,
            580.,   -96.,  -222.],
         [  126.,   452.,   942.,   728.,   782.,   828.,   184.,   770.,
            440.,   814.,   724.,  1214.,   410.,   734., -1192.,   786.,
            524.,  -564.,   212.,  1430.,   286.,   102.,    28.,   386.,
            354.,   362.,   386.,   454.,   838.,   232.,   762.,   572.,
           -242.,  3240.,   694.,  1552.,   676.,   338.,   510.,  1168.,
            580.,   -96.,  -222.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3114., 2788., 2298., 2512., 2458., 2412., 3056., 2470., 2800., 2426.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1090 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.01s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  80.,  370.,  876.,  830.,  964.,  822.,  122.,  816.,  718.,  832.,
           698., 1000.,  412.,  932., -982.,  864.,  558., -510.,  178., 1280.,
           440.,   16.,   30.,  312.,  200.,  372.,  504.,  492.,  772.,  442.,
           688.,  502., -224., 2638.,  396., 2146.,  794.,  348.,  536., 1370.,
           594.,   78., -184.],
         [  80.,  370.,  876.,  830.,  964.,  822.,  122.,  816.,  718.,  832.,
           698., 1000.,  412.,  932., -982.,  864.,  558., -510.,  178., 1280.,
           440.,   16.,   30.,  312.,  200.,  372.,  504.,  492.,  772.,  442.,
           688.,  502., -224., 2638.,  396., 2146.,  794.,  348.,  536., 1370.,
           594.,   78., -184.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2558., 2268., 1762., 1808., 1674., 1816., 2516., 1822., 1920., 1806.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0129 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.07s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   94.,   388.,   822.,   688.,   874.,   904.,   232.,   870.,
            536.,   842.,   676.,  1170.,   486.,   774., -1128.,   746.,
            524.,  -568.,   188.,  1386.,   234.,    94.,     0.,   346.,
            238.,   358.,   474.,   426.,   810.,   284.,   770.,   644.,
           -234.,  3236.,   622.,  1636.,   632.,   414.,   502.,  1368.,
            572.,   -44.,  -234.],
         [   94.,   388.,   822.,   688.,   874.,   904.,   232.,   870.,
            536.,   842.,   676.,  1170.,   486.,   774., -1128.,   746.,
            524.,  -568.,   188.,  1386.,   234.,    94.,     0.,   346.,
            238.,   358.,   474.,   426.,   810.,   284.,   770.,   644.,
           -234.,  3236.,   622.,  1636.,   632.,   414.,   502.,  1368.,
            572.,   -44.,  -234.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3142., 2848., 2414., 2548., 2362., 2332., 3004., 2366., 2700., 2394.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0739 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.02s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 170.,  420.,  854.,  732., 1014.,  828.,  140.,  738.,  644.,  918.,
           680., 1006.,  370.,  942., -972.,  874.,  548., -500.,  120., 1302.,
           410.,    6.,   20.,  290.,  162.,  386.,  522.,  510.,  738.,  436.,
           626.,  468., -106., 2572.,  506., 2128.,  844.,  402.,  514., 1388.,
           548.,  104., -290.],
         [ 170.,  420.,  854.,  732., 1014.,  828.,  140.,  738.,  644.,  918.,
           680., 1006.,  370.,  942., -972.,  874.,  548., -500.,  120., 1302.,
           410.,    6.,   20.,  290.,  162.,  386.,  522.,  510.,  738.,  436.,
           626.,  468., -106., 2572.,  506., 2128.,  844.,  402.,  514., 1388.,
           548.,  104., -290.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2402., 2152., 1718., 1840., 1558., 1744., 2432., 1834., 1928., 1654.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.0294 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.22s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   88.,   398.,   836.,   802.,   816.,   786.,    90.,   764.,
            482.,   840.,   734.,  1192.,   336.,   708., -1042.,   740.,
            482.,  -622.,   138.,  1448.,   248.,    68.,    30.,   348.,
            364.,   360.,   472.,   508.,   744.,   286.,   744.,   610.,
           -160.,  3242.,   672.,  1642.,   702.,   408.,   528.,  1222.,
            602.,   -66.,  -204.],
         [   88.,   398.,   836.,   802.,   816.,   786.,    90.,   764.,
            482.,   840.,   734.,  1192.,   336.,   708., -1042.,   740.,
            482.,  -622.,   138.,  1448.,   248.,    68.,    30.,   348.,
            364.,   360.,   472.,   508.,   744.,   286.,   744.,   610.,
           -160.,  3242.,   672.,  1642.,   702.,   408.,   528.,  1222.,
            602.,   -66.,  -204.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3154., 2844., 2406., 2440., 2426., 2456., 3152., 2478., 2760., 2402.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2247 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.19s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  162.,   372.,   830.,   852.,   954.,   812.,   256.,   730.,
            584.,   858.,   688.,   998.,   334.,   978., -1012.,   722.,
            604.,  -512.,   160.,  1438.,   318.,   218.,    40.,   338.,
            210.,   226.,   458.,   530.,   846.,   400.,   702.,   512.,
           -198.,  2656.,   442.,  2180.,   860.,   270.,   478.,  1288.,
            612.,   180.,  -206.],
         [  162.,   372.,   830.,   852.,   954.,   812.,   256.,   730.,
            584.,   858.,   688.,   998.,   334.,   978., -1012.,   722.,
            604.,  -512.,   160.,  1438.,   318.,   218.,    40.,   338.,
            210.,   226.,   458.,   530.,   846.,   400.,   702.,   512.,
           -198.,  2656.,   442.,  2180.,   860.,   270.,   478.,  1288.,
            612.,   180.,  -206.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2494., 2284., 1826., 1804., 1702., 1844., 2400., 1926., 2072., 1798.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1992 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.29s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   80.,   446.,   868.,   794.,   756.,   890.,   154.,   756.,
            510.,   872.,   734.,  1204.,   420.,   812., -1090.,   736.,
            538.,  -630.,   118.,  1364.,   248.,   132.,    -6.,   420.,
            216.,   388.,   584.,   496.,   876.,   318.,   780.,   710.,
           -232.,  3190.,   672.,  1530.,   574.,   408.,   488.,  1266.,
            626.,  -122.,  -236.],
         [   80.,   446.,   868.,   794.,   756.,   890.,   154.,   756.,
            510.,   872.,   734.,  1204.,   420.,   812., -1090.,   736.,
            538.,  -630.,   118.,  1364.,   248.,   132.,    -6.,   420.,
            216.,   388.,   584.,   496.,   876.,   318.,   780.,   710.,
           -232.,  3190.,   672.,  1530.,   574.,   408.,   488.,  1266.,
            626.,  -122.,  -236.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3110., 2744., 2322., 2396., 2434., 2300., 3036., 2434., 2680., 2318.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.3014 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.20s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 162.,  528.,  842.,  836., 1006.,  948.,  184.,  738.,  596.,  798.,
           652., 1018.,  434.,  974., -972.,  802.,  564., -448.,  132., 1326.,
           390.,   18.,   20.,  318.,  214.,  254.,  510.,  358.,  706.,  400.,
           674.,  580., -226., 2644.,  586., 2136.,  864.,  350.,  554., 1248.,
           596.,  112., -210.],
         [ 162.,  528.,  842.,  836., 1006.,  948.,  184.,  738.,  596.,  798.,
           652., 1018.,  434.,  974., -972.,  802.,  564., -448.,  132., 1326.,
           390.,   18.,   20.,  318.,  214.,  254.,  510.,  358.,  706.,  400.,
           674.,  580., -226., 2644.,  586., 2136.,  864.,  350.,  554., 1248.,
           596.,  112., -210.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2482., 2116., 1802., 1808., 1638., 1696., 2460., 1906., 2048., 1846.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2093 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.13s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  120.,   462.,   948.,   894.,   860.,   890.,   146.,   772.,
            434.,   904.,   674.,  1180.,   444.,   804., -1146.,   828.,
            518.,  -546.,   214.,  1328.,   308.,    12.,   -34.,   440.,
            244.,   400.,   460.,   460.,   772.,   322.,   724.,   570.,
           -148.,  3194.,   816.,  1554.,   638.,   500.,   520.,  1218.,
            578.,  -118.,  -244.],
         [  120.,   462.,   948.,   894.,   860.,   890.,   146.,   772.,
            434.,   904.,   674.,  1180.,   444.,   804., -1146.,   828.,
            518.,  -546.,   214.,  1328.,   308.,    12.,   -34.,   440.,
            244.,   400.,   460.,   460.,   772.,   322.,   724.,   570.,
           -148.,  3194.,   816.,  1554.,   638.,   500.,   520.,  1218.,
            578.,  -118.,  -244.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3074., 2732., 2246., 2300., 2334., 2304., 3048., 2422., 2760., 2290.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.1379 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:03<00:00,  3.94s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  56.,  362.,  848.,  870., 1036.,  802.,  146.,  828.,  638.,  800.,
           646.,  948.,  344.,  956., -938.,  824.,  426., -410.,  242., 1308.,
           428.,  140.,  102.,  324.,  188.,  324.,  528.,  472.,  708.,  398.,
           592.,  558., -140., 2582.,  560., 2142.,  866.,  376.,  408., 1382.,
           602.,  170., -264.],
         [  56.,  362.,  848.,  870., 1036.,  802.,  146.,  828.,  638.,  800.,
           646.,  948.,  344.,  956., -938.,  824.,  426., -410.,  242., 1308.,
           428.,  140.,  102.,  324.,  188.,  324.,  528.,  472.,  708.,  398.,
           592.,  558., -140., 2582.,  560., 2142.,  866.,  376.,  408., 1382.,
           602.,  170., -264.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2526., 2220., 1734., 1712., 1546., 1780., 2436., 1754., 1944., 1782.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 3.9479 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
100%|| 1/1 [00:04<00:00,  4.23s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  140.,   418.,   880.,   722.,   844.,   910.,   190.,   748.,
            530.,   884.,   686.,  1228.,   480.,   740., -1102.,   748.,
            486.,  -510.,   134.,  1404.,   288.,   108.,   -54.,   404.,
            264.,   372.,   508.,   420.,   752.,   390.,   856.,   590.,
           -144.,  3182.,   684.,  1506.,   698.,   276.,   444.,  1210.,
            594.,  -118.,  -100.],
         [  140.,   418.,   880.,   722.,   844.,   910.,   190.,   748.,
            530.,   884.,   686.,  1228.,   480.,   740., -1102.,   748.,
            486.,  -510.,   134.,  1404.,   288.,   108.,   -54.,   404.,
            264.,   372.,   508.,   420.,   752.,   390.,   856.,   590.,
           -144.,  3182.,   684.,  1506.,   698.,   276.,   444.,  1210.,
            594.,  -118.,  -100.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[3042., 2764., 2302., 2460., 2338., 2272., 2992., 2434., 2652., 2298.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 4.2388 seconds.
PGD attack failed
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/2): BoundBuffers(name=/2, inputs=[], perturbed=False)
  (/shape): BoundBuffers(name=/shape, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True)
  (/13): BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True)
  (/17): BoundSplit(name=/17, inputs=[/shape], perturbed=False)
  (/18): BoundSplit(name=/18, inputs=[/shape], perturbed=False)
  (/19): BoundSqueeze(name=/19, inputs=[/17], perturbed=False)
  (/20): BoundSqueeze(name=/20, inputs=[/18], perturbed=False)
  (/21): BoundUnsqueeze(name=/21, inputs=[/19], perturbed=False)
  (/22): BoundUnsqueeze(name=/22, inputs=[/20], perturbed=False)
  (/23): BoundConcat(name=/23, inputs=[/21, /22], perturbed=False)
  (/24): BoundReshape(name=/24, inputs=[/14/merge, /23], perturbed=True)
  (/25): BoundTranspose(name=/25, inputs=[/8], perturbed=False)
  (/26): BoundMatMul(name=/26, inputs=[/24, /25], perturbed=True)
  (/10/merge): BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
  (/14/merge): BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
)
Original output: tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
Split layers:
  BoundConv(name=/9, inputs=[/input.1, /6], perturbed=True): [(BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True), 0)]
  BoundConv(name=/13, inputs=[/10/merge, /7], perturbed=True): [(BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True), 0)]
Nonlinear functions:
   BoundSignMerge(name=/10/merge, inputs=[/9], perturbed=True)
   BoundSignMerge(name=/14/merge, inputs=[/13], perturbed=True)
initial crown bounds: tensor([[ -8534.,  -9120.,  -9430.,  -9196.,  -9146.,  -9244.,  -8272.,  -8974.,
          -8740.,  -9162.,  -8796.,  -9102.,  -8854.,  -8866.,  -8032.,  -9270.,
          -8532.,  -8512.,  -9008.,  -9434.,  -9042.,  -8654.,  -8268.,  -8842.,
          -8222.,  -8778.,  -8946.,  -8846.,  -9330.,  -8820.,  -8782.,  -9040.,
          -8434.,  -8846.,  -9680.,  -9180.,  -8698.,  -8766., -10008.,  -8864.,
          -8756.,  -7850.]], device='cuda:0')
Worst class: (+ rhs) -10008.0
Total VNNLIB file length: 42, max property batch size: 1, total number of batches: 42
lA shape: [torch.Size([42, 1, 16, 28, 28]), torch.Size([42, 1, 32, 27, 27])]

Properties batch 0, size 1
Remaining timeout: 832.8379459381104
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
Remaining spec index tensor([0], device='cuda:0') with bounds tensor([[-8534.]], device='cuda:0') need to verify.
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Model prediction is: tensor([   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
          860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
          214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
          400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
          674.,   376.,   500.,  1222.,   674.,  -166.,  -220.],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 43])
lA shapes: [torch.Size([1, 1, 16, 28, 28]), torch.Size([1, 1, 32, 27, 27])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-8534.]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /9,/13,/26
Keeping alphas for these layers: ['/26']
Keeping alphas for these layers: ['/26']
Node /10/merge input 0: size torch.Size([16, 28, 28]) unstable 12544
Node /14/merge input 0: size torch.Size([32, 27, 27]) unstable 23328
-----------------
# of unstable neurons: 35872
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/13, 14011] 
split level 1: [/13, 11149] 
split level 2: [/13, 3103] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 8 = 0.0
pruning-in-iteration extra time: 9.274482727050781e-05
Time: prepare 0.0004    bound 0.2200    transfer 0.0002    finalize 0.0007    func 0.2213    
Accumulated time: func 0.2213    prepare 0.0007    bound 0.2200    transfer 0.0002    finalize 0.0007    
Current worst splitting domains lb-rhs (depth):
-7078.97705 (3), -7078.95215 (3), -7078.69531 (3), -7078.65479 (3), -7078.00049 (3), -7077.97949 (3), -7077.91797 (3), -7077.87939 (3), 
length of domains: 8
Time: pickout 0.0003    decision 0.0291    set_bounds 0.0012    solve 0.2213    add 0.0105    
Accumulated time: pickout 0.0003    decision 0.0291    set_bounds 0.0012    solve 0.2213    add 0.0105    
Current (lb-rhs): -7078.97705078125
8 domains visited
Cumulative time: 0.5078907012939453

BaB round 2
batch: 8
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] [/9, 8515] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 16 = 0.0
pruning-in-iteration extra time: 5.602836608886719e-05
Time: prepare 0.0017    bound 0.0833    transfer 0.0003    finalize 0.0011    func 0.0864    
Accumulated time: func 0.3077    prepare 0.0029    bound 0.3032    transfer 0.0005    finalize 0.0018    
Current worst splitting domains lb-rhs (depth):
-6795.65430 (4), -6795.58252 (4), -6795.22803 (4), -6795.18213 (4), -6793.68506 (4), -6793.61426 (4), -6793.59326 (4), -6793.56299 (4), -6793.41064 (4), -6793.35547 (4), -6793.25977 (4), -6793.21387 (4), -6791.62500 (4), -6791.59424 (4), -6791.44189 (4), -6791.38721 (4), 
length of domains: 16
Time: pickout 0.0006    decision 0.0307    set_bounds 0.0019    solve 0.0865    add 0.0019    
Accumulated time: pickout 0.0009    decision 0.0598    set_bounds 0.0031    solve 0.3078    add 0.0124    
Current (lb-rhs): -6795.654296875
24 domains visited
Cumulative time: 0.629636287689209

BaB round 3
batch: 16
Average branched neurons at iteration 3:  1.0000
splitting decisions: 
split level 0: [/9, 11622] [/9, 11622] [/9, 11622] [/9, 11622] [/9, 8004] [/9, 11622] [/9, 11622] [/9, 11622] [/9, 11622] [/9, 11622] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 5.4836273193359375e-05
Time: prepare 0.0031    bound 0.0860    transfer 0.0005    finalize 0.0020    func 0.0916    
Accumulated time: func 0.3993    prepare 0.0063    bound 0.3892    transfer 0.0011    finalize 0.0038    
Current worst splitting domains lb-rhs (depth):
-6755.93799 (5), -6755.86035 (5), -6755.80469 (5), -6755.56738 (5), -6755.51221 (5), -6755.26855 (5), -6755.21289 (5), -6754.77686 (5), -6754.18408 (5), -6754.12842 (5), -6754.10742 (5), -6754.02930 (5), -6753.97070 (5), -6753.91504 (5), -6753.79980 (5), -6753.75684 (5), -6753.74414 (5), -6753.73682 (5), -6753.67969 (5), -6753.59131 (5), 
length of domains: 32
Time: pickout 0.0008    decision 0.0333    set_bounds 0.0024    solve 0.0916    add 0.0037    
Accumulated time: pickout 0.0017    decision 0.0931    set_bounds 0.0055    solve 0.3994    add 0.0161    
Current (lb-rhs): -6755.93798828125
56 domains visited
Cumulative time: 0.7616713047027588

BaB round 4
batch: 32
Average branched neurons at iteration 4:  1.0000
splitting decisions: 
split level 0: [/9, 8004] [/9, 8004] [/9, 8004] [/9, 8004] [/9, 11622] [/9, 8004] [/9, 8004] [/9, 8004] [/9, 8469] [/9, 8004] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 5.698204040527344e-05
Time: prepare 0.0042    bound 0.1267    transfer 0.0010    finalize 0.0068    func 0.1388    
Accumulated time: func 0.5381    prepare 0.0108    bound 0.5159    transfer 0.0021    finalize 0.0106    
Current worst splitting domains lb-rhs (depth):
-6745.83594 (6), -6745.80664 (6), -6745.67188 (6), -6745.62744 (6), -6745.41553 (6), -6745.37158 (6), -6745.00635 (6), -6744.96191 (6), -6744.59961 (6), -6744.57080 (6), -6744.50293 (6), -6744.45898 (6), -6744.30127 (6), -6744.25684 (6), -6744.12305 (6), -6743.95947 (6), -6743.95361 (6), -6743.90918 (6), -6743.79297 (6), -6743.74854 (6), 
length of domains: 64
Time: pickout 0.0011    decision 0.0579    set_bounds 0.0042    solve 0.1388    add 0.0078    
Accumulated time: pickout 0.0028    decision 0.1510    set_bounds 0.0098    solve 0.5383    add 0.0239    
Current (lb-rhs): -6745.8359375
120 domains visited
Cumulative time: 0.9717087745666504

BaB round 5
batch: 64
Average branched neurons at iteration 5:  1.0000
splitting decisions: 
split level 0: [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8469] [/9, 8004] [/9, 8469] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 5.888938903808594e-05
Time: prepare 0.0093    bound 0.2342    transfer 0.0019    finalize 0.0131    func 0.2585    
Accumulated time: func 0.7966    prepare 0.0204    bound 0.7501    transfer 0.0039    finalize 0.0237    
Current worst splitting domains lb-rhs (depth):
-6744.68018 (7), -6744.67139 (7), -6744.63525 (7), -6744.62695 (7), -6744.51514 (7), -6744.50732 (7), -6744.41504 (7), -6744.40625 (7), -6744.22168 (7), -6744.21387 (7), -6744.12158 (7), -6744.11377 (7), -6743.84814 (7), -6743.83984 (7), -6743.74805 (7), -6743.73975 (7), -6743.47705 (7), -6743.43213 (7), -6743.42480 (7), -6743.34473 (7), 
length of domains: 128
Time: pickout 0.0027    decision 0.0940    set_bounds 0.0079    solve 0.2585    add 0.0149    
Accumulated time: pickout 0.0055    decision 0.2450    set_bounds 0.0176    solve 0.7968    add 0.0389    
Current (lb-rhs): -6744.68017578125
248 domains visited
Cumulative time: 1.3499715328216553

BaB round 6
batch: 128
Average branched neurons at iteration 6:  1.0000
splitting decisions: 
split level 0: [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] [/9, 4644] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.29425048828125e-05
Time: prepare 0.0178    bound 0.4685    transfer 0.0107    finalize 0.0343    func 0.5315    
Accumulated time: func 1.3281    prepare 0.0385    bound 1.2186    transfer 0.0147    finalize 0.0580    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.83301 (8), -6743.82275 (8), -6743.80371 (8), -6743.79297 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.68945 (8), -6743.66016 (8), -6743.65381 (8), -6743.62500 (8), -6743.52344 (8), -6743.49365 (8), -6743.49365 (8), -6743.48779 (8), 
length of domains: 256
Time: pickout 0.0060    decision 0.1818    set_bounds 0.0152    solve 0.5316    add 0.0378    
Accumulated time: pickout 0.0115    decision 0.4268    set_bounds 0.0328    solve 1.3284    add 0.0767    
Current (lb-rhs): -6743.888671875
504 domains visited
Cumulative time: 2.1252920627593994

BaB round 7
batch: 128
Average branched neurons at iteration 7:  1.0000
splitting decisions: 
split level 0: [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] [/9, 8439] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0195    bound 0.4883    transfer 0.0063    finalize 0.0335    func 0.5476    
Accumulated time: func 1.8757    prepare 0.0583    bound 1.7068    transfer 0.0210    finalize 0.0915    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 384
Time: pickout 0.0081    decision 0.1984    set_bounds 0.0158    solve 0.5477    add 0.0324    
Accumulated time: pickout 0.0196    decision 0.6252    set_bounds 0.0487    solve 1.8761    add 0.1091    
Current (lb-rhs): -6743.888671875
760 domains visited
Cumulative time: 2.9280033111572266

BaB round 8
batch: 128
Average branched neurons at iteration 8:  1.0000
splitting decisions: 
split level 0: [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] [/9, 4355] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.341934204101562e-05
Time: prepare 0.0176    bound 0.4396    transfer 0.0037    finalize 0.0152    func 0.4761    
Accumulated time: func 2.3518    prepare 0.0763    bound 2.1464    transfer 0.0246    finalize 0.1067    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 512
Time: pickout 0.0057    decision 0.1824    set_bounds 0.0152    solve 0.4762    add 0.0328    
Accumulated time: pickout 0.0253    decision 0.8076    set_bounds 0.0639    solve 2.3524    add 0.1419    
Current (lb-rhs): -6743.888671875
1016 domains visited
Cumulative time: 3.641529083251953

BaB round 9
batch: 128
Average branched neurons at iteration 9:  1.0000
splitting decisions: 
split level 0: [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] [/9, 1857] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0175    bound 0.4381    transfer 0.0037    finalize 0.0197    func 0.4790    
Accumulated time: func 2.8308    prepare 0.0940    bound 2.5846    transfer 0.0283    finalize 0.1263    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 640
Time: pickout 0.0059    decision 0.1803    set_bounds 0.0152    solve 0.4791    add 0.0355    
Accumulated time: pickout 0.0312    decision 0.9879    set_bounds 0.0791    solve 2.8314    add 0.1774    
Current (lb-rhs): -6743.888671875
1272 domains visited
Cumulative time: 4.357880353927612

BaB round 10
batch: 128
Average branched neurons at iteration 10:  1.0000
splitting decisions: 
split level 0: [/9, 7881] [/9, 7881] [/9, 7881] [/9, 7881] [/9, 8003] [/9, 7881] [/9, 8003] [/9, 7881] [/9, 7881] [/9, 7881] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0198    bound 0.4936    transfer 0.0036    finalize 0.0152    func 0.5323    
Accumulated time: func 3.3631    prepare 0.1141    bound 3.0781    transfer 0.0320    finalize 0.1415    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 768
Time: pickout 0.0057    decision 0.1952    set_bounds 0.0155    solve 0.5324    add 0.0308    
Accumulated time: pickout 0.0369    decision 1.1831    set_bounds 0.0946    solve 3.3638    add 0.2082    
Current (lb-rhs): -6743.888671875
1528 domains visited
Cumulative time: 5.137685537338257

BaB round 11
batch: 128
Average branched neurons at iteration 11:  1.0000
splitting decisions: 
split level 0: [/9, 8516] [/9, 8149] [/9, 8516] [/9, 8516] [/9, 7881] [/9, 8516] [/9, 7881] [/9, 8516] [/9, 8516] [/9, 8516] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0201    bound 0.4382    transfer 0.0036    finalize 0.0156    func 0.4777    
Accumulated time: func 3.8407    prepare 0.1346    bound 3.5163    transfer 0.0356    finalize 0.1572    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 896
Time: pickout 0.0060    decision 0.1984    set_bounds 0.0153    solve 0.4778    add 0.0299    
Accumulated time: pickout 0.0429    decision 1.3815    set_bounds 0.1099    solve 3.8415    add 0.2381    
Current (lb-rhs): -6743.888671875
1784 domains visited
Cumulative time: 5.865386009216309

BaB round 12
batch: 128
Average branched neurons at iteration 12:  1.0000
splitting decisions: 
split level 0: [/9, 8149] [/9, 8516] [/9, 8149] [/9, 8149] [/9, 11140] [/9, 8149] [/9, 11140] [/9, 8149] [/9, 8149] [/9, 8003] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.079673767089844e-05
Time: prepare 0.0175    bound 0.4405    transfer 0.0039    finalize 0.0156    func 0.4776    
Accumulated time: func 4.3183    prepare 0.1524    bound 3.9568    transfer 0.0395    finalize 0.1728    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1024
Time: pickout 0.0060    decision 0.1796    set_bounds 0.0152    solve 0.4777    add 0.0329    
Accumulated time: pickout 0.0490    decision 1.5612    set_bounds 0.1251    solve 4.3193    add 0.2710    
Current (lb-rhs): -6743.888671875
2040 domains visited
Cumulative time: 6.577171802520752

BaB round 13
batch: 128
Average branched neurons at iteration 13:  1.0000
splitting decisions: 
split level 0: [/9, 8003] [/9, 8003] [/9, 8003] [/9, 8003] [/9, 8149] [/9, 8003] [/9, 8149] [/9, 8003] [/9, 8003] [/9, 8149] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.246566772460938e-05
Time: prepare 0.0198    bound 0.4972    transfer 0.0036    finalize 0.0152    func 0.5360    
Accumulated time: func 4.8543    prepare 0.1726    bound 4.4541    transfer 0.0432    finalize 0.1880    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1152
Time: pickout 0.0069    decision 0.2000    set_bounds 0.0155    solve 0.5361    add 0.3751    
Accumulated time: pickout 0.0559    decision 1.7612    set_bounds 0.1406    solve 4.8553    add 0.6461    
Current (lb-rhs): -6743.888671875
2296 domains visited
Cumulative time: 7.711097002029419

BaB round 14
batch: 128
Average branched neurons at iteration 14:  1.0000
splitting decisions: 
split level 0: [/9, 2039] [/9, 11621] [/9, 2039] [/9, 2039] [/9, 8516] [/9, 11621] [/9, 8516] [/9, 2039] [/9, 2039] [/9, 2039] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.127357482910156e-05
Time: prepare 0.0197    bound 0.4461    transfer 0.0037    finalize 0.0153    func 0.4848    
Accumulated time: func 5.3391    prepare 0.1925    bound 4.9002    transfer 0.0469    finalize 0.2033    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1280
Time: pickout 0.0059    decision 0.1982    set_bounds 0.0157    solve 0.4849    add 0.0323    
Accumulated time: pickout 0.0618    decision 1.9594    set_bounds 0.1564    solve 5.3402    add 0.6784    
Current (lb-rhs): -6743.888671875
2552 domains visited
Cumulative time: 8.449292659759521

BaB round 15
batch: 128
Average branched neurons at iteration 15:  1.0000
splitting decisions: 
split level 0: [/9, 11621] [/9, 2039] [/9, 11621] [/9, 11621] [/9, 11621] [/9, 8513] [/9, 2039] [/9, 11621] [/9, 11621] [/9, 11621] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.270408630371094e-05
Time: prepare 0.0206    bound 0.4525    transfer 0.0037    finalize 0.0243    func 0.5011    
Accumulated time: func 5.8402    prepare 0.2134    bound 5.3527    transfer 0.0505    finalize 0.2276    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1408
Time: pickout 0.0061    decision 0.1873    set_bounds 0.0159    solve 0.5012    add 0.0352    
Accumulated time: pickout 0.0679    decision 2.1468    set_bounds 0.1722    solve 5.8415    add 0.7135    
Current (lb-rhs): -6743.888671875
2808 domains visited
Cumulative time: 9.195285558700562

BaB round 16
batch: 128
Average branched neurons at iteration 16:  1.0000
splitting decisions: 
split level 0: [/9, 8032] [/9, 8032] [/9, 8032] [/9, 7894] [/9, 2039] [/9, 2039] [/9, 11621] [/9, 11653] [/9, 11653] [/9, 8032] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.437301635742188e-05
Time: prepare 0.0177    bound 0.4855    transfer 0.0036    finalize 0.0198    func 0.5266    
Accumulated time: func 6.3668    prepare 0.2315    bound 5.8381    transfer 0.0542    finalize 0.2474    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1536
Time: pickout 0.0066    decision 0.1791    set_bounds 0.0156    solve 0.5267    add 0.0332    
Accumulated time: pickout 0.0745    decision 2.3259    set_bounds 0.1878    solve 6.3682    add 0.7467    
Current (lb-rhs): -6743.888671875
3064 domains visited
Cumulative time: 9.956878662109375

BaB round 17
batch: 128
Average branched neurons at iteration 17:  1.0000
splitting decisions: 
split level 0: [/9, 11653] [/9, 11653] [/9, 11653] [/9, 8032] [/9, 7894] [/9, 11653] [/9, 7894] [/9, 11066] [/9, 8032] [/9, 11653] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0195    bound 0.4841    transfer 0.0037    finalize 0.0154    func 0.5227    
Accumulated time: func 6.8896    prepare 0.2512    bound 6.3222    transfer 0.0578    finalize 0.2629    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1664
Time: pickout 0.0061    decision 0.1981    set_bounds 0.0155    solve 0.5228    add 0.0344    
Accumulated time: pickout 0.0806    decision 2.5240    set_bounds 0.2033    solve 6.8910    add 0.7811    
Current (lb-rhs): -6743.888671875
3320 domains visited
Cumulative time: 10.734232425689697

BaB round 18
batch: 128
Average branched neurons at iteration 18:  1.0000
splitting decisions: 
split level 0: [/9, 8513] [/9, 11066] [/9, 8513] [/9, 11653] [/9, 11653] [/9, 11066] [/9, 11653] [/9, 8513] [/9, 11066] [/9, 8513] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.175041198730469e-05
Time: prepare 0.0202    bound 0.4642    transfer 0.0036    finalize 0.0197    func 0.5077    
Accumulated time: func 7.3973    prepare 0.2718    bound 6.7864    transfer 0.0615    finalize 0.2826    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1792
Time: pickout 0.0069    decision 0.1991    set_bounds 0.0155    solve 0.5083    add 0.0336    
Accumulated time: pickout 0.0875    decision 2.7231    set_bounds 0.2188    solve 7.3993    add 0.8147    
Current (lb-rhs): -6743.888671875
3576 domains visited
Cumulative time: 11.498724937438965

BaB round 19
batch: 128
Average branched neurons at iteration 19:  1.0000
splitting decisions: 
split level 0: [/9, 11066] [/9, 8513] [/9, 11066] [/9, 8513] [/9, 8513] [/9, 8032] [/9, 8513] [/9, 8032] [/9, 8513] [/9, 11066] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.222724914550781e-05
Time: prepare 0.0177    bound 0.4366    transfer 0.0036    finalize 0.0197    func 0.4777    
Accumulated time: func 7.8750    prepare 0.2898    bound 7.2230    transfer 0.0651    finalize 0.3023    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 1920
Time: pickout 0.0061    decision 0.1812    set_bounds 0.0153    solve 0.4778    add 0.0337    
Accumulated time: pickout 0.0936    decision 2.9043    set_bounds 0.2341    solve 7.8771    add 0.8484    
Current (lb-rhs): -6743.888671875
3832 domains visited
Cumulative time: 12.213130235671997

BaB round 20
batch: 128
Average branched neurons at iteration 20:  1.0000
splitting decisions: 
split level 0: [/9, 11140] [/9, 7894] [/9, 11140] [/9, 11066] [/9, 11066] [/9, 7894] [/9, 11066] [/9, 7894] [/9, 11140] [/9, 7894] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.0001385211944580078
Time: prepare 0.0178    bound 0.4854    transfer 0.0037    finalize 0.0198    func 0.5267    
Accumulated time: func 8.4017    prepare 0.3080    bound 7.7084    transfer 0.0688    finalize 0.3221    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2048
Time: pickout 0.0072    decision 0.1802    set_bounds 0.0153    solve 0.5269    add 0.0339    
Accumulated time: pickout 0.1008    decision 3.0845    set_bounds 0.2494    solve 8.4040    add 0.8823    
Current (lb-rhs): -6743.888671875
4088 domains visited
Cumulative time: 12.97700047492981

BaB round 21
batch: 128
Average branched neurons at iteration 21:  1.0000
splitting decisions: 
split level 0: [/9, 4568] [/9, 11140] [/9, 4568] [/9, 11140] [/9, 8032] [/9, 11140] [/9, 8032] [/9, 11140] [/9, 2116] [/9, 11140] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.000133514404296875
Time: prepare 0.0196    bound 0.4643    transfer 0.0038    finalize 0.0244    func 0.5122    
Accumulated time: func 8.9139    prepare 0.3280    bound 8.1727    transfer 0.0726    finalize 0.3465    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2176
Time: pickout 0.0069    decision 0.1962    set_bounds 0.0155    solve 0.5123    add 0.6488    
Accumulated time: pickout 0.1077    decision 3.2807    set_bounds 0.2649    solve 8.9163    add 1.5311    
Current (lb-rhs): -6743.888671875
4344 domains visited
Cumulative time: 14.357144117355347

BaB round 22
batch: 128
Average branched neurons at iteration 22:  1.0000
splitting decisions: 
split level 0: [/9, 4516] [/9, 4568] [/9, 2116] [/9, 4568] [/9, 4568] [/9, 4568] [/9, 4568] [/9, 4568] [/9, 8121] [/9, 2116] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.389617919921875e-05
Time: prepare 0.0204    bound 0.4396    transfer 0.0037    finalize 0.0156    func 0.4794    
Accumulated time: func 9.3933    prepare 0.3487    bound 8.6123    transfer 0.0763    finalize 0.3621    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2304
Time: pickout 0.0058    decision 0.1969    set_bounds 0.0155    solve 0.4795    add 0.0335    
Accumulated time: pickout 0.1135    decision 3.4776    set_bounds 0.2805    solve 9.3958    add 1.5647    
Current (lb-rhs): -6743.888671875
4600 domains visited
Cumulative time: 15.088780403137207

BaB round 23
batch: 128
Average branched neurons at iteration 23:  1.0000
splitting decisions: 
split level 0: [/9, 2116] [/9, 2116] [/9, 10019] [/9, 2116] [/9, 11168] [/9, 2116] [/9, 2116] [/9, 8033] [/9, 10019] [/9, 8121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 9.703636169433594e-05
Time: prepare 0.0176    bound 0.4418    transfer 0.0037    finalize 0.0159    func 0.4791    
Accumulated time: func 9.8724    prepare 0.3666    bound 9.0541    transfer 0.0800    finalize 0.3780    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2432
Time: pickout 0.0059    decision 0.1800    set_bounds 0.0152    solve 0.4792    add 0.0341    
Accumulated time: pickout 0.1194    decision 3.6576    set_bounds 0.2957    solve 9.8750    add 1.5988    
Current (lb-rhs): -6743.888671875
4856 domains visited
Cumulative time: 15.803598880767822

BaB round 24
batch: 128
Average branched neurons at iteration 24:  1.0000
splitting decisions: 
split level 0: [/9, 8121] [/9, 8121] [/9, 8121] [/9, 8121] [/9, 2116] [/9, 4516] [/9, 10019] [/9, 2116] [/9, 7894] [/9, 10019] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00012230873107910156
Time: prepare 0.0197    bound 0.4846    transfer 0.0037    finalize 0.0153    func 0.5234    
Accumulated time: func 10.3958    prepare 0.3866    bound 9.5388    transfer 0.0837    finalize 0.3934    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2560
Time: pickout 0.0064    decision 0.2003    set_bounds 0.0154    solve 0.5235    add 0.0331    
Accumulated time: pickout 0.1258    decision 3.8578    set_bounds 0.3111    solve 10.3985    add 1.6319    
Current (lb-rhs): -6743.888671875
5112 domains visited
Cumulative time: 16.582724809646606

BaB round 25
batch: 128
Average branched neurons at iteration 25:  1.0000
splitting decisions: 
split level 0: [/9, 10019] [/9, 10019] [/9, 8553] [/9, 10019] [/9, 8121] [/9, 8033] [/9, 8121] [/9, 8121] [/9, 4329] [/9, 8553] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.079673767089844e-05
Time: prepare 0.0181    bound 0.4299    transfer 0.0037    finalize 0.0152    func 0.4669    
Accumulated time: func 10.8627    prepare 0.4051    bound 9.9686    transfer 0.0874    finalize 0.4086    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2688
Time: pickout 0.0062    decision 0.1870    set_bounds 0.0153    solve 0.4670    add 0.0317    
Accumulated time: pickout 0.1320    decision 4.0448    set_bounds 0.3264    solve 10.8654    add 1.6636    
Current (lb-rhs): -6743.888671875
5368 domains visited
Cumulative time: 17.29033327102661

BaB round 26
batch: 128
Average branched neurons at iteration 26:  1.0000
splitting decisions: 
split level 0: [/9, 8553] [/9, 4516] [/9, 7894] [/9, 4516] [/9, 10019] [/9, 8121] [/9, 11168] [/9, 10019] [/9, 8553] [/9, 4329] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.365776062011719e-05
Time: prepare 0.0177    bound 0.4327    transfer 0.0036    finalize 0.0153    func 0.4694    
Accumulated time: func 11.3321    prepare 0.4231    bound 10.4013    transfer 0.0910    finalize 0.4239    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2816
Time: pickout 0.0059    decision 0.1786    set_bounds 0.0152    solve 0.4695    add 0.0318    
Accumulated time: pickout 0.1379    decision 4.2234    set_bounds 0.3416    solve 11.3350    add 1.6955    
Current (lb-rhs): -6743.888671875
5624 domains visited
Cumulative time: 17.991806745529175

BaB round 27
batch: 128
Average branched neurons at iteration 27:  1.0000
splitting decisions: 
split level 0: [/9, 7894] [/9, 4329] [/9, 4516] [/9, 4329] [/9, 4516] [/9, 10019] [/9, 4516] [/9, 4516] [/9, 11121] [/9, 8260] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.532669067382812e-05
Time: prepare 0.0196    bound 0.4836    transfer 0.0037    finalize 0.0154    func 0.5222    
Accumulated time: func 11.8543    prepare 0.4430    bound 10.8849    transfer 0.0947    finalize 0.4393    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 2944
Time: pickout 0.0058    decision 0.1830    set_bounds 0.0154    solve 0.5224    add 0.0327    
Accumulated time: pickout 0.1437    decision 4.4065    set_bounds 0.3570    solve 11.8573    add 1.7281    
Current (lb-rhs): -6743.888671875
5880 domains visited
Cumulative time: 18.75145649909973

BaB round 28
batch: 128
Average branched neurons at iteration 28:  1.0000
splitting decisions: 
split level 0: [/9, 2108] [/9, 11684] [/9, 4329] [/9, 2108] [/9, 8553] [/9, 2108] [/9, 4329] [/9, 8553] [/9, 8260] [/9, 11044] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.198883056640625e-05
Time: prepare 0.0205    bound 0.4940    transfer 0.0036    finalize 0.0153    func 0.5335    
Accumulated time: func 12.3878    prepare 0.4639    bound 11.3789    transfer 0.0983    finalize 0.4546    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3072
Time: pickout 0.0060    decision 0.2026    set_bounds 0.0165    solve 0.5336    add 0.0325    
Accumulated time: pickout 0.1497    decision 4.6091    set_bounds 0.3735    solve 12.3909    add 1.7606    
Current (lb-rhs): -6743.888671875
6136 domains visited
Cumulative time: 19.542948484420776

BaB round 29
batch: 128
Average branched neurons at iteration 29:  1.0000
splitting decisions: 
split level 0: [/9, 4329] [/9, 2108] [/9, 11684] [/9, 11684] [/9, 4329] [/9, 11684] [/9, 8553] [/9, 11684] [/9, 8198] [/9, 8198] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0197    bound 0.4825    transfer 0.0037    finalize 0.0153    func 0.5213    
Accumulated time: func 12.9091    prepare 0.4840    bound 11.8614    transfer 0.1020    finalize 0.4699    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3200
Time: pickout 0.0059    decision 0.1978    set_bounds 0.0155    solve 0.5214    add 0.0319    
Accumulated time: pickout 0.1555    decision 4.8068    set_bounds 0.3890    solve 12.9123    add 1.7925    
Current (lb-rhs): -6743.888671875
6392 domains visited
Cumulative time: 20.315818786621094

BaB round 30
batch: 128
Average branched neurons at iteration 30:  1.0000
splitting decisions: 
split level 0: [/9, 11684] [/9, 8553] [/9, 2108] [/9, 8553] [/9, 2108] [/9, 4329] [/9, 2108] [/9, 2108] [/13, 5362] [/9, 11121] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.318092346191406e-05
Time: prepare 0.0199    bound 0.4602    transfer 0.0036    finalize 0.0153    func 0.4992    
Accumulated time: func 13.4083    prepare 0.5042    bound 12.3217    transfer 0.1056    finalize 0.4853    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3328
Time: pickout 0.0060    decision 0.1957    set_bounds 0.0154    solve 0.4998    add 0.0329    
Accumulated time: pickout 0.1615    decision 5.0025    set_bounds 0.4044    solve 13.4122    add 1.8254    
Current (lb-rhs): -6743.888671875
6648 domains visited
Cumulative time: 21.06610631942749

BaB round 31
batch: 128
Average branched neurons at iteration 31:  1.0000
splitting decisions: 
split level 0: [/9, 11121] [/9, 11121] [/9, 11121] [/9, 8260] [/9, 11684] [/9, 8260] [/9, 11684] [/9, 4329] [/9, 4516] [/9, 4516] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0176    bound 0.4341    transfer 0.0037    finalize 0.0154    func 0.4708    
Accumulated time: func 13.8791    prepare 0.5222    bound 12.7557    transfer 0.1093    finalize 0.5006    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3456
Time: pickout 0.0059    decision 0.1798    set_bounds 0.0153    solve 0.4709    add 0.0327    
Accumulated time: pickout 0.1674    decision 5.1823    set_bounds 0.4197    solve 13.8831    add 1.8581    
Current (lb-rhs): -6743.888671875
6904 domains visited
Cumulative time: 21.77106022834778

BaB round 32
batch: 128
Average branched neurons at iteration 32:  1.0000
splitting decisions: 
split level 0: [/9, 8260] [/9, 8260] [/9, 8260] [/9, 11121] [/9, 8033] [/9, 8553] [/9, 8260] [/9, 11121] [/9, 11684] [/9, 2108] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 5.984306335449219e-05
Time: prepare 0.0179    bound 0.4301    transfer 0.0037    finalize 0.0153    func 0.4670    
Accumulated time: func 14.3461    prepare 0.5404    bound 13.1859    transfer 0.1130    finalize 0.5159    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3584
Time: pickout 0.0057    decision 0.1819    set_bounds 0.0152    solve 0.4671    add 0.0334    
Accumulated time: pickout 0.1732    decision 5.3642    set_bounds 0.4349    solve 14.3502    add 1.8915    
Current (lb-rhs): -6743.888671875
7160 domains visited
Cumulative time: 22.47486448287964

BaB round 33
batch: 128
Average branched neurons at iteration 33:  1.0000
splitting decisions: 
split level 0: [/9, 8198] [/9, 8198] [/9, 8198] [/9, 8198] [/9, 11121] [/9, 11121] [/9, 11121] [/9, 8260] [/9, 2108] [/9, 11027] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00013947486877441406
Time: prepare 0.0200    bound 0.4833    transfer 0.0037    finalize 0.0153    func 0.5224    
Accumulated time: func 14.8685    prepare 0.5608    bound 13.6692    transfer 0.1166    finalize 0.5312    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3712
Time: pickout 0.0056    decision 0.1835    set_bounds 0.0158    solve 0.5225    add 0.0318    
Accumulated time: pickout 0.1788    decision 5.5476    set_bounds 0.4507    solve 14.8728    add 1.9233    
Current (lb-rhs): -6743.888671875
7416 domains visited
Cumulative time: 23.234548807144165

BaB round 34
batch: 128
Average branched neurons at iteration 34:  1.0000
splitting decisions: 
split level 0: [/9, 11044] [/9, 11044] [/9, 11044] [/9, 11044] [/9, 8260] [/9, 11044] [/9, 8198] [/9, 8198] [/9, 11044] [/9, 11684] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.365776062011719e-05
Time: prepare 0.0202    bound 0.4834    transfer 0.0036    finalize 0.0154    func 0.5228    
Accumulated time: func 15.3914    prepare 0.5813    bound 14.1527    transfer 0.1203    finalize 0.5467    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3840
Time: pickout 0.0060    decision 0.1969    set_bounds 0.0156    solve 0.5229    add 0.0322    
Accumulated time: pickout 0.1847    decision 5.7445    set_bounds 0.4663    solve 15.3957    add 1.9555    
Current (lb-rhs): -6743.888671875
7672 domains visited
Cumulative time: 24.008639097213745

BaB round 35
batch: 128
Average branched neurons at iteration 35:  1.0000
splitting decisions: 
split level 0: [/9, 11168] [/9, 11027] [/9, 11027] [/9, 11027] [/9, 8198] [/9, 8198] [/9, 11044] [/9, 11027] [/9, 4082] [/9, 11168] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.0005044937133789062
Time: prepare 0.0183    bound 0.4310    transfer 0.0038    finalize 0.0163    func 0.4695    
Accumulated time: func 15.8609    prepare 0.6000    bound 14.5836    transfer 0.1241    finalize 0.5630    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 3968
Time: pickout 0.0062    decision 0.1952    set_bounds 0.0156    solve 0.5234    add 0.0359    
Accumulated time: pickout 0.1909    decision 5.9397    set_bounds 0.4819    solve 15.9191    add 1.9914    
Current (lb-rhs): -6743.888671875
7928 domains visited
Cumulative time: 24.78538942337036

BaB round 36
batch: 128
Average branched neurons at iteration 36:  1.0000
splitting decisions: 
split level 0: [/9, 8523] [/9, 4082] [/9, 4082] [/9, 4082] [/9, 11044] [/9, 11027] [/9, 11027] [/9, 8148] [/9, 11168] [/9, 4082] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.4849853515625e-05
Time: prepare 0.0179    bound 0.4421    transfer 0.0036    finalize 0.0153    func 0.4790    
Accumulated time: func 16.3399    prepare 0.6182    bound 15.0257    transfer 0.1278    finalize 0.5784    
Current worst splitting domains lb-rhs (depth):
-6743.88867 (8), -6743.87793 (8), -6743.85889 (8), -6743.84814 (8), -6743.77734 (8), -6743.74707 (8), -6743.74170 (8), -6743.71191 (8), -6743.52344 (8), -6743.49365 (8), -6743.48779 (8), -6743.45850 (8), -6743.14941 (8), -6743.11963 (8), -6743.11377 (8), -6743.10547 (9), -6743.10059 (9), -6743.08447 (8), -6743.08398 (9), -6743.07812 (9), 
length of domains: 4096
Time: pickout 0.0058    decision 0.1788    set_bounds 0.0153    solve 0.4791    add 0.0348    
Accumulated time: pickout 0.1968    decision 6.1185    set_bounds 0.4971    solve 16.3982    add 2.0262    
Current (lb-rhs): -6743.888671875
8184 domains visited
Cumulative time: 25.500516891479492

BaB round 37
batch: 128
Average branched neurons at iteration 37:  1.0000
splitting decisions: 
split level 0: [/9, 11027] [/9, 11168] [/9, 7921] [/9, 11168] [/9, 8523] [/9, 4082] [/9, 8033] [/9, 11044] [/9, 8523] [/9, 8523] 
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 6.413459777832031e-05
Time: prepare 0.0213    bound 0.4940    transfer 0.0037    finalize 0.0153    func 0.5343    
Accumulated time: func 16.8742    prepare 0.6397    bound 15.5197    transfer 0.1314    finalize 0.5937    
Killed
sed: can't read out.txt: No such file or directory
head: cannot open 'out.txt' for reading: No such file or directory
run_instance.sh exit code: 0, Result: no_result_in_file, Runtime: 397.359597152
Appending result 'no_result_in_file' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:33:40 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 90%   55C    P5              36W / 170W |    755MiB / 12288MiB |     34%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          277MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     70MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    226MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:01<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 15.261319922

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:33:53 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2479s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:01<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  92.,  310.,  948.,  798.,  984.,  746.,  242.,  676.,  570.,  768.,
           638.,  988.,  284.,  856., -954.,  820.,  358., -362.,  322., 1220.,
           556.,  -52.,  170.,  276.,  272.,  416.,  544.,  516.,  744.,  318.,
           688.,  550., -176., 2306.,  456., 2326.,  874.,  548.,  500., 1258.,
           518.,  210., -332.],
         [  92.,  310.,  948.,  798.,  984.,  746.,  242.,  676.,  570.,  768.,
           638.,  988.,  284.,  856., -954.,  820.,  358., -362.,  322., 1220.,
           556.,  -52.,  170.,  276.,  272.,  416.,  544.,  516.,  744.,  318.,
           688.,  550., -176., 2306.,  456., 2326.,  874.,  548.,  500., 1258.,
           518.,  210., -332.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2214., 1996., 1358., 1508., 1322., 1560., 2064., 1630., 1736., 1538.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 1.1682 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 2.1567819118499756
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 6.090604416
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:34:01 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 88%   52C    P5              28W / 170W |    755MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          277MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     70MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    226MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.461789505

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:34:12 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2357s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-160.,  310.,  820.,  654.,  972.,  870.,  174.,  756.,  602.,  892.,
           646.,  896.,  408.,  832., -902.,  900.,  274., -322.,  290., 1432.,
           612.,  -12.,   -6.,  424.,   44.,  424.,  508.,  460.,  592.,  406.,
           536.,  534.,  -48., 2222.,  552., 2258.,  846.,  376.,  432., 1334.,
           666.,  318., -240.],
         [-160.,  310.,  820.,  654.,  972.,  870.,  174.,  756.,  602.,  892.,
           646.,  896.,  408.,  832., -902.,  900.,  274., -322.,  290., 1432.,
           612.,  -12.,   -6.,  424.,   44.,  424.,  508.,  460.,  592.,  406.,
           536.,  534.,  -48., 2222.,  552., 2258.,  846.,  376.,  432., 1334.,
           666.,  318., -240.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2382., 1912., 1402., 1568., 1250., 1352., 2048., 1466., 1620., 1330.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.3965 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.3856236934661865
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.309339340
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:34:19 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 86%   50C    P3              37W / 170W |    755MiB / 12288MiB |     10%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          277MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     70MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    226MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.453295923

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:34:30 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.3097s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_8258_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[   48.,   454.,   892.,   754.,   832.,   826.,   158.,   776.,   534.,
           860.,   718.,  1208.,   392.,   724., -1130.,   784.,   390.,  -618.,
           214.,  1376.,   248.,   112.,   -54.,   412.,   348.,   364.,   484.,
           400.,   784.,   266.,   820.,   602.,  -184.,  3282.,   712.,  1442.,
           674.,   376.,   500.,  1222.,   674.,  -166.,  -220.]],
       device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -86.,  164.,  826.,  656.,  866.,  700.,  120.,  630.,  708.,  734.,
           840., 1046.,  310.,  818., -948.,  838.,  376., -384.,  256., 1418.,
           590.,   42.,  -96.,  382.,  -10.,  322.,  666.,  354.,  938.,  432.,
           502.,  376.,   58., 2128.,  594., 2232.,  868.,  474.,  542., 1508.,
           848.,  164., -130.],
         [ -86.,  164.,  826.,  656.,  866.,  700.,  120.,  630.,  708.,  734.,
           840., 1046.,  310.,  818., -948.,  838.,  376., -384.,  256., 1418.,
           590.,   42.,  -96.,  382.,  -10.,  322.,  666.,  354.,  938.,  432.,
           502.,  376.,   58., 2128.,  594., 2232.,  868.,  474.,  542., 1508.,
           848.,  164., -130.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[2214., 1964., 1302., 1472., 1262., 1428., 2008., 1498., 1420., 1394.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.3436 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.3233120441436768
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.348612774
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:34:37 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 85%   49C    P3              37W / 170W |    695MiB / 12288MiB |      9%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          277MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    162MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.273203717

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:34:47 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2532s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 218., 1088., 1034., 1204., 1562., 1192.,  132., 1950., 1572.,  446.,
          912.,  442.,  198., -262.,   92., 1198., 1132.,  908.,  752.,  318.,
          850.,  226.,  420.,  646.,  314.,    2.,  962.,  638.,  498.,  556.,
           14.,  380.,  618.,  848., -146.,  548.,   -4.,  422.,  382.,  432.,
         1148.,  -84.,  350.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 246., 1156., 1094., 1216., 1690., 1236.,   68., 1666., 1472.,  550.,
           880.,  490.,  130., -274.,   32., 1294., 1172.,  884.,  936.,  318.,
           874.,  278.,  452.,  658.,  406.,    2., 1022.,  706.,  606.,  532.,
            66.,  476.,  522.,  784., -114.,  492., -140.,  506.,  342.,  424.,
          1108.,  -52.,  270.],
         [ 246., 1156., 1094., 1216., 1690., 1236.,   68., 1666., 1472.,  550.,
           880.,  490.,  130., -274.,   32., 1294., 1172.,  884.,  936.,  318.,
           874.,  278.,  452.,  658.,  406.,    2., 1022.,  706.,  606.,  532.,
            66.,  476.,  522.,  784., -114.,  492., -140.,  506.,  342.,  424.,
          1108.,  -52.,  270.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[1420.,  510.,  572.,  450.,  -24.,  430., 1598.,  194., 1116.,  786.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.2930 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.2575464248657227
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.191729982
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:34:54 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 84%   47C    P3              36W / 170W |    747MiB / 12288MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.333869330

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:35:05 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2449s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 218., 1088., 1034., 1204., 1562., 1192.,  132., 1950., 1572.,  446.,
          912.,  442.,  198., -262.,   92., 1198., 1132.,  908.,  752.,  318.,
          850.,  226.,  420.,  646.,  314.,    2.,  962.,  638.,  498.,  556.,
           14.,  380.,  618.,  848., -146.,  548.,   -4.,  422.,  382.,  432.,
         1148.,  -84.,  350.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 398., 1552., 1202., 1500., 1502., 1276.,  344., 1182., 1284.,  610.,
           988.,  618.,  250., -174.,  264., 1306.,  948.,  756.,  560.,  418.,
           886.,  502.,  404.,  694.,  218.,  138.,  890.,  366.,  842.,  652.,
            26.,  420.,  442.,  988.,   54.,  804.,  192.,  158.,  302.,  288.,
           804.,  -32.,  386.],
         [ 398., 1552., 1202., 1500., 1502., 1276.,  344., 1182., 1284.,  610.,
           988.,  618.,  250., -174.,  264., 1306.,  948.,  756.,  560.,  418.,
           886.,  502.,  404.,  694.,  218.,  138.,  890.,  366.,  842.,  652.,
            26.,  420.,  442.,  988.,   54.,  804.,  192.,  158.,  302.,  288.,
           804.,  -32.,  386.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 784., -370.,  -20., -318., -320.,  -94.,  838., -102.,  572.,  194.]]],
       device='cuda:0')
number of violation:  7
Attack finished in 0.2683 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.235903024673462
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.176407707
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:35:12 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 83%   46C    P3              36W / 170W |    747MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.289141848

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:35:22 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2098s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 218., 1088., 1034., 1204., 1562., 1192.,  132., 1950., 1572.,  446.,
          912.,  442.,  198., -262.,   92., 1198., 1132.,  908.,  752.,  318.,
          850.,  226.,  420.,  646.,  314.,    2.,  962.,  638.,  498.,  556.,
           14.,  380.,  618.,  848., -146.,  548.,   -4.,  422.,  382.,  432.,
         1148.,  -84.,  350.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 356., 1622., 1072., 1462., 1660., 1386.,  306.,  608., 1018.,  436.,
           754.,  544.,  260.,   76.,  466., 1356., 1026.,  910.,  582.,  400.,
           892.,  428.,  742.,  476.,  676.,  192.,  908.,  228.,  620.,  718.,
           116.,  682.,  440.,  810.,  336.,  806.,  258.,  236.,  428.,  414.,
           690.,    6.,  -32.],
         [ 356., 1622., 1072., 1462., 1660., 1386.,  306.,  608., 1018.,  436.,
           754.,  544.,  260.,   76.,  466., 1356., 1026.,  910.,  582.,  400.,
           892.,  428.,  742.,  476.,  676.,  192.,  908.,  228.,  620.,  718.,
           116.,  682.,  440.,  810.,  336.,  806.,  258.,  236.,  428.,  414.,
           690.,    6.,  -32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[  252., -1014.,  -464.,  -854., -1052.,  -778.,   302.,  -410.,
            172.,  -146.]]], device='cuda:0')
number of violation:  20
Attack finished in 0.2639 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.2228808403015137
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.104522358
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:35:29 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 83%   45C    P5              36W / 170W |    747MiB / 12288MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.054336656

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:35:39 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2357s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 210., 1092., 1034., 1212., 1554., 1192.,  152., 1946., 1568.,  442.,
          912.,  442.,  210., -262.,   84., 1202., 1132.,  908.,  764.,  314.,
          850.,  214.,  404.,  642.,  322.,   -6.,  946.,  638.,  490.,  548.,
            6.,  384.,  626.,  844., -158.,  560.,    0.,  414.,  382.,  416.,
         1160.,  -68.,  354.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 142.,  924.,  950., 1248., 1562., 1156.,  -52., 1518., 1440.,  454.,
           900.,  450.,  166., -146.,  172., 1286.,  928.,  812.,  812.,  310.,
           866.,  390.,  516.,  686.,  586.,  -10.,  978.,  634.,  650.,  732.,
           262.,  472.,  358.,  780.,   30.,  600., -228.,  634.,  442.,  476.,
          1124., -176.,  326.],
         [ 142.,  924.,  950., 1248., 1562., 1156.,  -52., 1518., 1440.,  454.,
           900.,  450.,  166., -146.,  172., 1286.,  928.,  812.,  812.,  310.,
           866.,  390.,  516.,  686.,  586.,  -10.,  978.,  634.,  650.,  732.,
           262.,  472.,  358.,  780.,   30.,  600., -228.,  634.,  442.,  476.,
          1124., -176.,  326.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[1376.,  594.,  568.,  270.,  -44.,  362., 1570.,   78., 1064.,  618.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0495 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.011390209197998
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.937256524
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:35:46 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 82%   44C    P5              29W / 170W |    747MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.132099877

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:35:57 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2308s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_30_30_QConv_16_3_QConv_32_2_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_30_idx_11985_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
Merging Sign node: %s BoundSign(name=/10, inputs=[/9], perturbed=False)
Merging Sign node: %s BoundSign(name=/14, inputs=[/13], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 130., 1096., 1086., 1284., 1526., 1196.,  180., 1974., 1544.,  486.,
          932.,  470.,  198., -246.,   76., 1230., 1148.,  812.,  704.,  350.,
          858.,  234.,  428.,  702.,  350.,   -2.,  886.,  646.,  498.,  560.,
           54.,  448.,  590.,  860., -166.,  572.,  -20.,  354.,  390.,  360.,
         1124.,  -60.,  398.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   6., 1176., 1290., 1612., 1358., 1328.,  376., 1530., 1192.,  626.,
           924.,  754.,  266., -142.,  580., 1002., 1012.,  492.,  616.,  662.,
          1018.,  150.,  364., 1134.,  782.,  -10.,  794.,  866.,  610.,  672.,
           150.,  536.,  258., 1112.,   58.,  564.,  -32.,  386.,   70.,  436.,
           960.,  -56.,  162.],
         [   6., 1176., 1290., 1612., 1358., 1328.,  376., 1530., 1192.,  626.,
           924.,  754.,  266., -142.,  580., 1002., 1012.,  492.,  616.,  662.,
          1018.,  150.,  364., 1134.,  782.,  -10.,  794.,  866.,  610.,  672.,
           150.,  536.,  258., 1112.,   58.,  564.,  -32.,  386.,   70.,  436.,
           960.,  -56.,  162.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[1524.,  354.,  240.,  -82.,  172.,  202., 1154.,  338.,  904.,  606.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0498 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0110502243041992
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.892468457
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:36:03 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 82%   44C    P5              27W / 170W |    747MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:01<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 13.798728316

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:36:15 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.3283s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  8.,  26.,   0., 162., -20.,  86.,   0.,  -8., -20.,  28.,   6.,  12.,
           8., -22.,   6.,   2.,  22., -26., -36.,   6.,   0., -14.,  10.,  16.,
         -50.,   0., -26., -10.,  22.,   0., -20.,  34.,  16., -20.,   8., -18.,
           0., -40.,   2., -40., -56., -18., -34.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:01<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  6.,  28.,  18., 124., -18., 128.,  -2.,   6., -14.,  10.,  20.,
           18.,  -6., -24.,   4.,  20.,  32., -52., -26.,   8., -26.,  -4.,
            0.,   2., -56., -26., -12., -12.,   0.,  10., -26.,  44.,   2.,
           -2.,  10.,   0., -22., -38.,  -4., -22., -34., -40., -24.],
         [  6.,  28.,  18., 124., -18., 128.,  -2.,   6., -14.,  10.,  20.,
           18.,  -6., -24.,   4.,  20.,  32., -52., -26.,   8., -26.,  -4.,
            0.,   2., -56., -26., -12., -12.,   0.,  10., -26.,  44.,   2.,
           -2.,  10.,   0., -22., -38.,  -4., -22., -34., -40., -24.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[118.,  96., 106., 142.,  -4., 126., 118., 138., 114., 104.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 1.7656 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 2.8030288219451904
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 6.843483486
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:36:24 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 81%   45C    P5              35W / 170W |    747MiB / 12288MiB |     14%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.743010580

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:36:35 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2457s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  0.,  26.,   0., 166., -20.,  82.,   0., -16., -20.,  20.,   2.,  12.,
          12., -22.,   2.,  -2.,  18., -30., -32.,  10.,   4., -10.,  14.,  16.,
         -46.,   0., -26., -10.,  18.,   8., -20.,  42.,  20., -28.,   0., -10.,
           0., -40.,  -6., -40., -60., -18., -34.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  0.,  50.,  28., 114.,   8., 122.,  12.,  -8., -44., -16.,  10.,
           36.,  -8., -42., -10.,  10.,  22., -54., -12.,  10., -20.,   6.,
           -6.,  20., -18., -20., -26.,   6.,   6.,  24., -32.,  42., -16.,
          -16.,  -8., -10.,   0., -56., -26., -48., -36., -38., -10.],
         [  0.,  50.,  28., 114.,   8., 122.,  12.,  -8., -44., -16.,  10.,
           36.,  -8., -42., -10.,  10.,  22., -54., -12.,  10., -20.,   6.,
           -6.,  20., -18., -20., -26.,   6.,   6.,  24., -32.,  42., -16.,
          -16.,  -8., -10.,   0., -56., -26., -48., -36., -38., -10.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[114.,  64.,  86., 106.,  -8., 102., 122., 158., 130., 104.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.5013 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.5206060409545898
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.496070104
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:36:42 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 81%   44C    P3              36W / 170W |    747MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.421390252

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:36:53 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2553s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  6.,  24.,  -2., 164., -22.,  88.,  -2., -14., -18.,  26.,   8.,  14.,
          10., -20.,   4.,   4.,  16., -32., -34.,   8.,   2., -12.,   8.,  14.,
         -44.,  -2., -24.,  -8.,  24.,   2., -18.,  36.,  14., -22.,   2., -12.,
           6., -42.,  -4., -46., -62., -20., -32.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-28.,  14.,   8., 114., -12., 126.,  16.,  32.,  12., -12.,  18.,
            4., -12.,  -6.,  26.,   2.,  30., -34., -52., -22., -24., -14.,
            6., -12., -42.,  -4., -70., -14.,  34.,   0.,  -8.,  30.,   4.,
            4., -12., -10., -16., -64.,  -2., -16., -40., -50.,  -6.],
         [-28.,  14.,   8., 114., -12., 126.,  16.,  32.,  12., -12.,  18.,
            4., -12.,  -6.,  26.,   2.,  30., -34., -52., -22., -24., -14.,
            6., -12., -42.,  -4., -70., -14.,  34.,   0.,  -8.,  30.,   4.,
            4., -12., -10., -16., -64.,  -2., -16., -40., -50.,  -6.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[142., 100., 106., 126., -12.,  98.,  82., 102., 126.,  96.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.3423 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.353865623474121
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.313975353
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:37:00 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 81%   44C    P5              34W / 170W |    747MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      133MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.412864149

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:37:11 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2209s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  6.,  24.,  -2., 168., -18.,  84.,  -6., -14., -18.,  26.,   8.,  18.,
          10., -24.,   4.,   4.,  20., -32., -34.,  12.,   6., -16.,   8.,  18.,
         -40.,   2., -20.,  -8.,  24.,   6., -14.,  40.,  10., -22.,  -2., -12.,
           2., -42.,  -8., -50., -66., -16., -32.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-18.,  64., -62.,  36.,  58.,  52., -14.,  34.,  26., -22., -12.,
          -18.,   6., -32.,  -4.,   0.,   8.,  -8.,  34., -64.,  14.,   8.,
           -8.,   2., -12., -18.,  -8.,   0.,  -8.,  -2., -34.,  24.,   2.,
          -14.,  -2.,  -8., -10., -14.,  -8., -54.,   2., -40.,   4.],
         [-18.,  64., -62.,  36.,  58.,  52., -14.,  34.,  26., -22., -12.,
          -18.,   6., -32.,  -4.,   0.,   8.,  -8.,  34., -64.,  14.,   8.,
           -8.,   2., -12., -18.,  -8.,   0.,  -8.,  -2., -34.,  24.,   2.,
          -14.,  -2.,  -8., -10., -14.,  -8., -54.,   2., -40.,   4.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 54., -28.,  98., -22., -16.,  50.,   2.,  10.,  58.,  48.]]],
       device='cuda:0')
number of violation:  3
Attack finished in 0.3452 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.3684675693511963
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.381576515
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:37:18 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 80%   43C    P3              36W / 170W |    747MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.384522527

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:37:28 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2290s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_7040_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  4.,  22.,   0., 166., -20.,  82.,   0., -12., -20.,  28.,   6.,  12.,
           8., -22.,   6.,   6.,  18., -26., -40.,  14.,   4., -14.,  14.,  20.,
         -42.,   0., -22., -10.,  22.,   8., -20.,  42.,  12., -28.,   4., -18.,
           4., -44.,  -2., -48., -60., -18., -30.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 16.,  18., -12., -22.,  12.,  26.,   4.,   8.,  -4.,   4., -62.,
            8., -24., -18., -26., -22.,  18.,  10.,  -4.,  14.,  24., -26.,
           42.,  88.,  22.,  20., -22.,   6.,  38.,   8.,  -8., -14., -52.,
          -32.,   8., -22., -28.,   0.,  -6., -16.,   0.,  18.,   2.],
         [ 16.,  18., -12., -22.,  12.,  26.,   4.,   8.,  -4.,   4., -62.,
            8., -24., -18., -26., -22.,  18.,  10.,  -4.,  14.,  24., -26.,
           42.,  88.,  22.,  20., -22.,   6.,  38.,   8.,  -8., -14., -52.,
          -32.,   8., -22., -28.,   0.,  -6., -16.,   0.,  18.,   2.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[-38., -40., -10., -34., -48., -26., -30., -18., -26.,  40.]]],
       device='cuda:0')
number of violation:  32
Attack finished in 0.3429 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.3369395732879639
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.240061295
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:37:36 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 80%   43C    P5              34W / 170W |    747MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.709137573

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:37:46 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2213s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -8., -38.,  28., -42.,  12., -26., -16., -24., -12.,   0.,  -6.,  -4.,
           4.,  34., -34.,  14.,  -2., -14., -28.,  10.,  -4.,  -2., -18., -60.,
         -22.,   4.,  22.,  -6., -30., -24., -40., -22.,  32., 120.,  12.,  74.,
          28.,  48., -18.,  72.,  28.,  14., -18.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-16., -38.,  20., -38.,  24., -26., -16., -48., -20., -12., -22.,
           12.,  12.,  22., -26.,  18.,  -2., -18.,   0.,   6., -16.,  -2.,
          -46., -48., -14., -16.,  30.,   2., -18., -20., -36., -34.,  36.,
           92.,  24.,  94.,  16.,  52., -14.,  56.,  28.,  10., -26.],
         [-16., -38.,  20., -38.,  24., -26., -16., -48., -20., -12., -22.,
           12.,  12.,  22., -26.,  18.,  -2., -18.,   0.,   6., -16.,  -2.,
          -46., -48., -14., -16.,  30.,   2., -18., -20., -36., -34.,  36.,
           92.,  24.,  94.,  16.,  52., -14.,  56.,  28.,  10., -26.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[108., 130.,  72., 130.,  68., 118., 108., 140., 112., 104.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.5783 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.5759494304656982
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.494485069
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:37:54 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 80%   43C    P3              37W / 170W |    747MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.490162249

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:38:04 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2361s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -8., -38.,  28., -42.,  12., -26., -16., -24., -12.,   0.,  -6.,  -4.,
           4.,  34., -34.,  14.,  -2., -14., -28.,  10.,  -4.,  -2., -18., -60.,
         -22.,   4.,  22.,  -6., -30., -24., -40., -22.,  32., 120.,  12.,  74.,
          28.,  48., -18.,  72.,  28.,  14., -18.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -4., -18.,  24., -54.,  32., -42., -24., -32.,  -4.,  -8., -22.,
           -8.,   4.,  14., -34.,  18., -10., -10., -12., -14.,  -4.,   6.,
          -34., -60., -10., -20.,  18., -14., -14., -28., -40., -42.,  16.,
           96.,  24., 110.,  32.,  44., -10.,  52.,  44.,   6.,  -6.],
         [ -4., -18.,  24., -54.,  32., -42., -24., -32.,  -4.,  -8., -22.,
           -8.,   4.,  14., -34.,  18., -10., -10., -12., -14.,  -4.,   6.,
          -34., -60., -10., -20.,  18., -14., -14., -28., -40., -42.,  16.,
           96.,  24., 110.,  32.,  44., -10.,  52.,  44.,   6.,  -6.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[100., 114.,  72., 150.,  64., 138., 120., 128., 100., 104.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4391 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.45186185836792
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.393536926
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:38:12 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 80%   43C    P3              36W / 170W |    747MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          267MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     74MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.692362757

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:38:23 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2693s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -8., -38.,  28., -42.,  12., -26., -16., -24., -12.,   0.,  -6.,  -4.,
           4.,  34., -34.,  14.,  -2., -14., -28.,  10.,  -4.,  -2., -18., -60.,
         -22.,   4.,  22.,  -6., -30., -24., -40., -22.,  32., 120.,  12.,  74.,
          28.,  48., -18.,  72.,  28.,  14., -18.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -6., -36.,  30., -56.,   6., -32., -38., -26.,  -2.,   2., -12.,
           10.,   2.,  36., -40.,  12.,   0., -24., -10.,   4., -14.,  12.,
          -44., -54., -20., -22.,  16.,  -8., -16., -30., -34., -28.,  18.,
           94.,  30.,  96.,   6.,  54., -16.,  66.,  50.,   4., -12.],
         [ -6., -36.,  30., -56.,   6., -32., -38., -26.,  -2.,   2., -12.,
           10.,   2.,  36., -40.,  12.,   0., -24., -10.,   4., -14.,  12.,
          -44., -54., -20., -22.,  16.,  -8., -16., -30., -34., -28.,  18.,
           94.,  30.,  96.,   6.,  54., -16.,  66.,  50.,   4., -12.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[100., 130.,  64., 150.,  88., 126., 132., 120.,  96.,  92.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4438 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.4697089195251465
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.459681694
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:38:30 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 80%   43C    P3              36W / 170W |    734MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.474700126

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:38:40 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2301s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -4., -38.,  28., -46.,  20., -22., -16., -24.,  -8.,  -8.,  -6.,   8.,
           4.,  34., -34.,  14.,   2., -22., -16.,  14., -12.,  -2., -22., -56.,
         -22.,   0.,  34.,  -6., -34., -28., -32., -10.,  24., 120.,  12.,  66.,
          12.,  52., -26.,  72.,  20.,   2., -18.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-12., -46.,  40., -34., -12., -10., -20., -52., -12., -20.,  -6.,
            4.,   8.,  22., -30.,  10.,   2., -34., -20.,  14., -32.,   2.,
          -38., -44., -10.,  -8.,   2., -34., -18.,  -4., -12., -14.,  24.,
           84.,  44.,  86.,  28.,  36., -10.,  52.,  28.,  10., -34.],
         [-12., -46.,  40., -34., -12., -10., -20., -52., -12., -20.,  -6.,
            4.,   8.,  22., -30.,  10.,   2., -34., -20.,  14., -32.,   2.,
          -38., -44., -10.,  -8.,   2., -34., -18.,  -4., -12., -14.,  24.,
           84.,  44.,  86.,  28.,  36., -10.,  52.,  28.,  10., -34.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 96., 130.,  44., 118.,  96.,  94., 104., 136.,  96., 104.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4250 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.4341199398040771
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.379194333
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:38:48 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 79%   43C    P3              37W / 170W |    734MiB / 12288MiB |     24%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.354271578

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:38:58 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2373s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_8258_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -6., -36.,  34., -52.,  22., -24., -10., -26.,  -6., -10.,  -8.,   6.,
          10.,  32., -32.,  20.,  -4., -20., -10.,  12., -10.,  -4., -28., -58.,
         -24.,  -2.,  36.,  -4., -32., -30., -34., -16.,  26., 114.,   6.,  64.,
          18.,  54., -20.,  70.,  18.,   4., -16.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-10., -40.,  14., -56., -26., -24., -26., -18.,  -6., -10.,   0.,
            2.,  26.,  24., -60.,   8.,  16., -24., -38.,  28., -46.,  32.,
          -36., -18., -16., -18.,  -4., -20., -28.,   2., -22.,   8.,  -2.,
           74.,  42.,  80.,   6.,  42.,  -8.,  66.,  58., -12., -16.],
         [-10., -40.,  14., -56., -26., -24., -26., -18.,  -6., -10.,   0.,
            2.,  26.,  24., -60.,   8.,  16., -24., -38.,  28., -46.,  32.,
          -36., -18., -16., -18.,  -4., -20., -28.,   2., -22.,   8.,  -2.,
           74.,  42.,  80.,   6.,  42.,  -8.,  66.,  58., -12., -16.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 84., 114.,  60., 130., 100.,  98., 100.,  92.,  80.,  84.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.3473 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.366081953048706
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.277824649
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:39:05 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 79%   42C    P5              34W / 170W |    734MiB / 12288MiB |     11%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.202835699

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:39:16 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2419s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 18.,  12., -66.,  16.,  38.,  16.,  -2.,  62.,  42.,  22.,  -4.,  10.,
          -2., -44.,  -8.,  -4.,  20., -16.,  34., -32.,  22.,  16., -28., -22.,
          32., -50.,  48.,   4.,  20.,  10.,  14.,  -4.,  30.,   2.,  10.,  -8.,
         -14.,   6., -32., -34.,  14., -28.,  36.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 44.,  42., -64.,  10.,  64.,  30.,   0.,  60.,  36.,  -4.,   2.,
            8., -16., -50.,  -6., -10.,  30., -14.,  40., -26.,   0.,  26.,
          -50., -36.,  34., -64.,  46.,  14.,  -2.,   0., -20., -10.,  28.,
           -8.,  -8.,  -6.,   0.,  20., -30., -40.,  24., -38.,  22.],
         [ 44.,  42., -64.,  10.,  64.,  30.,   0.,  60.,  36.,  -4.,   2.,
            8., -16., -50.,  -6., -10.,  30., -14.,  40., -26.,   0.,  26.,
          -50., -36.,  34., -64.,  46.,  14.,  -2.,   0., -20., -10.,  28.,
           -8.,  -8.,  -6.,   0.,  20., -30., -40.,  24., -38.,  22.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 16.,  18., 124.,  50.,  -4.,  30.,  60.,  24.,  64.,  58.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0901 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0875353813171387
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.024501641
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:39:23 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 79%   42C    P5              31W / 170W |    734MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.098496551

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:39:33 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2479s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 18.,  12., -66.,  16.,  38.,  16.,  -2.,  62.,  42.,  22.,  -4.,  10.,
          -2., -44.,  -8.,  -4.,  20., -16.,  34., -32.,  22.,  16., -28., -22.,
          32., -50.,  48.,   4.,  20.,  10.,  14.,  -4.,  30.,   2.,  10.,  -8.,
         -14.,   6., -32., -34.,  14., -28.,  36.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 48.,  46., -60.,  18.,  72.,  46.,  12.,  68.,  40.,  -4., -18.,
           -8., -12., -34.,  -2.,  -2.,  10., -18.,  28., -38.,   0.,  30.,
          -34., -20.,  18., -48.,  18.,  -6.,  -2.,  12., -20.,   2.,  32.,
           -8.,   0., -22.,  -8.,   8., -22., -32.,   4., -46.,  26.],
         [ 48.,  46., -60.,  18.,  72.,  46.,  12.,  68.,  40.,  -4., -18.,
           -8., -12., -34.,  -2.,  -2.,  10., -18.,  28., -38.,   0.,  30.,
          -34., -20.,  18., -48.,  18.,  -6.,  -2.,  12., -20.,   2.,  32.,
           -8.,   0., -22.,  -8.,   8., -22., -32.,   4., -46.,  26.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 20.,  22., 128.,  50.,  -4.,  22.,  56.,  28.,  72.,  86.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.0879 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.1022400856018066
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.003363247
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:39:40 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 79%   42C    P5              33W / 170W |    734MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    224MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.149000075

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:39:50 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2905s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 18.,  12., -66.,  16.,  38.,  16.,  -2.,  62.,  42.,  22.,  -4.,  10.,
          -2., -44.,  -8.,  -4.,  20., -16.,  34., -32.,  22.,  16., -28., -22.,
          32., -50.,  48.,   4.,  20.,  10.,  14.,  -4.,  30.,   2.,  10.,  -8.,
         -14.,   6., -32., -34.,  14., -28.,  36.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 34.,  48., -46., -12.,  50.,  24.,  -2.,  42.,  34.,   2.,   0.,
            2., -10., -76., -16., -16.,  44.,   4.,  10., -20.,  38.,  28.,
          -44., -14.,  36., -50.,  36.,   8.,   4.,  18.,  -6.,   8.,  -2.,
            2., -10., -12.,  -6.,  10., -52., -42.,  38., -28.,  36.],
         [ 34.,  48., -46., -12.,  50.,  24.,  -2.,  42.,  34.,   2.,   0.,
            2., -10., -76., -16., -16.,  44.,   4.,  10., -20.,  38.,  28.,
          -44., -14.,  36., -50.,  36.,   8.,   4.,  18.,  -6.,   8.,  -2.,
            2., -10., -12.,  -6.,  10., -52., -42.,  38., -28.,  36.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 8., -6., 88., 54., -8., 18., 44.,  8., 40., 42.]]], device='cuda:0')
number of violation:  3
Attack finished in 0.1121 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.1808335781097412
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.243678828
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:39:57 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 79%   42C    P3              37W / 170W |    785MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    275MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.358185699

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:40:08 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2108s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 30.,  36., -54.,  12.,  46.,  24.,  -2.,  70.,  46.,  18.,  -4.,   6.,
          -2., -48.,  -4.,  -8.,  32., -24.,  38., -36.,  18.,  24., -32., -26.,
          16., -54.,  40.,   0.,  12.,   2.,  10.,   0.,  22.,  -6.,  -2., -28.,
         -18.,   6., -28., -30.,  14., -36.,  20.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 30.,  72., -22.,   8.,  66.,  60., -18.,  54.,  38., -30.,   8.,
            6., -22., -32., -20., -28.,   4., -24.,  34.,  -8.,  -6.,  44.,
          -44., -34.,  28., -50.,  32.,  20.,   0.,  26., -26.,   0.,  10.,
           -2., -14., -20., -22.,  10., -44., -22.,  22., -60.,  44.],
         [ 30.,  72., -22.,   8.,  66.,  60., -18.,  54.,  38., -30.,   8.,
            6., -22., -32., -20., -28.,   4., -24.,  34.,  -8.,  -6.,  44.,
          -44., -34.,  28., -50.,  32.,  20.,   0.,  26., -26.,   0.,  10.,
           -2., -14., -20., -22.,  10., -44., -22.,  22., -60.,  44.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 24., -18.,  76.,  46., -12.,  -6.,  72.,  16.,  84.,  46.]]],
       device='cuda:0')
number of violation:  3
Attack finished in 0.0889 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.084686517715454
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.969044563
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:40:15 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   42C    P5              33W / 170W |    766MiB / 12288MiB |     73%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    256MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.293694365

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:40:25 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2128s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_48_48_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_BN_Dense_256_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_48_idx_11985_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/38, inputs=[/37], perturbed=False)
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/48, inputs=[/47], perturbed=False)
Merging Sign node: %s BoundSign(name=/63, inputs=[/62], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 28.,  22., -60.,  -2.,  32.,  26.,  -8.,  56.,  52.,  24.,   2.,  -8.,
          -4., -46., -22.,  -6.,  34., -14.,  40., -14.,  16.,  18., -26., -12.,
          22., -68.,  34.,  14.,   6.,  12.,  20.,  -2.,  12.,  -4.,  12.,  -6.,
         -16.,   8., -34., -40.,  36., -34.,  30.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 46.,  40., -62.,   4.,  62.,  16.,  -2.,  42.,  42.,  14.,   4.,
           -2., -14., -28., -20., -16.,  32.,   0.,  10., -16.,  42.,  32.,
          -40., -14.,  36., -38.,  32.,   4.,  -4.,  14.,  -2.,  20.,   6.,
           -6., -10., -20., -22.,  14., -28., -42.,  -6., -32.,  28.],
         [ 46.,  40., -62.,   4.,  62.,  16.,  -2.,  42.,  42.,  14.,   4.,
           -2., -14., -28., -20., -16.,  32.,   0.,  10., -16.,  42.,  32.,
          -40., -14.,  36., -38.,  32.,   4.,  -4.,  14.,  -2.,  20.,   6.,
           -6., -10., -20., -22.,  14., -28., -42.,  -6., -32.,  28.]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ -4.,   2., 104.,  38., -20.,  26.,  44.,   0.,  28.,  38.]]],
       device='cuda:0')
number of violation:  2
Attack finished in 0.0877 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.0825169086456299
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 4.948770632
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:40:32 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   41C    P5              34W / 170W |    813MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    303MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.953867499

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:40:43 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2304s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  10.,   92.,  234.,  416.,  -12.,  222.,   88., -176., -148.,   42.,
         -106., -104.,  -72., -108.,   -4.,   34.,   46., -106.,  -12.,  -76.,
          -52.,  -60.,    6.,  -44., -104.,   18.,  -96.,  -58., -100.,   22.,
          -68.,   76.,   88.,  -22.,  -18.,    2.,  -22.,  -70.,    2.,   20.,
         -148.,  -46.,  -62.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  16.,   86.,  148.,  362.,   42.,  364.,  122., -158., -154.,  -28.,
           -80.,  -50.,  -86., -130.,  -18.,   20.,   32., -152.,   22.,  -42.,
           -46.,  -38.,   -8.,   10.,  -66.,    8.,  -62.,    0.,  -98.,   -8.,
           -50.,   90.,   46.,    0., -100.,    0.,  -32.,  -24.,  -36.,   42.,
          -110., -112.,  -52.],
         [  16.,   86.,  148.,  362.,   42.,  364.,  122., -158., -154.,  -28.,
           -80.,  -50.,  -86., -130.,  -18.,   20.,   32., -152.,   22.,  -42.,
           -46.,  -38.,   -8.,   10.,  -66.,    8.,  -62.,    0.,  -98.,   -8.,
           -50.,   90.,   46.,    0., -100.,    0.,  -32.,  -24.,  -36.,   42.,
          -110., -112.,  -52.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[346., 276., 214., 320.,  -2., 240., 520., 516., 390., 442.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.8037 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.9521026611328125
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.876804245
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:40:51 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   43C    P3              37W / 170W |    813MiB / 12288MiB |     13%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    303MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.662618880

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:41:02 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2197s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  18.,  100.,  234.,  420.,   -8.,  218.,   92., -164., -132.,   38.,
         -110.,  -96.,  -84., -112.,  -20.,   34.,   50., -102.,  -12.,  -80.,
          -56.,  -60.,    6.,  -48., -104.,    2., -100.,  -62.,  -92.,   18.,
          -72.,   64.,   84.,  -26.,  -22.,   -2.,  -10.,  -70.,  -14.,   36.,
         -148.,  -34.,  -66.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  38.,  112.,  154.,  348.,   20.,  358.,  140., -104., -176.,   54.,
           -42., -112.,  -76., -108.,  -64.,  -22.,   82., -130., -104.,  -60.,
           -56.,   12.,   30.,   44.,  -24.,  -10., -112.,  -54.,  -96.,   -6.,
           -24.,   32.,    8.,  -10.,  -66.,   -6.,   66.,  -70.,  -10.,   20.,
           -52.,  -82.,  -26.],
         [  38.,  112.,  154.,  348.,   20.,  358.,  140., -104., -176.,   54.,
           -42., -112.,  -76., -108.,  -64.,  -22.,   82., -130., -104.,  -60.,
           -56.,   12.,   30.,   44.,  -24.,  -10., -112.,  -54.,  -96.,   -6.,
           -24.,   32.,    8.,  -10.,  -66.,   -6.,   66.,  -70.,  -10.,   20.,
           -52.,  -82.,  -26.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[310., 236., 194., 328., -10., 208., 452., 524., 294., 390.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4897 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6978764533996582
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.656272048
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:41:09 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   42C    P3              36W / 170W |    793MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    283MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.769004359

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:41:20 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2939s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  18.,   92.,  238.,  416.,   -8.,  218.,   96., -184., -136.,   42.,
         -110., -108.,  -84., -104.,   -8.,   30.,   66.,  -98.,   -8.,  -64.,
          -56.,  -64.,   18.,  -48., -112.,    6., -104.,  -54.,  -92.,   14.,
          -76.,   64.,   88.,  -14.,  -34.,  -10.,  -14.,  -74.,  -14.,   40.,
         -144.,  -46.,  -78.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  60.,  138.,   36.,  170.,   62.,  292.,  118.,    2., -122.,   -8.,
           -32.,  -46., -114., -134.,  -46.,   44.,   48., -152.,  -46., -118.,
            10.,    6.,  -40.,  -38.,  -14.,  -44.,  -46.,   36.,  -46.,  -44.,
           -78.,  -18.,   70.,  -12.,  -88.,  -52.,   32.,  -20.,  -28.,   58.,
            -6.,  -80.,   48.],
         [  60.,  138.,   36.,  170.,   62.,  292.,  118.,    2., -122.,   -8.,
           -32.,  -46., -114., -134.,  -46.,   44.,   48., -152.,  -46., -118.,
            10.,    6.,  -40.,  -38.,  -14.,  -44.,  -46.,   36.,  -46.,  -44.,
           -78.,  -18.,   70.,  -12.,  -88.,  -52.,   32.,  -20.,  -28.,   58.,
            -6.,  -80.,   48.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 110.,   32.,  134.,  108., -122.,   52.,  168.,  292.,  178.,  202.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.5019 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6862196922302246
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.729463842
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:41:28 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   42C    P3              38W / 170W |    809MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     64MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    299MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.765457057

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:41:38 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2657s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  24.,   94.,  236.,  418.,    2.,  220.,   82., -166., -162.,   64.,
         -100.,  -94.,  -62., -110.,    6.,   24.,   40., -116.,  -22.,  -74.,
          -66.,  -58.,    4.,  -74.,  -90.,   12., -106.,  -68., -118.,   20.,
          -74.,   66.,   78.,  -16.,  -16.,    8.,    0.,  -80.,    0.,   34.,
         -154.,  -36.,  -60.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -70.,  -40.,  194.,   76.,   40.,  206.,  100.,  104.,  -16.,   -6.,
           -34., -116.,  -84.,  -12.,    4.,   14.,  -46.,  -66., -160.,  -40.,
           -56.,  -16.,   18.,  100.,   36.,  -46.,  -88.,   42.,  -32.,   78.,
           -32.,   12.,  -36.,  -10.,   38.,  -70.,  -62.,  -54.,   30.,  -16.,
            16.,  -86.,  -18.],
         [ -70.,  -40.,  194.,   76.,   40.,  206.,  100.,  104.,  -16.,   -6.,
           -34., -116.,  -84.,  -12.,    4.,   14.,  -46.,  -66., -160.,  -40.,
           -56.,  -16.,   18.,  100.,   36.,  -46.,  -88.,   42.,  -32.,   78.,
           -32.,   12.,  -36.,  -10.,   38.,  -70.,  -62.,  -54.,   30.,  -16.,
            16.,  -86.,  -18.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 146.,  116., -118.,   36., -130.,  -24.,  -28.,   92.,   82.,  110.]]],
       device='cuda:0')
number of violation:  6
Attack finished in 0.5147 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6601476669311523
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.627029867
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:41:46 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   42C    P3              36W / 170W |    811MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     65MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    299MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.442999754

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:41:57 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2859s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_7040_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  12.,  102.,  216.,  438.,  -14.,  216.,   90., -166., -126.,   52.,
          -92.,  -98.,  -66., -106.,   -2.,   44.,   52., -112.,  -34.,  -78.,
          -58.,  -46.,   32.,  -38., -122.,   12., -126.,  -68.,  -86.,   28.,
          -50.,   74.,  102.,  -36.,  -28.,    0.,   -8.,  -92.,    0.,   42.,
         -146.,  -20.,  -52.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   6.,   72.,  178.,  316.,   20.,  366.,  136., -120., -116.,   26.,
            -2., -120.,  -76., -100.,  -64.,   18.,   58., -150., -148.,  -76.,
           -20.,  -12.,   -6.,   56.,  -16.,  -22., -132.,  -26.,  -80.,   14.,
           -40.,   28.,   56.,  -26., -110.,   -2.,   50.,  -78.,   30.,   -4.,
          -104.,  -62.,  -26.],
         [   6.,   72.,  178.,  316.,   20.,  366.,  136., -120., -116.,   26.,
            -2., -120.,  -76., -100.,  -64.,   18.,   58., -150., -148.,  -76.,
           -20.,  -12.,   -6.,   56.,  -16.,  -22., -132.,  -26.,  -80.,   14.,
           -40.,   28.,   56.,  -26., -110.,   -2.,   50.,  -78.,   30.,   -4.,
          -104.,  -62.,  -26.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[310., 244., 138., 296., -50., 180., 436., 432., 290., 318.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.2062 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.4691905975341797
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.483891555
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 14:42:04 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 78%   42C    P3              38W / 170W |    787MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          265MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     65MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    275MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       34MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      133MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
100%|| 1/1 [00:16<00:00, 16.16s/it]
100%|| 1/1 [00:16<00:00, 16.67s/it]
  0%|                                                     | 0/1 [00:00<?, ?it/s]Preparation finished.
prepare_instance.sh exit code: 0, runtime: 52.145502400

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:42:54 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2848s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.45s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-136., -142.,   32.,  -38.,   94.,  -80.,  -94.,  -62., -226.,  -40.,
            44.,  -42.,   50.,  170.,   22.,  -68.,  -36., -104.,    2.,   66.,
           -54.,   54.,    8.,  -78.,   82.,  336.,   78.,   44.,  -14., -128.,
           -30.,  -58.,   14.,  356.,   -4.,  136.,  104.,   28.,  -84.,  174.,
           -54.,  -16.,  -32.],
         [-136., -142.,   32.,  -38.,   94.,  -80.,  -94.,  -62., -226.,  -40.,
            44.,  -42.,   50.,  170.,   22.,  -68.,  -36., -104.,    2.,   66.,
           -54.,   54.,    8.,  -78.,   82.,  336.,   78.,   44.,  -14., -128.,
           -30.,  -58.,   14.,  356.,   -4.,  136.,  104.,   28.,  -84.,  174.,
           -54.,  -16.,  -32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[492., 498., 324., 394., 262., 436., 450., 418., 582., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.4646 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.42s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-106., -128.,   42.,   12.,   80.,  -42., -108., -116., -140.,  -58.,
            42.,  -52.,   68.,   96.,   24.,  -22.,    6.,  -82.,   16.,   24.,
           -48.,  -24.,  -54., -124.,   84.,  150.,  112.,   26.,   -4.,  -70.,
           -68.,  -84.,   44.,  406.,   38.,  210.,   82.,   66.,  -62.,  144.,
           -20.,  -74.,  -58.],
         [-106., -128.,   42.,   12.,   80.,  -42., -108., -116., -140.,  -58.,
            42.,  -52.,   68.,   96.,   24.,  -22.,    6.,  -82.,   16.,   24.,
           -48.,  -24.,  -54., -124.,   84.,  150.,  112.,   26.,   -4.,  -70.,
           -68.,  -84.,   44.,  406.,   38.,  210.,   82.,   66.,  -62.,  144.,
           -20.,  -74.,  -58.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[512., 534., 364., 394., 326., 448., 514., 522., 546., 464.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.4305 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.81s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-138., -160.,   22.,  -28.,   64.,  -78., -112.,  -84., -180.,  -62.,
            30.,  -12.,   52.,  148.,   24.,  -58.,  -38.,  -90.,    0.,   36.,
           -72.,   12.,  -18.,  -76.,   80.,  334.,  108.,   42.,  -12.,  -94.,
            -8.,  -88.,    4.,  346.,   22.,  174.,  130.,   50.,  -50.,  148.,
           -52.,  -26.,  -66.],
         [-138., -160.,   22.,  -28.,   64.,  -78., -112.,  -84., -180.,  -62.,
            30.,  -12.,   52.,  148.,   24.,  -58.,  -38.,  -90.,    0.,   36.,
           -72.,   12.,  -18.,  -76.,   80.,  334.,  108.,   42.,  -12.,  -94.,
            -8.,  -88.,    4.,  346.,   22.,  174.,  130.,   50.,  -50.,  148.,
           -52.,  -26.,  -66.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[484., 506., 324., 374., 282., 424., 458., 430., 526., 408.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.8210 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.92s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -86., -136.,   14.,   20.,   72.,  -22., -104., -104., -136.,  -30.,
            50.,  -52.,  100.,   76.,   32.,  -14.,   14.,  -78.,    8.,    0.,
           -16.,  -20.,  -54., -120.,   80.,  150.,  112.,   22.,   -8.,  -58.,
           -60., -120.,   60.,  418.,   14.,  222.,   94.,   62.,  -82.,  140.,
           -24.,  -58.,  -62.],
         [ -86., -136.,   14.,   20.,   72.,  -22., -104., -104., -136.,  -30.,
            50.,  -52.,  100.,   76.,   32.,  -14.,   14.,  -78.,    8.,    0.,
           -16.,  -20.,  -54., -120.,   80.,  150.,  112.,   22.,   -8.,  -58.,
           -60., -120.,   60.,  418.,   14.,  222.,   94.,   62.,  -82.,  140.,
           -24.,  -58.,  -62.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[504., 554., 404., 398., 346., 440., 522., 522., 554., 448.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.9256 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.94s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104., -154.,   52.,  -54.,  102.,  -52.,  -90., -110., -174.,  -40.,
            32.,  -22.,   38.,  162.,   34.,  -64.,  -40.,  -92.,   14.,   70.,
           -70.,   26.,   -8.,  -82.,   50.,  332.,  102.,   80.,  -10., -104.,
           -26.,  -46.,   14.,  356.,  -12.,  152.,  104.,   56.,  -72.,  158.,
           -54.,  -56.,  -72.],
         [-104., -154.,   52.,  -54.,  102.,  -52.,  -90., -110., -174.,  -40.,
            32.,  -22.,   38.,  162.,   34.,  -64.,  -40.,  -92.,   14.,   70.,
           -70.,   26.,   -8.,  -82.,   50.,  332.,  102.,   80.,  -10., -104.,
           -26.,  -46.,   14.,  356.,  -12.,  152.,  104.,   56.,  -72.,  158.,
           -54.,  -56.,  -72.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[460., 510., 304., 410., 254., 408., 446., 466., 530., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.9448 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.45s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -82., -100.,   54.,   16.,   60.,  -18., -116., -108., -124.,  -26.,
            34.,  -24.,  100.,   76.,   44.,    2.,   66.,  -70.,   12.,    8.,
           -40.,  -16.,  -82., -144.,   36.,  138.,   64.,    6.,  -40.,  -74.,
           -64., -116.,   40.,  418.,   18.,  234.,   82.,   42.,  -78.,  160.,
           -12.,  -66.,  -78.],
         [ -82., -100.,   54.,   16.,   60.,  -18., -116., -108., -124.,  -26.,
            34.,  -24.,  100.,   76.,   44.,    2.,   66.,  -70.,   12.,    8.,
           -40.,  -16.,  -82., -144.,   36.,  138.,   64.,    6.,  -40.,  -74.,
           -64., -116.,   40.,  418.,   18.,  234.,   82.,   42.,  -78.,  160.,
           -12.,  -66.,  -78.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[500., 518., 364., 402., 358., 436., 534., 526., 542., 444.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.4592 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.75s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-130., -128.,   74.,  -40.,   84.,  -50., -108.,  -92., -200.,  -54.,
            18.,  -28.,   40.,  164.,   24.,  -74.,  -46.,  -90.,   -4.,   60.,
           -80.,   32.,    6.,  -64.,   52.,  318.,   96.,   66.,   -4., -142.,
           -28.,  -52.,   32.,  338.,  -18.,  150.,   90.,   42.,  -42.,  164.,
           -60.,  -42.,  -58.],
         [-130., -128.,   74.,  -40.,   84.,  -50., -108.,  -92., -200.,  -54.,
            18.,  -28.,   40.,  164.,   24.,  -74.,  -46.,  -90.,   -4.,   60.,
           -80.,   32.,    6.,  -64.,   52.,  318.,   96.,   66.,   -4., -142.,
           -28.,  -52.,   32.,  338.,  -18.,  150.,   90.,   42.,  -42.,  164.,
           -60.,  -42.,  -58.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[468., 466., 264., 378., 254., 388., 446., 430., 538., 392.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.7561 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.60s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -108.,   50.,   16.,   60.,  -26.,  -92., -112., -124.,  -30.,
             6.,  -24.,   56.,   88.,   28.,  -10.,   22.,  -78.,   20.,    8.,
           -56.,  -44.,  -70., -132.,   52.,  154.,   84.,   26.,  -32.,  -66.,
          -108., -112.,   44.,  402.,   26.,  218.,   94.,   54.,  -54.,  168.,
            -8.,  -58.,  -70.],
         [-114., -108.,   50.,   16.,   60.,  -26.,  -92., -112., -124.,  -30.,
             6.,  -24.,   56.,   88.,   28.,  -10.,   22.,  -78.,   20.,    8.,
           -56.,  -44.,  -70., -132.,   52.,  154.,   84.,   26.,  -32.,  -66.,
          -108., -112.,   44.,  402.,   26.,  218.,   94.,   54.,  -54.,  168.,
            -8.,  -58.,  -70.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[516., 510., 352., 386., 342., 428., 494., 514., 526., 432.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.6131 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.52s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-134., -112.,   86.,  -52.,   84.,  -70., -100.,  -92., -204.,  -70.,
             2.,  -28.,   52.,  144.,   16.,  -82.,  -30.,  -78.,    0.,   32.,
          -100.,   40.,  -14.,  -64.,   96.,  330.,   76.,   78.,   -8., -106.,
           -32.,  -84.,   28.,  346.,   14.,  146.,  118.,   58.,  -34.,  116.,
             0.,  -18.,  -38.],
         [-134., -112.,   86.,  -52.,   84.,  -70., -100.,  -92., -204.,  -70.,
             2.,  -28.,   52.,  144.,   16.,  -82.,  -30.,  -78.,    0.,   32.,
          -100.,   40.,  -14.,  -64.,   96.,  330.,   76.,   78.,   -8., -106.,
           -32.,  -84.,   28.,  346.,   14.,  146.,  118.,   58.,  -34.,  116.,
             0.,  -18.,  -38.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[480., 458., 260., 398., 262., 416., 446., 438., 550., 416.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.5314 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.95s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-106., -160.,   22.,   32.,   76.,  -26., -112.,  -92., -112.,  -26.,
            22.,  -44.,   60.,  108.,   20.,  -34.,    6.,  -98.,   36.,    0.,
           -24.,  -28.,  -50., -124.,   84.,  162.,  112.,    6.,  -24.,  -34.,
           -72., -120.,   36.,  402.,   42.,  210.,  102.,   70.,  -54.,  144.,
            -4.,  -74.,  -86.],
         [-106., -160.,   22.,   32.,   76.,  -26., -112.,  -92., -112.,  -26.,
            22.,  -44.,   60.,  108.,   20.,  -34.,    6.,  -98.,   36.,    0.,
           -24.,  -28.,  -50., -124.,   84.,  162.,  112.,    6.,  -24.,  -34.,
           -72., -120.,   36.,  402.,   42.,  210.,  102.,   70.,  -54.,  144.,
            -4.,  -74.,  -86.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[508., 562., 380., 370., 326., 428., 514., 494., 514., 428.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.9623 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:17<00:00, 17.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104., -126.,   60.,  -38.,  110.,  -84., -102.,  -90., -158.,  -40.,
            12.,  -22.,   30.,  170.,   14.,  -44.,  -12., -112.,   -6.,   50.,
           -78.,    2.,   -4.,  -86.,   58.,  324.,  118.,   44.,  -10., -104.,
            -6.,  -98.,   22.,  344.,    0.,  176.,  108.,   28.,  -56.,  150.,
           -46.,  -44.,  -80.],
         [-104., -126.,   60.,  -38.,  110.,  -84., -102.,  -90., -158.,  -40.,
            12.,  -22.,   30.,  170.,   14.,  -44.,  -12., -112.,   -6.,   50.,
           -78.,    2.,   -4.,  -86.,   58.,  324.,  118.,   44.,  -10., -104.,
            -6.,  -98.,   22.,  344.,    0.,  176.,  108.,   28.,  -56.,  150.,
           -46.,  -44.,  -80.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[448., 470., 284., 382., 234., 428., 446., 434., 502., 384.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 17.1179 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:17<00:00, 17.11s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-124., -142.,   40.,   14.,   78.,  -28.,  -94.,  -78., -110.,  -24.,
            32.,  -18.,   98.,   86.,   62.,  -12.,   24.,  -68.,   10.,    2.,
           -38.,  -38.,  -80., -134.,   46.,  124.,  126.,    4.,  -54.,  -56.,
           -70., -106.,   22.,  424.,   36.,  220.,   72.,   68.,  -88.,  146.,
            -2.,  -68.,  -84.],
         [-124., -142.,   40.,   14.,   78.,  -28.,  -94.,  -78., -110.,  -24.,
            32.,  -18.,   98.,   86.,   62.,  -12.,   24.,  -68.,   10.,    2.,
           -38.,  -38.,  -80., -134.,   46.,  124.,  126.,    4.,  -54.,  -56.,
           -70., -106.,   22.,  424.,   36.,  220.,   72.,   68.,  -88.,  146.,
            -2.,  -68.,  -84.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[548., 566., 384., 410., 346., 452., 518., 502., 534., 448.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 17.1242 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.14s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-142., -144.,   34.,  -44.,  112.,  -54.,  -92.,  -84., -192.,  -38.,
            14.,  -12.,   48.,  132.,   36.,  -70.,  -38.,  -78.,   24.,   56.,
           -60.,   20.,  -18.,  -80.,   76.,  318.,  108.,   54.,  -16., -118.,
           -28.,  -88.,   28.,  338.,  -14.,  150.,  106.,   42.,  -46.,  144.,
           -40.,  -54.,  -46.],
         [-142., -144.,   34.,  -44.,  112.,  -54.,  -92.,  -84., -192.,  -38.,
            14.,  -12.,   48.,  132.,   36.,  -70.,  -38.,  -78.,   24.,   56.,
           -60.,   20.,  -18.,  -80.,   76.,  318.,  108.,   54.,  -16., -118.,
           -28.,  -88.,   28.,  338.,  -14.,  150.,  106.,   42.,  -46.,  144.,
           -40.,  -54.,  -46.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[480., 482., 304., 382., 226., 392., 430., 422., 530., 376.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.1529 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.47s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-138., -152.,   50.,   32.,   96.,    2., -104., -100., -124.,  -26.,
            34.,  -52.,   88.,   76.,   36.,  -26.,  -10.,  -70.,    8.,    4.,
           -28.,  -20.,  -58., -140.,   52.,  158.,  120.,   26.,  -56.,  -66.,
           -88., -120.,   36.,  414.,   42.,  222.,  102.,   50.,  -66.,  144.,
           -32.,  -62.,  -82.],
         [-138., -152.,   50.,   32.,   96.,    2., -104., -100., -124.,  -26.,
            34.,  -52.,   88.,   76.,   36.,  -26.,  -10.,  -70.,    8.,    4.,
           -28.,  -20.,  -58., -140.,   52.,  158.,  120.,   26.,  -56.,  -66.,
           -88., -120.,   36.,  414.,   42.,  222.,  102.,   50.,  -66.,  144.,
           -32.,  -62.,  -82.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[552., 566., 364., 382., 318., 412., 518., 514., 538., 440.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.4796 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.20s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-128., -134.,   56.,    2.,   78.,  -52., -130.,  -90., -174.,  -48.,
             8.,  -30.,   42.,  146.,   18.,  -44.,  -52.,  -72.,    6.,   46.,
           -66.,   26.,  -12.,  -66.,   58.,  344.,   94.,   36.,   14., -100.,
           -26.,  -50.,   22.,  348.,   -8.,  164.,  112.,    4.,  -40.,  142.,
           -66.,  -40.,  -64.],
         [-128., -134.,   56.,    2.,   78.,  -52., -130.,  -90., -174.,  -48.,
             8.,  -30.,   42.,  146.,   18.,  -44.,  -52.,  -72.,    6.,   46.,
           -66.,   26.,  -12.,  -66.,   58.,  344.,   94.,   36.,   14., -100.,
           -26.,  -50.,   22.,  348.,   -8.,  164.,  112.,    4.,  -40.,  142.,
           -66.,  -40.,  -64.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[476., 482., 292., 346., 270., 400., 478., 438., 522., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.2072 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.73s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-108., -114.,   40.,   26.,   54.,   -8.,  -98., -130., -154.,  -48.,
            40.,  -54.,   66.,   74.,   18.,  -36.,   12.,  -64.,   10.,   26.,
           -22.,  -22.,  -52., -126.,   90.,  152.,  106.,   36.,  -14.,  -72.,
           -90.,  -90.,   58.,  412.,    8.,  220.,   96.,   76.,  -76.,  150.,
           -30.,  -68.,  -64.],
         [-108., -114.,   40.,   26.,   54.,   -8.,  -98., -130., -154.,  -48.,
            40.,  -54.,   66.,   74.,   18.,  -36.,   12.,  -64.,   10.,   26.,
           -22.,  -22.,  -52., -126.,   90.,  152.,  106.,   36.,  -14.,  -72.,
           -90.,  -90.,   58.,  412.,    8.,  220.,   96.,   76.,  -76.,  150.,
           -30.,  -68.,  -64.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[520., 526., 372., 386., 358., 420., 510., 542., 566., 460.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.7407 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:16<00:00, 16.27s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104.,  -94.,   40.,  -22.,   58.,  -64.,  -62., -110., -226.,  -64.,
            20.,  -14.,   30.,  154.,   -2., -108.,  -16.,  -80.,   22.,   58.,
           -90.,   22.,  -32.,  -62.,   70.,  348.,  106.,   68.,  -22., -104.,
           -54.,  -58.,    6.,  356.,   -4.,  144.,  120.,   44.,  -40.,  122.,
           -34.,  -24.,  -52.],
         [-104.,  -94.,   40.,  -22.,   58.,  -64.,  -62., -110., -226.,  -64.,
            20.,  -14.,   30.,  154.,   -2., -108.,  -16.,  -80.,   22.,   58.,
           -90.,   22.,  -32.,  -62.,   70.,  348.,  106.,   68.,  -22., -104.,
           -54.,  -58.,    6.,  356.,   -4.,  144.,  120.,   44.,  -40.,  122.,
           -34.,  -24.,  -52.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[460., 450., 316., 378., 298., 420., 418., 466., 582., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 16.2759 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -116.,   62.,   12.,   88.,  -14., -104.,  -84., -116.,  -34.,
            18.,  -32.,   76.,   96.,   32.,  -14.,   26.,  -78.,    0.,   12.,
           -60.,  -16.,  -74., -136.,   84.,  138.,  112.,   26.,  -44.,  -66.,
           -88., -104.,   20.,  418.,    6.,  222.,   90.,   66.,  -62.,  156.,
            -8.,  -78.,  -78.],
         [-114., -116.,   62.,   12.,   88.,  -14., -104.,  -84., -116.,  -34.,
            18.,  -32.,   76.,   96.,   32.,  -14.,   26.,  -78.,    0.,   12.,
           -60.,  -16.,  -74., -136.,   84.,  138.,  112.,   26.,  -44.,  -66.,
           -88., -104.,   20.,  418.,    6.,  222.,   90.,   66.,  -62.,  156.,
            -8.,  -78.,  -78.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[532., 534., 356., 406., 330., 432., 522., 502., 534., 452.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7065 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -152.,   54.,  -20.,   84.,  -38.,  -88., -116., -188.,  -50.,
            14.,    4.,   48.,  144.,   36.,  -62.,  -22., -110.,   20.,   48.,
           -80.,   12.,  -14., -104.,   60.,  318.,  100.,   58.,    8., -118.,
           -40.,  -72.,   36.,  338.,    2.,  146.,  138.,   22.,  -54.,  144.,
           -68.,  -70.,  -54.],
         [-114., -152.,   54.,  -20.,   84.,  -38.,  -88., -116., -188.,  -50.,
            14.,    4.,   48.,  144.,   36.,  -62.,  -22., -110.,   20.,   48.,
           -80.,   12.,  -14., -104.,   60.,  318.,  100.,   58.,    8., -118.,
           -40.,  -72.,   36.,  338.,    2.,  146.,  138.,   22.,  -54.,  144.,
           -68.,  -70.,  -54.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[452., 490., 284., 358., 254., 376., 426., 454., 526., 388.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6468 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-112., -142.,   52.,   10.,   74.,  -40.,  -98., -118., -126.,  -24.,
            32.,  -38.,   62.,   74.,   38.,  -24.,    8.,  -72.,   26.,    6.,
           -50.,  -30.,  -64., -138.,   66.,  148.,   66.,   28.,  -46.,  -48.,
           -70.,  -86.,   42.,  396.,   20.,  208.,  108.,   52.,  -40.,  174.,
            -2.,  -48.,  -76.],
         [-112., -142.,   52.,   10.,   74.,  -40.,  -98., -118., -126.,  -24.,
            32.,  -38.,   62.,   74.,   38.,  -24.,    8.,  -72.,   26.,    6.,
           -50.,  -30.,  -64., -138.,   66.,  148.,   66.,   28.,  -46.,  -48.,
           -70.,  -86.,   42.,  396.,   20.,  208.,  108.,   52.,  -40.,  174.,
            -2.,  -48.,  -76.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[508., 538., 344., 386., 322., 436., 494., 514., 522., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7098 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-122., -144.,   90.,  -24.,   88.,  -58.,  -92., -120., -188.,  -66.,
            14.,  -28.,   60.,  136.,   16.,  -66.,  -38.,  -94.,   16.,   48.,
           -60.,  -12.,   -2.,  -80.,   72.,  302.,   72.,   42.,  -16., -118.,
           -28.,  -96.,   60.,  326.,   10.,  154.,  110.,   42.,  -26.,  168.,
           -44.,  -46.,  -42.],
         [-122., -144.,   90.,  -24.,   88.,  -58.,  -92., -120., -188.,  -66.,
            14.,  -28.,   60.,  136.,   16.,  -66.,  -38.,  -94.,   16.,   48.,
           -60.,  -12.,   -2.,  -80.,   72.,  302.,   72.,   42.,  -16., -118.,
           -28.,  -96.,   60.,  326.,   10.,  154.,  110.,   42.,  -26.,  168.,
           -44.,  -46.,  -42.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[448., 470., 236., 350., 238., 384., 418., 446., 514., 392.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6432 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-116., -154.,   20.,   14.,   86.,  -52., -118., -102., -134.,   -8.,
            32.,  -54.,   86.,   94.,   26.,  -32.,   -4.,  -52.,   10.,   14.,
           -18.,  -42.,  -44., -118.,   78.,  176.,  122.,   24.,  -26.,  -56.,
           -82., -118.,   46.,  420.,   36.,  232.,  100.,   80.,  -88.,  186.,
           -30.,  -52.,  -80.],
         [-116., -154.,   20.,   14.,   86.,  -52., -118., -102., -134.,   -8.,
            32.,  -54.,   86.,   94.,   26.,  -32.,   -4.,  -52.,   10.,   14.,
           -18.,  -42.,  -44., -118.,   78.,  176.,  122.,   24.,  -26.,  -56.,
           -82., -118.,   46.,  420.,   36.,  232.,  100.,   80.,  -88.,  186.,
           -30.,  -52.,  -80.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[536., 574., 400., 406., 334., 472., 538., 522., 554., 428.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7065 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -90., -120.,   30.,   16.,   28., -118., -152., -144., -112.,    6.,
           -46.,  -80.,   88.,  108.,   36.,  -18.,   14.,  -50.,  -12.,    0.,
            28.,  -24.,  -14.,  -92.,   88.,  198.,   96.,   14.,   12.,  -18.,
           -60., -124.,   12.,  354.,   34.,  334.,  110.,   70.,  -90.,  136.,
           -40.,  -18.,  -70.],
         [ -90., -120.,   30.,   16.,   28., -118., -152., -144., -112.,    6.,
           -46.,  -80.,   88.,  108.,   36.,  -18.,   14.,  -50.,  -12.,    0.,
            28.,  -24.,  -14.,  -92.,   88.,  198.,   96.,   14.,   12.,  -18.,
           -60., -124.,   12.,  354.,   34.,  334.,  110.,   70.,  -90.,  136.,
           -40.,  -18.,  -70.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[444., 474., 324., 338., 326., 472., 506., 498., 466., 348.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6444 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -90., -116.,   30.,   -4.,   72.,  -18., -108., -116., -140.,  -30.,
            50.,  -40.,   88.,   96.,   32.,  -18.,    2.,  -66.,   16.,   12.,
           -24.,   -4.,  -66., -116.,  100.,  150.,  112.,   30.,  -36.,  -50.,
           -80., -112.,   36.,  406.,   26.,  230.,   78.,   70.,  -62.,  136.,
           -24.,  -74.,  -62.],
         [ -90., -116.,   30.,   -4.,   72.,  -18., -108., -116., -140.,  -30.,
            50.,  -40.,   88.,   96.,   32.,  -18.,    2.,  -66.,   16.,   12.,
           -24.,   -4.,  -66., -116.,  100.,  150.,  112.,   30.,  -36.,  -50.,
           -80., -112.,   36.,  406.,   26.,  230.,   78.,   70.,  -62.,  136.,
           -24.,  -74.,  -62.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[496., 522., 376., 410., 334., 424., 514., 522., 546., 436.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7100 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-140., -166.,   44.,  -34.,   70.,  -52., -106., -102., -178.,  -56.,
            20.,   -6.,   54.,  126.,   26.,  -44.,  -28.,  -96.,  -14.,   38.,
           -66.,   22.,  -16.,  -46.,   70.,  344.,  106.,   44.,    2., -108.,
            -6.,  -78.,   22.,  364.,  -32.,  168.,  100.,   24.,  -64.,  158.,
           -66.,  -40.,  -52.],
         [-140., -166.,   44.,  -34.,   70.,  -52., -106., -102., -178.,  -56.,
            20.,   -6.,   54.,  126.,   26.,  -44.,  -28.,  -96.,  -14.,   38.,
           -66.,   22.,  -16.,  -46.,   70.,  344.,  106.,   44.,    2., -108.,
            -6.,  -78.,   22.,  364.,  -32.,  168.,  100.,   24.,  -64.,  158.,
           -66.,  -40.,  -52.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[504., 530., 320., 398., 294., 416., 470., 466., 542., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6444 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -86., -120.,   46.,    8.,   72.,  -22., -116., -124., -140.,  -42.,
            26.,  -56.,   52.,  116.,   24.,  -42.,    6.,  -58.,    4.,   40.,
           -16.,  -24.,  -58., -112.,   76.,  162.,  120.,   22.,  -16.,  -54.,
           -60.,  -96.,   40.,  402.,   30.,  218.,   86.,   82.,  -66.,  156.,
           -28.,  -74.,  -66.],
         [ -86., -120.,   46.,    8.,   72.,  -22., -116., -124., -140.,  -42.,
            26.,  -56.,   52.,  116.,   24.,  -42.,    6.,  -58.,    4.,   40.,
           -16.,  -24.,  -58., -112.,   76.,  162.,  120.,   22.,  -16.,  -54.,
           -60.,  -96.,   40.,  402.,   30.,  218.,   86.,   82.,  -66.,  156.,
           -28.,  -74.,  -66.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[488., 522., 356., 394., 330., 424., 518., 526., 542., 444.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7064 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -124.,   46.,  -28.,   80.,  -50.,  -88., -108., -196.,  -42.,
            -6.,  -20.,   20.,  164.,   44.,  -62.,  -42.,  -78.,    4.,   56.,
           -76.,   28.,  -14.,  -56.,   88.,  330.,  108.,   50.,  -24., -102.,
           -32.,  -48.,    4.,  342.,   -6.,  158.,  114.,   22.,  -42.,  128.,
           -64.,  -70.,  -66.],
         [-114., -124.,   46.,  -28.,   80.,  -50.,  -88., -108., -196.,  -42.,
            -6.,  -20.,   20.,  164.,   44.,  -62.,  -42.,  -78.,    4.,   56.,
           -76.,   28.,  -14.,  -56.,   88.,  330.,  108.,   50.,  -24., -102.,
           -32.,  -48.,    4.,  342.,   -6.,  158.,  114.,   22.,  -42.,  128.,
           -64.,  -70.,  -66.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[456., 466., 296., 370., 262., 392., 430., 450., 538., 384.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6423 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-112., -134.,   40.,   14.,   78.,  -32., -118., -118., -138.,  -20.,
            28.,  -50.,   62.,   86.,   26.,  -28.,   -4.,  -72.,   26.,   18.,
           -30.,  -10.,  -56., -106.,   82.,  156.,  110.,   40.,  -30.,  -68.,
           -78., -114.,   38.,  412.,   36.,  220.,   92.,   68.,  -64.,  138.,
           -14.,  -76.,  -76.],
         [-112., -134.,   40.,   14.,   78.,  -32., -118., -118., -138.,  -20.,
            28.,  -50.,   62.,   86.,   26.,  -28.,   -4.,  -72.,   26.,   18.,
           -30.,  -10.,  -56., -106.,   82.,  156.,  110.,   40.,  -30.,  -68.,
           -78., -114.,   38.,  412.,   36.,  220.,   92.,   68.,  -64.,  138.,
           -14.,  -76.,  -76.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[524., 546., 372., 398., 334., 444., 530., 530., 550., 432.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7063 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-108., -118.,   52.,  -26.,   82.,  -40.,  -66.,  -94., -162.,  -64.,
            -4.,  -54.,   34.,  170.,   38.,  -64.,  -64., -100.,   42.,   34.,
           -82.,    6.,  -24.,  -74.,   86.,  316.,   74.,   56.,  -22.,  -92.,
           -46.,  -66.,   42.,  332.,  -28.,  144.,  120.,   16.,  -32.,  130.,
           -54.,  -72.,  -28.],
         [-108., -118.,   52.,  -26.,   82.,  -40.,  -66.,  -94., -162.,  -64.,
            -4.,  -54.,   34.,  170.,   38.,  -64.,  -64., -100.,   42.,   34.,
           -82.,    6.,  -24.,  -74.,   86.,  316.,   74.,   56.,  -22.,  -92.,
           -46.,  -66.,   42.,  332.,  -28.,  144.,  120.,   16.,  -32.,  130.,
           -54.,  -72.,  -28.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[440., 450., 280., 358., 250., 372., 398., 426., 494., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6413 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -94., -100.,   34.,   24.,   48.,  -30., -116., -112., -132.,  -26.,
            34.,  -44.,   80.,   84.,   48.,    6.,   18.,  -62.,    0.,   -8.,
           -24.,   -4.,  -54., -140.,   56.,  118.,   92.,   26.,  -40.,  -50.,
           -76., -100.,   28.,  426.,   22.,  230.,   54.,   74.,  -66.,  168.,
            -4.,  -74.,  -70.],
         [ -94., -100.,   34.,   24.,   48.,  -30., -116., -112., -132.,  -26.,
            34.,  -44.,   80.,   84.,   48.,    6.,   18.,  -62.,    0.,   -8.,
           -24.,   -4.,  -54., -140.,   56.,  118.,   92.,   26.,  -40.,  -50.,
           -76., -100.,   28.,  426.,   22.,  230.,   54.,   74.,  -66.,  168.,
            -4.,  -74.,  -70.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[520., 526., 392., 402., 378., 456., 542., 538., 558., 452.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7150 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-132., -154.,   56.,  -70.,  110.,  -72.,  -82.,  -82., -202.,  -68.,
            28.,  -26.,   34.,  134.,   34.,  -60.,  -48., -108.,  -14.,   54.,
           -70.,   22.,    0.,  -70.,   86.,  328.,  110.,   56.,   -6., -128.,
           -34.,  -70.,   30.,  336.,  -12.,  168.,  108.,   48.,  -60.,  142.,
           -38.,  -32.,  -32.],
         [-132., -154.,   56.,  -70.,  110.,  -72.,  -82.,  -82., -202.,  -68.,
            28.,  -26.,   34.,  134.,   34.,  -60.,  -48., -108.,  -14.,   54.,
           -70.,   22.,    0.,  -70.,   86.,  328.,  110.,   56.,   -6., -128.,
           -34.,  -70.,   30.,  336.,  -12.,  168.,  108.,   48.,  -60.,  142.,
           -38.,  -32.,  -32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[468., 490., 280., 406., 226., 408., 418., 418., 538., 404.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6433 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -92., -118.,   24.,   14.,   62.,  -32., -110., -122., -130.,  -24.,
            32.,  -46.,   74.,  102.,   42.,  -12.,   16.,  -52.,  -10.,   26.,
           -10.,  -22.,  -44., -130.,   58.,  144.,  146.,   12.,  -30.,  -48.,
           -82., -114.,   46.,  412.,   28.,  224.,  100.,   64.,  -88.,  154.,
           -38.,  -64.,  -76.],
         [ -92., -118.,   24.,   14.,   62.,  -32., -110., -122., -130.,  -24.,
            32.,  -46.,   74.,  102.,   42.,  -12.,   16.,  -52.,  -10.,   26.,
           -10.,  -22.,  -44., -130.,   58.,  144.,  146.,   12.,  -30.,  -48.,
           -82., -114.,   46.,  412.,   28.,  224.,  100.,   64.,  -88.,  154.,
           -38.,  -64.,  -76.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[504., 530., 388., 398., 350., 444., 522., 534., 542., 436.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7142 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-118., -140.,   86.,  -36.,   96.,  -62., -100., -132., -200.,  -42.,
            14.,  -36.,   40.,  148.,   20.,  -46.,  -26.,  -78.,   -8.,   16.,
           -88.,   24.,  -10.,  -60.,   64.,  338.,   96.,   50.,  -28., -118.,
           -44.,  -76.,    8.,  358.,    6.,  166.,  114.,   54.,  -34.,  152.,
           -44.,  -50.,  -82.],
         [-118., -140.,   86.,  -36.,   96.,  -62., -100., -132., -200.,  -42.,
            14.,  -36.,   40.,  148.,   20.,  -46.,  -26.,  -78.,   -8.,   16.,
           -88.,   24.,  -10.,  -60.,   64.,  338.,   96.,   50.,  -28., -118.,
           -44.,  -76.,    8.,  358.,    6.,  166.,  114.,   54.,  -34.,  152.,
           -44.,  -50.,  -82.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[476., 498., 272., 394., 262., 420., 458., 490., 558., 400.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6396 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104., -150.,   48.,   26.,   58.,  -44., -102., -130., -130.,  -24.,
            12.,  -42.,   74.,   86.,   58.,    0.,    8.,  -60.,   18.,   -2.,
           -58.,  -34.,  -48., -134.,   58.,  132.,  106.,   24.,  -50.,  -32.,
           -74.,  -90.,   38.,  408.,   40.,  212.,   88.,   48.,  -32.,  138.,
             2.,  -72.,  -80.],
         [-104., -150.,   48.,   26.,   58.,  -44., -102., -130., -130.,  -24.,
            12.,  -42.,   74.,   86.,   58.,    0.,    8.,  -60.,   18.,   -2.,
           -58.,  -34.,  -48., -134.,   58.,  132.,  106.,   24.,  -50.,  -32.,
           -74.,  -90.,   38.,  408.,   40.,  212.,   88.,   48.,  -32.,  138.,
             2.,  -72.,  -80.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[512., 558., 360., 382., 350., 452., 510., 538., 538., 432.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7130 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-132., -122.,   60.,  -14.,   82.,  -60.,  -82.,  -94., -202.,  -48.,
             4.,  -10.,   42.,  126.,   22.,  -72.,  -52., -104.,   22.,   34.,
          -102.,   18.,  -36.,  -78.,   82.,  336.,   90.,   76.,   -6., -100.,
           -26.,  -70.,   42.,  348.,   16.,  140.,  104.,   40.,  -28.,  130.,
           -38.,  -60.,  -68.],
         [-132., -122.,   60.,  -14.,   82.,  -60.,  -82.,  -94., -202.,  -48.,
             4.,  -10.,   42.,  126.,   22.,  -72.,  -52., -104.,   22.,   34.,
          -102.,   18.,  -36.,  -78.,   82.,  336.,   90.,   76.,   -6., -100.,
           -26.,  -70.,   42.,  348.,   16.,  140.,  104.,   40.,  -28.,  130.,
           -38.,  -60.,  -68.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[480., 470., 288., 362., 266., 408., 430., 442., 550., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6406 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -94., -112.,   42.,   16.,   72.,  -38., -100., -112., -132.,  -14.,
            18.,  -44.,   88.,  120.,   48.,  -34.,    2.,  -50.,    4.,   20.,
           -36.,  -32.,  -54., -112.,   76.,  142.,  128.,   10.,  -28.,  -82.,
           -64., -124.,   32.,  402.,   66.,  218.,  110.,   70.,  -66.,  148.,
            -4.,  -86.,  -54.],
         [ -94., -112.,   42.,   16.,   72.,  -38., -100., -112., -132.,  -14.,
            18.,  -44.,   88.,  120.,   48.,  -34.,    2.,  -50.,    4.,   20.,
           -36.,  -32.,  -54., -112.,   76.,  142.,  128.,   10.,  -28.,  -82.,
           -64., -124.,   32.,  402.,   66.,  218.,  110.,   70.,  -66.,  148.,
            -4.,  -86.,  -54.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[496., 514., 360., 386., 330., 440., 502., 514., 534., 416.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7221 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-118., -144.,   42.,  -32.,   60.,  -46.,  -84.,  -76., -196.,  -66.,
            18.,  -36.,   60.,  144.,   12.,  -58.,  -34.,  -94.,   20.,   56.,
           -76.,   20.,   -6.,  -84.,   64.,  326.,   92.,   42.,   12., -110.,
           -32.,  -76.,   48.,  338.,  -14.,  142.,  114.,   14.,  -62.,  176.,
           -68.,  -54.,  -42.],
         [-118., -144.,   42.,  -32.,   60.,  -46.,  -84.,  -76., -196.,  -66.,
            18.,  -36.,   60.,  144.,   12.,  -58.,  -34.,  -94.,   20.,   56.,
           -76.,   20.,   -6.,  -84.,   64.,  326.,   92.,   42.,   12., -110.,
           -32.,  -76.,   48.,  338.,  -14.,  142.,  114.,   14.,  -62.,  176.,
           -68.,  -54.,  -42.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[456., 482., 296., 370., 278., 384., 422., 414., 534., 404.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6463 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-106., -120.,   46.,    8.,   52.,  -10.,  -96., -132., -168.,  -42.,
            38.,  -32.,   80.,   80.,   28.,  -26.,   14.,  -70.,   24.,   24.,
           -40.,   -8.,  -62., -112.,   68.,  150.,   96.,   50.,  -36.,  -54.,
           -80., -100.,   36.,  402.,   30.,  214.,   70.,   78.,  -62.,  148.,
           -36.,  -74.,  -58.],
         [-106., -120.,   46.,    8.,   52.,  -10.,  -96., -132., -168.,  -42.,
            38.,  -32.,   80.,   80.,   28.,  -26.,   14.,  -70.,   24.,   24.,
           -40.,   -8.,  -62., -112.,   68.,  150.,   96.,   50.,  -36.,  -54.,
           -80., -100.,   36.,  402.,   30.,  214.,   70.,   78.,  -62.,  148.,
           -36.,  -74.,  -58.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[508., 522., 356., 394., 350., 412., 498., 534., 570., 444.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7113 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.63s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-102., -108.,   42.,   56.,  -16.,  -90., -132., -116., -124.,   -2.,
           -42.,  -28.,   80.,  104.,   28.,   -2.,   50.,  -66.,  -16.,    8.,
           -28.,  -16.,  -70., -160.,   52.,  154.,   84.,   34.,    0.,  -46.,
          -120., -140.,   64.,  330.,   50.,  314.,   94.,   70.,  -78.,  168.,
           -32.,    2.,  -66.],
         [-102., -108.,   42.,   56.,  -16.,  -90., -132., -116., -124.,   -2.,
           -42.,  -28.,   80.,  104.,   28.,   -2.,   50.,  -66.,  -16.,    8.,
           -28.,  -16.,  -70., -160.,   52.,  154.,   84.,   34.,    0.,  -46.,
          -120., -140.,   64.,  330.,   50.,  314.,   94.,   70.,  -78.,  168.,
           -32.,    2.,  -66.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[432., 438., 288., 274., 346., 420., 462., 446., 454., 332.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6374 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-110., -108.,   58.,    0.,   48.,  -26., -104., -132., -164.,  -34.,
            34.,  -28.,   72.,   84.,   20.,   -6.,   22.,  -58.,   28.,   20.,
           -40.,  -16.,  -66., -120.,   56.,  142.,  100.,   42.,  -28.,  -70.,
           -92., -108.,   52.,  414.,   10.,  222.,   66.,   90.,  -42.,  160.,
            -4.,  -62.,  -62.],
         [-110., -108.,   58.,    0.,   48.,  -26., -104., -132., -164.,  -34.,
            34.,  -28.,   72.,   84.,   20.,   -6.,   22.,  -58.,   28.,   20.,
           -40.,  -16.,  -66., -120.,   56.,  142.,  100.,   42.,  -28.,  -70.,
           -92., -108.,   52.,  414.,   10.,  222.,   66.,   90.,  -42.,  160.,
            -4.,  -62.,  -62.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[524., 522., 356., 414., 366., 440., 518., 546., 578., 448.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7180 seconds.
PGD attack failed
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/6): BoundBuffers(name=/6, inputs=[], perturbed=False)
  (/shape): BoundBuffers(name=/shape, inputs=[], perturbed=False)
  (/18): BoundBuffers(name=/18, inputs=[], perturbed=False)
  (/19): BoundBuffers(name=/19, inputs=[], perturbed=False)
  (/21): BoundParams(name=/21, inputs=[], perturbed=False)
  (/22): BoundParams(name=/22, inputs=[], perturbed=False)
  (/23): BoundParams(name=/23, inputs=[], perturbed=False)
  (/24): BoundBuffers(name=/24, inputs=[], perturbed=False)
  (/25): BoundBuffers(name=/25, inputs=[], perturbed=False)
  (/27): BoundParams(name=/27, inputs=[], perturbed=False)
  (/28): BoundParams(name=/28, inputs=[], perturbed=False)
  (/29): BoundParams(name=/29, inputs=[], perturbed=False)
  (/30): BoundBuffers(name=/30, inputs=[], perturbed=False)
  (/31): BoundBuffers(name=/31, inputs=[], perturbed=False)
  (/33): BoundParams(name=/33, inputs=[], perturbed=False)
  (/34): BoundParams(name=/34, inputs=[], perturbed=False)
  (/35): BoundParams(name=/35, inputs=[], perturbed=False)
  (/36): BoundBuffers(name=/36, inputs=[], perturbed=False)
  (/37): BoundBuffers(name=/37, inputs=[], perturbed=False)
  (/39): BoundParams(name=/39, inputs=[], perturbed=False)
  (/40): BoundParams(name=/40, inputs=[], perturbed=False)
  (/41): BoundConv(name=/41, inputs=[/input.1, /21], perturbed=True)
  (/input): BoundMaxPool(name=/input, inputs=[/41], perturbed=True)
  (/43): BoundBatchNormalization(name=/43, inputs=[/input, /22, /23, /24, /25], perturbed=True)
  (/47): BoundConv(name=/47, inputs=[/44/merge, /27], perturbed=True)
  (/input.8): BoundMaxPool(name=/input.8, inputs=[/47], perturbed=True)
  (/49): BoundBatchNormalization(name=/49, inputs=[/input.8, /28, /29, /30, /31], perturbed=True)
  (/53): BoundConv(name=/53, inputs=[/50/merge, /33], perturbed=True)
  (/input.16): BoundMaxPool(name=/input.16, inputs=[/53], perturbed=True)
  (/55): BoundBatchNormalization(name=/55, inputs=[/input.16, /34, /35, /36, /37], perturbed=True)
  (/59): BoundSplit(name=/59, inputs=[/shape], perturbed=False)
  (/60): BoundSplit(name=/60, inputs=[/shape], perturbed=False)
  (/61): BoundSqueeze(name=/61, inputs=[/59], perturbed=False)
  (/62): BoundSqueeze(name=/62, inputs=[/60], perturbed=False)
  (/63): BoundUnsqueeze(name=/63, inputs=[/61], perturbed=False)
  (/64): BoundUnsqueeze(name=/64, inputs=[/62], perturbed=False)
  (/65): BoundConcat(name=/65, inputs=[/63, /64], perturbed=False)
  (/66): BoundReshape(name=/66, inputs=[/56/merge, /65], perturbed=True)
  (/67): BoundTranspose(name=/67, inputs=[/39], perturbed=False)
  (/68): BoundMatMul(name=/68, inputs=[/66, /67], perturbed=True)
  (/69): BoundMul(name=/69, inputs=[/68, /18], perturbed=True)
  (/70): BoundAdd(name=/70, inputs=[/69, /19], perturbed=True)
  (/74): BoundTranspose(name=/74, inputs=[/40], perturbed=False)
  (/75): BoundMatMul(name=/75, inputs=[/71/merge, /74], perturbed=True)
  (/44/merge): BoundSignMerge(name=/44/merge, inputs=[/43], perturbed=True)
  (/50/merge): BoundSignMerge(name=/50/merge, inputs=[/49], perturbed=True)
  (/56/merge): BoundSignMerge(name=/56/merge, inputs=[/55], perturbed=True)
  (/71/merge): BoundSignMerge(name=/71/merge, inputs=[/70], perturbed=True)
)
Original output: tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
Split layers:
  BoundBatchNormalization(name=/43, inputs=[/input, /22, /23, /24, /25], perturbed=True): [(BoundSignMerge(name=/44/merge, inputs=[/43], perturbed=True), 0)]
  BoundBatchNormalization(name=/49, inputs=[/input.8, /28, /29, /30, /31], perturbed=True): [(BoundSignMerge(name=/50/merge, inputs=[/49], perturbed=True), 0)]
  BoundBatchNormalization(name=/55, inputs=[/input.16, /34, /35, /36, /37], perturbed=True): [(BoundSignMerge(name=/56/merge, inputs=[/55], perturbed=True), 0)]
  BoundAdd(name=/70, inputs=[/69, /19], perturbed=True): [(BoundSignMerge(name=/71/merge, inputs=[/70], perturbed=True), 0)]
Nonlinear functions:
   BoundMaxPool(name=/input, inputs=[/41], perturbed=True)
   BoundMaxPool(name=/input.8, inputs=[/47], perturbed=True)
   BoundMaxPool(name=/input.16, inputs=[/53], perturbed=True)
   BoundSignMerge(name=/44/merge, inputs=[/43], perturbed=True)
   BoundSignMerge(name=/50/merge, inputs=[/49], perturbed=True)
   BoundSignMerge(name=/56/merge, inputs=[/55], perturbed=True)
   BoundSignMerge(name=/71/merge, inputs=[/70], perturbed=True)
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py:880: UserWarning: Creating an identity matrix with size 1024x1024 for node BoundAdd(name=/70, inputs=[/69, /19], perturbed=True). This may indicate poor performance for bound computation. If you see this message on a small network please submit a bug report.
  sparse_C = self.get_sparse_C(
layer /44/merge using sparse-features alpha with shape [3222]; unstable size 3222; total size 28800 ([1, 32, 30, 30])
layer /44/merge start_node /47 using full alpha [4, 64, 1, 3222] with unstable size 64 total_size 64 output_shape 64
layer /44/merge start_node /49 using full alpha [4, 64, 1, 3222] with unstable size 64 total_size 64 output_shape 64
layer /44/merge start_node /53 using full alpha [4, 64, 1, 3222] with unstable size 64 total_size 64 output_shape 64
layer /44/merge start_node /55 using full alpha [4, 64, 1, 3222] with unstable size 64 total_size 64 output_shape 64
layer /44/merge start_node /70 using full alpha [4, 1024, 1, 3222] with unstable size 1024 total_size 1024 output_shape torch.Size([1024])
layer /44/merge start_node /75 using full alpha [4, 42, 1, 3222] with unstable size None total_size 42 output_shape 42
layer /50/merge using sparse-features alpha with shape [7433]; unstable size 7433; total size 10816 ([1, 64, 13, 13])
layer /50/merge start_node /53 using full alpha [4, 64, 1, 7433] with unstable size 64 total_size 64 output_shape 64
layer /50/merge start_node /55 using full alpha [4, 64, 1, 7433] with unstable size 64 total_size 64 output_shape 64
layer /50/merge start_node /70 using full alpha [4, 1024, 1, 7433] with unstable size 1024 total_size 1024 output_shape torch.Size([1024])
layer /50/merge start_node /75 using full alpha [4, 42, 1, 7433] with unstable size None total_size 42 output_shape 42
layer /56/merge using full alpha with shape torch.Size([64, 5, 5]); unstable size 1600; total size 1600 ([1, 64, 5, 5])
layer /56/merge start_node /70 using full alpha [4, 1024, 1, 64, 5, 5] with unstable size 1024 total_size 1024 output_shape torch.Size([1024])
layer /56/merge start_node /75 using full alpha [4, 42, 1, 64, 5, 5] with unstable size None total_size 42 output_shape 42
layer /71/merge using full alpha with shape torch.Size([1024]); unstable size 1024; total size 1024 ([1, 1024])
layer /71/merge start_node /75 using full alpha [4, 42, 1, 1024] with unstable size None total_size 42 output_shape 42
Optimizable variables initialized.
initial CROWN bounds: tensor([[-1040., -1102., -1004.,  -990.,  -914., -1064., -1126., -1030., -1106.,
         -1012.,  -976., -1062., -1026.,  -966., -1006., -1000., -1016., -1076.,
         -1082., -1074., -1022.,  -998., -1056., -1122.,  -982.,  -988.,  -974.,
         -1016., -1062., -1092., -1038., -1078., -1030., -1036.,  -956.,  -972.,
          -944., -1080.,  -898., -1058., -1084., -1084.]], device='cuda:0') None
Traceback (most recent call last):
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py", line 612, in <module>
    abcrown.main()
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py", line 557, in main
    verified_status, ret = self.incomplete_verifier(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py", line 123, in incomplete_verifier
    global_lb, ret = model.build(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/beta_CROWN_solver.py", line 500, in build
    ret = self.net.compute_bounds(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 1193, in compute_bounds
    ret1 = self._get_optimized_bounds(bound_side='lower', **kwargs)
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/optimized_bounds.py", line 426, in _get_optimized_bounds
    ret = self.compute_bounds(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 1206, in compute_bounds
    return self._compute_bounds_main(C=C,
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 1303, in _compute_bounds_main
    self.check_prior_bounds(final)
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 800, in check_prior_bounds
    self.check_prior_bounds(n)
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 804, in check_prior_bounds
    self.compute_intermediate_bounds(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/bound_general.py", line 910, in compute_intermediate_bounds
    node.lower, node.upper = self.backward_general(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/backward_bound.py", line 256, in backward_general
    A, lower_b, upper_b = l.bound_backward(
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/operators/relu.py", line 249, in bound_backward
    self._backward_relaxation(last_lA, last_uA, x, start_node, unstable_idx)
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/operators/relu.py", line 855, in _backward_relaxation
    lb_lower_d, ub_lower_d, lb_upper_d, ub_upper_d = self._mask_alpha(lower, upper,
  File "/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/auto_LiRPA/operators/relu.py", line 793, in _mask_alpha
    lb_upper_d = torch.clamp(lb_upper_d, min=0) * no_mask
RuntimeError: CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 11.75 GiB total capacity; 9.33 GiB already allocated; 117.62 MiB free; 9.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
exit code: 2
head: cannot open 'out.txt' for reading: No such file or directory

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example --bound_prop_method crown --apply_output_constraints_to
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 14:53:44 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.1927s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.81s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-136., -142.,   32.,  -38.,   94.,  -80.,  -94.,  -62., -226.,  -40.,
            44.,  -42.,   50.,  170.,   22.,  -68.,  -36., -104.,    2.,   66.,
           -54.,   54.,    8.,  -78.,   82.,  336.,   78.,   44.,  -14., -128.,
           -30.,  -58.,   14.,  356.,   -4.,  136.,  104.,   28.,  -84.,  174.,
           -54.,  -16.,  -32.],
         [-136., -142.,   32.,  -38.,   94.,  -80.,  -94.,  -62., -226.,  -40.,
            44.,  -42.,   50.,  170.,   22.,  -68.,  -36., -104.,    2.,   66.,
           -54.,   54.,    8.,  -78.,   82.,  336.,   78.,   44.,  -14., -128.,
           -30.,  -58.,   14.,  356.,   -4.,  136.,  104.,   28.,  -84.,  174.,
           -54.,  -16.,  -32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[492., 498., 324., 394., 262., 436., 450., 418., 582., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.8157 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-106., -128.,   42.,   12.,   80.,  -42., -108., -116., -140.,  -58.,
            42.,  -52.,   68.,   96.,   24.,  -22.,    6.,  -82.,   16.,   24.,
           -48.,  -24.,  -54., -124.,   84.,  150.,  112.,   26.,   -4.,  -70.,
           -68.,  -84.,   44.,  406.,   38.,  210.,   82.,   66.,  -62.,  144.,
           -20.,  -74.,  -58.],
         [-106., -128.,   42.,   12.,   80.,  -42., -108., -116., -140.,  -58.,
            42.,  -52.,   68.,   96.,   24.,  -22.,    6.,  -82.,   16.,   24.,
           -48.,  -24.,  -54., -124.,   84.,  150.,  112.,   26.,   -4.,  -70.,
           -68.,  -84.,   44.,  406.,   38.,  210.,   82.,   66.,  -62.,  144.,
           -20.,  -74.,  -58.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[512., 534., 364., 394., 326., 448., 514., 522., 546., 464.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7127 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-138., -160.,   22.,  -28.,   64.,  -78., -112.,  -84., -180.,  -62.,
            30.,  -12.,   52.,  148.,   24.,  -58.,  -38.,  -90.,    0.,   36.,
           -72.,   12.,  -18.,  -76.,   80.,  334.,  108.,   42.,  -12.,  -94.,
            -8.,  -88.,    4.,  346.,   22.,  174.,  130.,   50.,  -50.,  148.,
           -52.,  -26.,  -66.],
         [-138., -160.,   22.,  -28.,   64.,  -78., -112.,  -84., -180.,  -62.,
            30.,  -12.,   52.,  148.,   24.,  -58.,  -38.,  -90.,    0.,   36.,
           -72.,   12.,  -18.,  -76.,   80.,  334.,  108.,   42.,  -12.,  -94.,
            -8.,  -88.,    4.,  346.,   22.,  174.,  130.,   50.,  -50.,  148.,
           -52.,  -26.,  -66.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[484., 506., 324., 374., 282., 424., 458., 430., 526., 408.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6484 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -86., -136.,   14.,   20.,   72.,  -22., -104., -104., -136.,  -30.,
            50.,  -52.,  100.,   76.,   32.,  -14.,   14.,  -78.,    8.,    0.,
           -16.,  -20.,  -54., -120.,   80.,  150.,  112.,   22.,   -8.,  -58.,
           -60., -120.,   60.,  418.,   14.,  222.,   94.,   62.,  -82.,  140.,
           -24.,  -58.,  -62.],
         [ -86., -136.,   14.,   20.,   72.,  -22., -104., -104., -136.,  -30.,
            50.,  -52.,  100.,   76.,   32.,  -14.,   14.,  -78.,    8.,    0.,
           -16.,  -20.,  -54., -120.,   80.,  150.,  112.,   22.,   -8.,  -58.,
           -60., -120.,   60.,  418.,   14.,  222.,   94.,   62.,  -82.,  140.,
           -24.,  -58.,  -62.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[504., 554., 404., 398., 346., 440., 522., 522., 554., 448.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7124 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.65s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104., -154.,   52.,  -54.,  102.,  -52.,  -90., -110., -174.,  -40.,
            32.,  -22.,   38.,  162.,   34.,  -64.,  -40.,  -92.,   14.,   70.,
           -70.,   26.,   -8.,  -82.,   50.,  332.,  102.,   80.,  -10., -104.,
           -26.,  -46.,   14.,  356.,  -12.,  152.,  104.,   56.,  -72.,  158.,
           -54.,  -56.,  -72.],
         [-104., -154.,   52.,  -54.,  102.,  -52.,  -90., -110., -174.,  -40.,
            32.,  -22.,   38.,  162.,   34.,  -64.,  -40.,  -92.,   14.,   70.,
           -70.,   26.,   -8.,  -82.,   50.,  332.,  102.,   80.,  -10., -104.,
           -26.,  -46.,   14.,  356.,  -12.,  152.,  104.,   56.,  -72.,  158.,
           -54.,  -56.,  -72.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[460., 510., 304., 410., 254., 408., 446., 466., 530., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6600 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -82., -100.,   54.,   16.,   60.,  -18., -116., -108., -124.,  -26.,
            34.,  -24.,  100.,   76.,   44.,    2.,   66.,  -70.,   12.,    8.,
           -40.,  -16.,  -82., -144.,   36.,  138.,   64.,    6.,  -40.,  -74.,
           -64., -116.,   40.,  418.,   18.,  234.,   82.,   42.,  -78.,  160.,
           -12.,  -66.,  -78.],
         [ -82., -100.,   54.,   16.,   60.,  -18., -116., -108., -124.,  -26.,
            34.,  -24.,  100.,   76.,   44.,    2.,   66.,  -70.,   12.,    8.,
           -40.,  -16.,  -82., -144.,   36.,  138.,   64.,    6.,  -40.,  -74.,
           -64., -116.,   40.,  418.,   18.,  234.,   82.,   42.,  -78.,  160.,
           -12.,  -66.,  -78.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[500., 518., 364., 402., 358., 436., 534., 526., 542., 444.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7166 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-130., -128.,   74.,  -40.,   84.,  -50., -108.,  -92., -200.,  -54.,
            18.,  -28.,   40.,  164.,   24.,  -74.,  -46.,  -90.,   -4.,   60.,
           -80.,   32.,    6.,  -64.,   52.,  318.,   96.,   66.,   -4., -142.,
           -28.,  -52.,   32.,  338.,  -18.,  150.,   90.,   42.,  -42.,  164.,
           -60.,  -42.,  -58.],
         [-130., -128.,   74.,  -40.,   84.,  -50., -108.,  -92., -200.,  -54.,
            18.,  -28.,   40.,  164.,   24.,  -74.,  -46.,  -90.,   -4.,   60.,
           -80.,   32.,    6.,  -64.,   52.,  318.,   96.,   66.,   -4., -142.,
           -28.,  -52.,   32.,  338.,  -18.,  150.,   90.,   42.,  -42.,  164.,
           -60.,  -42.,  -58.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[468., 466., 264., 378., 254., 388., 446., 430., 538., 392.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6478 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -108.,   50.,   16.,   60.,  -26.,  -92., -112., -124.,  -30.,
             6.,  -24.,   56.,   88.,   28.,  -10.,   22.,  -78.,   20.,    8.,
           -56.,  -44.,  -70., -132.,   52.,  154.,   84.,   26.,  -32.,  -66.,
          -108., -112.,   44.,  402.,   26.,  218.,   94.,   54.,  -54.,  168.,
            -8.,  -58.,  -70.],
         [-114., -108.,   50.,   16.,   60.,  -26.,  -92., -112., -124.,  -30.,
             6.,  -24.,   56.,   88.,   28.,  -10.,   22.,  -78.,   20.,    8.,
           -56.,  -44.,  -70., -132.,   52.,  154.,   84.,   26.,  -32.,  -66.,
          -108., -112.,   44.,  402.,   26.,  218.,   94.,   54.,  -54.,  168.,
            -8.,  -58.,  -70.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[516., 510., 352., 386., 342., 428., 494., 514., 526., 432.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7136 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-134., -112.,   86.,  -52.,   84.,  -70., -100.,  -92., -204.,  -70.,
             2.,  -28.,   52.,  144.,   16.,  -82.,  -30.,  -78.,    0.,   32.,
          -100.,   40.,  -14.,  -64.,   96.,  330.,   76.,   78.,   -8., -106.,
           -32.,  -84.,   28.,  346.,   14.,  146.,  118.,   58.,  -34.,  116.,
             0.,  -18.,  -38.],
         [-134., -112.,   86.,  -52.,   84.,  -70., -100.,  -92., -204.,  -70.,
             2.,  -28.,   52.,  144.,   16.,  -82.,  -30.,  -78.,    0.,   32.,
          -100.,   40.,  -14.,  -64.,   96.,  330.,   76.,   78.,   -8., -106.,
           -32.,  -84.,   28.,  346.,   14.,  146.,  118.,   58.,  -34.,  116.,
             0.,  -18.,  -38.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[480., 458., 260., 398., 262., 416., 446., 438., 550., 416.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6526 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-106., -160.,   22.,   32.,   76.,  -26., -112.,  -92., -112.,  -26.,
            22.,  -44.,   60.,  108.,   20.,  -34.,    6.,  -98.,   36.,    0.,
           -24.,  -28.,  -50., -124.,   84.,  162.,  112.,    6.,  -24.,  -34.,
           -72., -120.,   36.,  402.,   42.,  210.,  102.,   70.,  -54.,  144.,
            -4.,  -74.,  -86.],
         [-106., -160.,   22.,   32.,   76.,  -26., -112.,  -92., -112.,  -26.,
            22.,  -44.,   60.,  108.,   20.,  -34.,    6.,  -98.,   36.,    0.,
           -24.,  -28.,  -50., -124.,   84.,  162.,  112.,    6.,  -24.,  -34.,
           -72., -120.,   36.,  402.,   42.,  210.,  102.,   70.,  -54.,  144.,
            -4.,  -74.,  -86.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[508., 562., 380., 370., 326., 428., 514., 494., 514., 428.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7242 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.65s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104., -126.,   60.,  -38.,  110.,  -84., -102.,  -90., -158.,  -40.,
            12.,  -22.,   30.,  170.,   14.,  -44.,  -12., -112.,   -6.,   50.,
           -78.,    2.,   -4.,  -86.,   58.,  324.,  118.,   44.,  -10., -104.,
            -6.,  -98.,   22.,  344.,    0.,  176.,  108.,   28.,  -56.,  150.,
           -46.,  -44.,  -80.],
         [-104., -126.,   60.,  -38.,  110.,  -84., -102.,  -90., -158.,  -40.,
            12.,  -22.,   30.,  170.,   14.,  -44.,  -12., -112.,   -6.,   50.,
           -78.,    2.,   -4.,  -86.,   58.,  324.,  118.,   44.,  -10., -104.,
            -6.,  -98.,   22.,  344.,    0.,  176.,  108.,   28.,  -56.,  150.,
           -46.,  -44.,  -80.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[448., 470., 284., 382., 234., 428., 446., 434., 502., 384.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6543 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.70s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-124., -142.,   40.,   14.,   78.,  -28.,  -94.,  -78., -110.,  -24.,
            32.,  -18.,   98.,   86.,   62.,  -12.,   24.,  -68.,   10.,    2.,
           -38.,  -38.,  -80., -134.,   46.,  124.,  126.,    4.,  -54.,  -56.,
           -70., -106.,   22.,  424.,   36.,  220.,   72.,   68.,  -88.,  146.,
            -2.,  -68.,  -84.],
         [-124., -142.,   40.,   14.,   78.,  -28.,  -94.,  -78., -110.,  -24.,
            32.,  -18.,   98.,   86.,   62.,  -12.,   24.,  -68.,   10.,    2.,
           -38.,  -38.,  -80., -134.,   46.,  124.,  126.,    4.,  -54.,  -56.,
           -70., -106.,   22.,  424.,   36.,  220.,   72.,   68.,  -88.,  146.,
            -2.,  -68.,  -84.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[548., 566., 384., 410., 346., 452., 518., 502., 534., 448.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7139 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-142., -144.,   34.,  -44.,  112.,  -54.,  -92.,  -84., -192.,  -38.,
            14.,  -12.,   48.,  132.,   36.,  -70.,  -38.,  -78.,   24.,   56.,
           -60.,   20.,  -18.,  -80.,   76.,  318.,  108.,   54.,  -16., -118.,
           -28.,  -88.,   28.,  338.,  -14.,  150.,  106.,   42.,  -46.,  144.,
           -40.,  -54.,  -46.],
         [-142., -144.,   34.,  -44.,  112.,  -54.,  -92.,  -84., -192.,  -38.,
            14.,  -12.,   48.,  132.,   36.,  -70.,  -38.,  -78.,   24.,   56.,
           -60.,   20.,  -18.,  -80.,   76.,  318.,  108.,   54.,  -16., -118.,
           -28.,  -88.,   28.,  338.,  -14.,  150.,  106.,   42.,  -46.,  144.,
           -40.,  -54.,  -46.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[480., 482., 304., 382., 226., 392., 430., 422., 530., 376.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6504 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.71s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-138., -152.,   50.,   32.,   96.,    2., -104., -100., -124.,  -26.,
            34.,  -52.,   88.,   76.,   36.,  -26.,  -10.,  -70.,    8.,    4.,
           -28.,  -20.,  -58., -140.,   52.,  158.,  120.,   26.,  -56.,  -66.,
           -88., -120.,   36.,  414.,   42.,  222.,  102.,   50.,  -66.,  144.,
           -32.,  -62.,  -82.],
         [-138., -152.,   50.,   32.,   96.,    2., -104., -100., -124.,  -26.,
            34.,  -52.,   88.,   76.,   36.,  -26.,  -10.,  -70.,    8.,    4.,
           -28.,  -20.,  -58., -140.,   52.,  158.,  120.,   26.,  -56.,  -66.,
           -88., -120.,   36.,  414.,   42.,  222.,  102.,   50.,  -66.,  144.,
           -32.,  -62.,  -82.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[552., 566., 364., 382., 318., 412., 518., 514., 538., 440.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7173 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.64s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-128., -134.,   56.,    2.,   78.,  -52., -130.,  -90., -174.,  -48.,
             8.,  -30.,   42.,  146.,   18.,  -44.,  -52.,  -72.,    6.,   46.,
           -66.,   26.,  -12.,  -66.,   58.,  344.,   94.,   36.,   14., -100.,
           -26.,  -50.,   22.,  348.,   -8.,  164.,  112.,    4.,  -40.,  142.,
           -66.,  -40.,  -64.],
         [-128., -134.,   56.,    2.,   78.,  -52., -130.,  -90., -174.,  -48.,
             8.,  -30.,   42.,  146.,   18.,  -44.,  -52.,  -72.,    6.,   46.,
           -66.,   26.,  -12.,  -66.,   58.,  344.,   94.,   36.,   14., -100.,
           -26.,  -50.,   22.,  348.,   -8.,  164.,  112.,    4.,  -40.,  142.,
           -66.,  -40.,  -64.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[476., 482., 292., 346., 270., 400., 478., 438., 522., 396.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6528 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.73s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-108., -114.,   40.,   26.,   54.,   -8.,  -98., -130., -154.,  -48.,
            40.,  -54.,   66.,   74.,   18.,  -36.,   12.,  -64.,   10.,   26.,
           -22.,  -22.,  -52., -126.,   90.,  152.,  106.,   36.,  -14.,  -72.,
           -90.,  -90.,   58.,  412.,    8.,  220.,   96.,   76.,  -76.,  150.,
           -30.,  -68.,  -64.],
         [-108., -114.,   40.,   26.,   54.,   -8.,  -98., -130., -154.,  -48.,
            40.,  -54.,   66.,   74.,   18.,  -36.,   12.,  -64.,   10.,   26.,
           -22.,  -22.,  -52., -126.,   90.,  152.,  106.,   36.,  -14.,  -72.,
           -90.,  -90.,   58.,  412.,    8.,  220.,   96.,   76.,  -76.,  150.,
           -30.,  -68.,  -64.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[520., 526., 372., 386., 358., 420., 510., 542., 566., 460.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7403 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.69s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-104.,  -94.,   40.,  -22.,   58.,  -64.,  -62., -110., -226.,  -64.,
            20.,  -14.,   30.,  154.,   -2., -108.,  -16.,  -80.,   22.,   58.,
           -90.,   22.,  -32.,  -62.,   70.,  348.,  106.,   68.,  -22., -104.,
           -54.,  -58.,    6.,  356.,   -4.,  144.,  120.,   44.,  -40.,  122.,
           -34.,  -24.,  -52.],
         [-104.,  -94.,   40.,  -22.,   58.,  -64.,  -62., -110., -226.,  -64.,
            20.,  -14.,   30.,  154.,   -2., -108.,  -16.,  -80.,   22.,   58.,
           -90.,   22.,  -32.,  -62.,   70.,  348.,  106.,   68.,  -22., -104.,
           -54.,  -58.,    6.,  356.,   -4.,  144.,  120.,   44.,  -40.,  122.,
           -34.,  -24.,  -52.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[460., 450., 316., 378., 298., 420., 418., 466., 582., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6958 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.75s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -116.,   62.,   12.,   88.,  -14., -104.,  -84., -116.,  -34.,
            18.,  -32.,   76.,   96.,   32.,  -14.,   26.,  -78.,    0.,   12.,
           -60.,  -16.,  -74., -136.,   84.,  138.,  112.,   26.,  -44.,  -66.,
           -88., -104.,   20.,  418.,    6.,  222.,   90.,   66.,  -62.,  156.,
            -8.,  -78.,  -78.],
         [-114., -116.,   62.,   12.,   88.,  -14., -104.,  -84., -116.,  -34.,
            18.,  -32.,   76.,   96.,   32.,  -14.,   26.,  -78.,    0.,   12.,
           -60.,  -16.,  -74., -136.,   84.,  138.,  112.,   26.,  -44.,  -66.,
           -88., -104.,   20.,  418.,    6.,  222.,   90.,   66.,  -62.,  156.,
            -8.,  -78.,  -78.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[532., 534., 356., 406., 330., 432., 522., 502., 534., 452.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7575 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.68s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-114., -152.,   54.,  -20.,   84.,  -38.,  -88., -116., -188.,  -50.,
            14.,    4.,   48.,  144.,   36.,  -62.,  -22., -110.,   20.,   48.,
           -80.,   12.,  -14., -104.,   60.,  318.,  100.,   58.,    8., -118.,
           -40.,  -72.,   36.,  338.,    2.,  146.,  138.,   22.,  -54.,  144.,
           -68.,  -70.,  -54.],
         [-114., -152.,   54.,  -20.,   84.,  -38.,  -88., -116., -188.,  -50.,
            14.,    4.,   48.,  144.,   36.,  -62.,  -22., -110.,   20.,   48.,
           -80.,   12.,  -14., -104.,   60.,  318.,  100.,   58.,    8., -118.,
           -40.,  -72.,   36.,  338.,    2.,  146.,  138.,   22.,  -54.,  144.,
           -68.,  -70.,  -54.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[452., 490., 284., 358., 254., 376., 426., 454., 526., 388.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6875 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.76s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-112., -142.,   52.,   10.,   74.,  -40.,  -98., -118., -126.,  -24.,
            32.,  -38.,   62.,   74.,   38.,  -24.,    8.,  -72.,   26.,    6.,
           -50.,  -30.,  -64., -138.,   66.,  148.,   66.,   28.,  -46.,  -48.,
           -70.,  -86.,   42.,  396.,   20.,  208.,  108.,   52.,  -40.,  174.,
            -2.,  -48.,  -76.],
         [-112., -142.,   52.,   10.,   74.,  -40.,  -98., -118., -126.,  -24.,
            32.,  -38.,   62.,   74.,   38.,  -24.,    8.,  -72.,   26.,    6.,
           -50.,  -30.,  -64., -138.,   66.,  148.,   66.,   28.,  -46.,  -48.,
           -70.,  -86.,   42.,  396.,   20.,  208.,  108.,   52.,  -40.,  174.,
            -2.,  -48.,  -76.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[508., 538., 344., 386., 322., 436., 494., 514., 522., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7705 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.68s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-122., -144.,   90.,  -24.,   88.,  -58.,  -92., -120., -188.,  -66.,
            14.,  -28.,   60.,  136.,   16.,  -66.,  -38.,  -94.,   16.,   48.,
           -60.,  -12.,   -2.,  -80.,   72.,  302.,   72.,   42.,  -16., -118.,
           -28.,  -96.,   60.,  326.,   10.,  154.,  110.,   42.,  -26.,  168.,
           -44.,  -46.,  -42.],
         [-122., -144.,   90.,  -24.,   88.,  -58.,  -92., -120., -188.,  -66.,
            14.,  -28.,   60.,  136.,   16.,  -66.,  -38.,  -94.,   16.,   48.,
           -60.,  -12.,   -2.,  -80.,   72.,  302.,   72.,   42.,  -16., -118.,
           -28.,  -96.,   60.,  326.,   10.,  154.,  110.,   42.,  -26.,  168.,
           -44.,  -46.,  -42.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[448., 470., 236., 350., 238., 384., 418., 446., 514., 392.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6915 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.75s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-116., -154.,   20.,   14.,   86.,  -52., -118., -102., -134.,   -8.,
            32.,  -54.,   86.,   94.,   26.,  -32.,   -4.,  -52.,   10.,   14.,
           -18.,  -42.,  -44., -118.,   78.,  176.,  122.,   24.,  -26.,  -56.,
           -82., -118.,   46.,  420.,   36.,  232.,  100.,   80.,  -88.,  186.,
           -30.,  -52.,  -80.],
         [-116., -154.,   20.,   14.,   86.,  -52., -118., -102., -134.,   -8.,
            32.,  -54.,   86.,   94.,   26.,  -32.,   -4.,  -52.,   10.,   14.,
           -18.,  -42.,  -44., -118.,   78.,  176.,  122.,   24.,  -26.,  -56.,
           -82., -118.,   46.,  420.,   36.,  232.,  100.,   80.,  -88.,  186.,
           -30.,  -52.,  -80.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[536., 574., 400., 406., 334., 472., 538., 522., 554., 428.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7598 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.68s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -90., -120.,   30.,   16.,   28., -118., -152., -144., -112.,    6.,
           -46.,  -80.,   88.,  108.,   36.,  -18.,   14.,  -50.,  -12.,    0.,
            28.,  -24.,  -14.,  -92.,   88.,  198.,   96.,   14.,   12.,  -18.,
           -60., -124.,   12.,  354.,   34.,  334.,  110.,   70.,  -90.,  136.,
           -40.,  -18.,  -70.],
         [ -90., -120.,   30.,   16.,   28., -118., -152., -144., -112.,    6.,
           -46.,  -80.,   88.,  108.,   36.,  -18.,   14.,  -50.,  -12.,    0.,
            28.,  -24.,  -14.,  -92.,   88.,  198.,   96.,   14.,   12.,  -18.,
           -60., -124.,   12.,  354.,   34.,  334.,  110.,   70.,  -90.,  136.,
           -40.,  -18.,  -70.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[444., 474., 324., 338., 326., 472., 506., 498., 466., 348.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6928 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.75s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -90., -116.,   30.,   -4.,   72.,  -18., -108., -116., -140.,  -30.,
            50.,  -40.,   88.,   96.,   32.,  -18.,    2.,  -66.,   16.,   12.,
           -24.,   -4.,  -66., -116.,  100.,  150.,  112.,   30.,  -36.,  -50.,
           -80., -112.,   36.,  406.,   26.,  230.,   78.,   70.,  -62.,  136.,
           -24.,  -74.,  -62.],
         [ -90., -116.,   30.,   -4.,   72.,  -18., -108., -116., -140.,  -30.,
            50.,  -40.,   88.,   96.,   32.,  -18.,    2.,  -66.,   16.,   12.,
           -24.,   -4.,  -66., -116.,  100.,  150.,  112.,   30.,  -36.,  -50.,
           -80., -112.,   36.,  406.,   26.,  230.,   78.,   70.,  -62.,  136.,
           -24.,  -74.,  -62.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[496., 522., 376., 410., 334., 424., 514., 522., 546., 436.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.7591 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
100%|| 1/1 [00:15<00:00, 15.69s/it]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-140., -166.,   44.,  -34.,   70.,  -52., -106., -102., -178.,  -56.,
            20.,   -6.,   54.,  126.,   26.,  -44.,  -28.,  -96.,  -14.,   38.,
           -66.,   22.,  -16.,  -46.,   70.,  344.,  106.,   44.,    2., -108.,
            -6.,  -78.,   22.,  364.,  -32.,  168.,  100.,   24.,  -64.,  158.,
           -66.,  -40.,  -52.],
         [-140., -166.,   44.,  -34.,   70.,  -52., -106., -102., -178.,  -56.,
            20.,   -6.,   54.,  126.,   26.,  -44.,  -28.,  -96.,  -14.,   38.,
           -66.,   22.,  -16.,  -46.,   70.,  344.,  106.,   44.,    2., -108.,
            -6.,  -78.,   22.,  364.,  -32.,  168.,  100.,   24.,  -64.,  158.,
           -66.,  -40.,  -52.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[504., 530., 320., 398., 294., 416., 470., 466., 542., 420.]]],
       device='cuda:0')
number of violation:  0
Attack finished in 15.6994 seconds.
PGD attack failed
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]Error: run_instance.sh exceeded 1060 second timeout!
run_instance.sh exit code: 124, Result: run_instance_timeout, Runtime: 1060.001558105
Appending result 'run_instance_timeout' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:00:36 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 96%   63C    P3              42W / 170W |    456MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:01<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 14.076759520

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:00:48 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2106s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:01<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ -88.,  -98.,   68.,   22.,   14.,  -96., -118., -154., -134.,   52.,
           -20.,  -66.,   78.,  106.,   30.,  -36.,   24.,  -60.,  -38.,   54.,
           -14.,  -30.,  -60., -102.,   66.,  160.,   90.,   28.,  -14.,  -60.,
           -94., -142.,   70.,  312.,   40.,  320.,  100.,   72.,  -84.,  122.,
           -38.,   24.,  -20.],
         [ -88.,  -98.,   68.,   22.,   14.,  -96., -118., -154., -134.,   52.,
           -20.,  -66.,   78.,  106.,   30.,  -36.,   24.,  -60.,  -38.,   54.,
           -14.,  -30.,  -60., -102.,   66.,  160.,   90.,   28.,  -14.,  -60.,
           -94., -142.,   70.,  312.,   40.,  320.,  100.,   72.,  -84.,  122.,
           -38.,   24.,  -20.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[400., 410., 244., 290., 298., 408., 430., 466., 446., 260.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 1.8917 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 3.0362234115600586
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 6.939615510
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:00:57 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 92%   58C    P3              37W / 170W |    456MiB / 12288MiB |      5%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      133MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:01<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 13.425163476

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:01:09 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2180s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:01<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-128., -102.,   24.,    2.,   22., -132., -154., -158., -154.,   48.,
            -8.,  -54.,  110.,  134.,   42.,  -28.,   44.,  -24.,   10.,   30.,
            -2.,   26.,  -32., -102.,   94.,  192.,   46.,   24.,    2.,  -76.,
          -106., -126.,   82.,  308.,   72.,  320.,  112.,   52.,  -96.,  162.,
           -50.,    4.,  -40.],
         [-128., -102.,   24.,    2.,   22., -132., -154., -158., -154.,   48.,
            -8.,  -54.,  110.,  134.,   42.,  -28.,   44.,  -24.,   10.,   30.,
            -2.,   26.,  -32., -102.,   94.,  192.,   46.,   24.,    2.,  -76.,
          -106., -126.,   82.,  308.,   72.,  320.,  112.,   52.,  -96.,  162.,
           -50.,    4.,  -40.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[436., 410., 284., 306., 286., 440., 462., 466., 462., 260.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 1.2681 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 2.4111249446868896
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 6.289513519
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:01:17 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 90%   55C    P5              35W / 170W |    456MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:01<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 13.256223190

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:01:28 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2120s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -94., -160.,   30.,   12.,   88.,  -50.,  -76.,  -64., -144.,  -22.,
           -6.,  -44.,   60.,   96.,   48.,   22.,   -6.,  -62.,  -12.,  -36.,
          -72.,  -20.,  -70., -148.,   84.,  130.,  140.,   22.,  -80.,  -58.,
          -68., -112.,   28.,  486.,   42.,  158.,   70.,  110.,  -46.,  176.,
           40.,  -78.,  -82.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:01<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-110., -120.,   -2.,   -4.,  -12., -154., -152., -196., -116.,   90.,
            -2.,  -28.,  140.,  116.,   36.,   -2.,   50.,  -14.,  -20.,  -28.,
            28.,  -24.,  -14.,  -60.,  116.,  138.,   40.,    2.,  -20.,  -26.,
           -96., -184.,   72.,  306.,   70.,  382.,   94.,  146., -110.,   92.,
            28.,   58.,  -10.],
         [-110., -120.,   -2.,   -4.,  -12., -154., -152., -196., -116.,   90.,
            -2.,  -28.,  140.,  116.,   36.,   -2.,   50.,  -14.,  -20.,  -28.,
            28.,  -24.,  -14.,  -60.,  116.,  138.,   40.,    2.,  -20.,  -26.,
           -96., -184.,   72.,  306.,   70.,  382.,   94.,  146., -110.,   92.,
            28.,   58.,  -10.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[416., 426., 308., 310., 318., 460., 458., 502., 422., 216.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 1.1093 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 2.2553396224975586
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 6.096210356
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:01:36 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 88%   53C    P3              37W / 170W |    456MiB / 12288MiB |      3%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.922965208

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:01:47 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2014s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_8258_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ -98., -156.,   10.,   28.,   72.,  -46.,  -80.,  -80., -160.,  -26.,
           10.,  -20.,   60.,   88.,   52.,   -2.,    6.,  -74.,    4.,   -4.,
          -68.,  -24.,  -54., -132.,   96.,  150.,  116.,   34.,  -72.,  -70.,
          -64., -100.,   20.,  486.,   38.,  150.,   74.,  102.,  -34.,  188.,
           32.,  -98.,  -74.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-112., -126.,  -12.,   38.,   30.,  -24.,  -34.,  -34., -158., -104.,
           -44.,   86.,   34.,  102.,  -42., -124.,  -32., -116.,   14.,   42.,
           -94.,   18.,  -20.,  -46.,   10.,  320.,    2.,   80.,  -30.,  -12.,
           -94.,    2.,   -6.,  288.,  -96.,   60.,   68.,    0.,   40.,  162.,
            10.,  -36.,  -32.],
         [-112., -126.,  -12.,   38.,   30.,  -24.,  -34.,  -34., -158., -104.,
           -44.,   86.,   34.,  102.,  -42., -124.,  -32., -116.,   14.,   42.,
           -94.,   18.,  -20.,  -46.,   10.,  320.,    2.,   80.,  -30.,  -12.,
           -94.,    2.,   -6.,  288.,  -96.,   60.,   68.,    0.,   40.,  162.,
            10.,  -36.,  -32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[400., 414., 300., 250., 258., 312., 322., 322., 446., 392.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.7941 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.9340522289276123
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.817721178
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:01:55 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 87%   51C    P3              37W / 170W |    456MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      133MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.639411085

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:02:06 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2046s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_1.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  70.,  160.,  -78., -100.,  192.,  122.,  -40.,  364.,  148.,  -38.,
           30.,  -96.,   40.,  -24.,  -28.,   42.,   62.,  -30., -160., -160.,
           20.,  -16.,  -38.,  -44.,  -44., -158.,  -80.,  -82.,  -44.,  -82.,
          -32.,  -56.,   -8.,   98.,  -70.,  -46.,  -82.,   74.,  -70.,   60.,
          136.,  -42.,   74.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 118.,  148.,  -74.,  -40.,  160.,   42.,  -36.,  188.,  288.,   30.,
            10., -168.,   68.,   -8.,    4.,  106.,  102.,   30., -184., -144.,
            24., -112.,   10.,  -80., -124., -202., -128., -118.,  -64.,  -78.,
           -52.,    0.,   48.,   46.,   22.,    2.,  -70.,   58.,  -70.,   76.,
            92.,   30.,   -6.],
         [ 118.,  148.,  -74.,  -40.,  160.,   42.,  -36.,  188.,  288.,   30.,
            10., -168.,   68.,   -8.,    4.,  106.,  102.,   30., -184., -144.,
            24., -112.,   10.,  -80., -124., -202., -128., -118.,  -64.,  -78.,
           -52.,    0.,   48.,   46.,   22.,    2.,  -70.,   58.,  -70.,   76.,
            92.,   30.,   -6.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[  70.,   40.,  262.,  228.,   28.,  146.,  224., -100.,  158.,  178.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4878 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6272859573364258
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.509866006
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:02:13 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 86%   50C    P3              37W / 170W |    456MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          209MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                     23MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.599597829

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:02:24 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2077s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_3.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  70.,  160.,  -78., -100.,  192.,  122.,  -40.,  364.,  148.,  -38.,
           30.,  -96.,   40.,  -24.,  -28.,   42.,   62.,  -30., -160., -160.,
           20.,  -16.,  -38.,  -44.,  -44., -158.,  -80.,  -82.,  -44.,  -82.,
          -32.,  -56.,   -8.,   98.,  -70.,  -46.,  -82.,   74.,  -70.,   60.,
          136.,  -42.,   74.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[   4.,   14.,    0., -134.,  134.,   36.,  -74.,  222.,  270.,   20.,
           108., -162.,  130.,    6.,  -38.,  104.,   72.,   36., -286.,  -42.,
           -46.,  -62.,   64.,  -34.,  -86., -104.,  -70., -176., -102.,  -68.,
           -66.,   22.,  -86.,   16.,   16.,    8.,  -76.,   44.,  -24.,   34.,
            82.,   32.,   32.],
         [   4.,   14.,    0., -134.,  134.,   36.,  -74.,  222.,  270.,   20.,
           108., -162.,  130.,    6.,  -38.,  104.,   72.,   36., -286.,  -42.,
           -46.,  -62.,   64.,  -34.,  -86., -104.,  -70., -176., -102.,  -68.,
           -66.,   22.,  -86.,   16.,   16.,    8.,  -76.,   44.,  -24.,   34.,
            82.,   32.,   32.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[218., 208., 222., 356.,  88., 186., 296., -48., 202., 114.]]],
       device='cuda:0')
number of violation:  1
Attack finished in 0.4882 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6239769458770752
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.530363756
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:02:32 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 85%   51C    P0              58W / 170W |    603MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          263MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    116MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      132MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.639286714

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:02:42 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2212s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_5.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=1.25, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  70.,  160.,  -78., -100.,  192.,  122.,  -40.,  364.,  148.,  -38.,
           30.,  -96.,   40.,  -24.,  -28.,   42.,   62.,  -30., -160., -160.,
           20.,  -16.,  -38.,  -44.,  -44., -158.,  -80.,  -82.,  -44.,  -82.,
          -32.,  -56.,   -8.,   98.,  -70.,  -46.,  -82.,   74.,  -70.,   60.,
          136.,  -42.,   74.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 156.,  122.,  -44.,  -42.,  206.,   56.,   -2.,   14.,  246.,   48.,
           -64., -238.,    2.,  -18.,   -6.,   64.,   64.,   60., -218.,  -26.,
            74.,  -46.,   -4.,  -46.,  -34., -224.,   18.,  -76., -122.,  -12.,
          -106.,   62.,   22.,   64.,   12.,    0., -108.,   80.,  -24.,   94.,
            90.,  -16.,  -72.],
         [ 156.,  122.,  -44.,  -42.,  206.,   56.,   -2.,   14.,  246.,   48.,
           -64., -238.,    2.,  -18.,   -6.,   64.,   64.,   60., -218.,  -26.,
            74.,  -46.,   -4.,  -46.,  -34., -224.,   18.,  -76., -122.,  -12.,
          -106.,   62.,   22.,   64.,   12.,    0., -108.,   80.,  -24.,   94.,
            90.,  -16.,  -72.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[-142., -108.,   58.,   56., -192.,  -42.,   16., -232.,  -34.,   78.]]],
       device='cuda:0')
number of violation:  17
Attack finished in 0.4865 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.624061107635498
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.509880745
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:02:50 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 85%   48C    P3              37W / 170W |    563MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          263MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    116MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       92MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.577603536

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:03:00 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2166s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_10.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=2.5, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  80.,  166.,  -44.,  -62.,  166.,  140.,  -18.,  374.,  154.,  -48.,
           20., -106.,   -6.,  -10.,  -18.,   32.,   72.,  -12., -170., -146.,
           18.,  -30.,  -56.,  -78.,  -74., -180., -102.,  -88.,  -42.,  -84.,
          -30.,  -30.,   10.,   84.,  -84.,  -40., -112.,   72.,  -92.,   66.,
          138.,  -64.,   68.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  20.,   74.,   64.,  -62.,   42.,  140.,  -66.,   -6.,   62.,   84.,
           128., -154.,   -6.,   14.,  -74.,  -64.,  -52.,   72., -222.,  -30.,
            26.,  -46.,   80.,  102.,  -42.,  -44.,    6., -172., -170.,  -20.,
           -50.,   70., -182.,  -20.,    4.,   84.,  -32.,   68.,   68.,   14.,
           154.,   36.,    0.],
         [  20.,   74.,   64.,  -62.,   42.,  140.,  -66.,   -6.,   62.,   84.,
           128., -154.,   -6.,   14.,  -74.,  -64.,  -52.,   72., -222.,  -30.,
            26.,  -46.,   80.,  102.,  -42.,  -44.,    6., -172., -170.,  -20.,
           -50.,   70., -182.,  -20.,    4.,   84.,  -32.,   68.,   68.,   14.,
           154.,   36.,    0.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ -26.,  -80.,  -70.,   56.,  -48., -146.,   60.,  -68.,  -90., -134.]]],
       device='cuda:0')
number of violation:  23
Attack finished in 0.4865 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6195337772369385
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.546340763
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:03:08 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 84%   47C    P3              36W / 170W |    610MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          263MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    116MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand      139MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
  0%|                                                     | 0/1 [00:00<?, ?it/s]
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 12.633878889

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp23/gtrsb.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: min
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "merge_sign")'
  no_batchdim_buffers: true
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: 'Customized("custom_model_loader", "customized_Gtrsb_loader")'
  onnx_optimization_flags: fix_gtrsb
  onnx_vnnlib_joint_optimization_flags: [peel_off_last_softmax_layer]
  check_optmized: true
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 128
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: [MaxPool]
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 8
    solver_threads: 4
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 6
    reduceop: max
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 180
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_batch_size: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: 'Customized("custom_adv_saver", "customized_gtrsb_saver")'
  early_stop_condition: 'Customized("custom_early_stop_condition", "customized_gtrsb_condition")'
  adv_example_finalizer: 'Customized("custom_adv_example_finalizer", "customized_gtrsb_adv_example_finalizer")'
  pgd_loss: 'Customized("custom_pgd_loss", "customized_gtrsb_loss")'
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: 'Customized("custom_attacker", "use_LiRPANet")'
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:03:19 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.1941s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx wih quirks {}
Onnx optimization with flag: fix_gtrsb
Found existed optimized onnx model at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/onnx/3_64_64_QConv_32_5_MP_2_BN_QConv_64_5_MP_2_BN_QConv_64_3_MP_2_BN_Dense_1024_BN_Dense_43_ep_30.onnx.optimized
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
Automatic inference of operator: sign
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/traffic_signs_recognition/vnnlib/model_64_idx_11985_eps_15.00000.vnnlib.compiled
Last Softmax node found, peel it off
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if shape[0] == 1 and len(shape) in [2, 3, 4, 5] and self.quirks.get("fix_batch_size") is True:
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:54: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  if (torch.prod(torch.tensor(input.shape)) != torch.prod(shape) and len(input.size()) == len(shape) + 1
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/operations/reshape.py:58: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  shape = [x if x != 0 else input.size(i) for i, x in enumerate(shape)]
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Merging Sign node: %s BoundSign(name=/44, inputs=[/43], perturbed=False)
Merging Sign node: %s BoundSign(name=/50, inputs=[/49], perturbed=False)
Merging Sign node: %s BoundSign(name=/56, inputs=[/55], perturbed=False)
Merging Sign node: %s BoundSign(name=/71, inputs=[/70], perturbed=False)
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=3.75, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[  54.,  112.,  -98.,  -76.,  124.,  130.,  -60.,  332.,  164.,   -2.,
           70.,  -64.,   56.,  -24.,  -24.,   82.,   94.,   26., -192., -168.,
           24.,  -12.,  -62.,  -72.,  -64., -174.,  -80.,  -98.,  -24.,  -98.,
            4.,  -80.,   20.,   78.,  -38.,    2.,  -58.,   54.,  -66.,   76.,
          120.,  -38.,   50.]], device='cuda:0')
  0%|                                                     | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                     | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[  80.,  102., -140.,  -42.,   46.,   44.,  -38.,   26.,  -26.,   20.,
           -64., -138.,   -2.,   78.,   86.,  -92.,   -8.,  140.,  -82., -122.,
            50., -138.,   64.,  -66.,  -14.,  -24.,  -66.,  -16.,  -18.,  -24.,
           -26., -150.,   38.,   24.,  136.,   40.,  -32.,   44.,  116.,  -42.,
           174.,   84.,   20.],
         [  80.,  102., -140.,  -42.,   46.,   44.,  -38.,   26.,  -26.,   20.,
           -64., -138.,   -2.,   78.,   86.,  -92.,   -8.,  140.,  -82., -122.,
            50., -138.,   64.,  -66.,  -14.,  -24.,  -66.,  -16.,  -18.,  -24.,
           -26., -150.,   38.,   24.,  136.,   40.,  -32.,   44.,  116.,  -42.,
           174.,   84.,   20.]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[-54., -76., 166.,  68., -20., -18.,  64.,  52.,   6.,  90.]]],
       device='cuda:0')
number of violation:  16
Attack finished in 0.4865 seconds.
PGD attack succeeded!
/home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/custom/custom_adv_saver.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  adv_output = F.softmax(adv_output).detach().cpu().numpy()
Result: sat
Time: 1.6268153190612793
exit code: 0
run_instance.sh exit code: 0, Result: sat, Runtime: 5.492929659
Appending result 'sat' to csv file 'results_traffic_signs_recognition.csv'
Doing run_single_instance with category 'traffic_signs_recognition' on onnx network '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx' with vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib' and timeout '1000'
/home/rafael/miniconda3/envs/alpha-beta-crown/bin
Preparing alpha-beta-CROWN for benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx' and vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib'
TOOL_DIR is /home/rafael/repos/VFProject/alpha-beta-CROWN
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
sudo: a password is required
Thu Dec 21 15:03:26 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060        Off | 00000000:05:00.0  On |                  N/A |
| 84%   47C    P3              38W / 170W |    566MiB / 12288MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1226      G   /usr/lib/xorg/Xorg                          263MiB |
|    0   N/A  N/A      2327      G   cinnamon                                     33MiB |
|    0   N/A  N/A      2989      G   /usr/lib/firefox/firefox                    116MiB |
|    0   N/A  N/A      3467      G   ...sion,SpareRendererForSitePerProcess       43MiB |
|    0   N/A  N/A      7302      G   ...,WinRetrieveSuggestionsOnlyOnDemand       95MiB |
+---------------------------------------------------------------------------------------+

Running warmup...

Preparation time is roughly 45 seconds for traffic_signs_recognition
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Preparation finished.
prepare_instance.sh exit code: 0, runtime: 10.875553214

Running benchmark instance in category 'traffic_signs_recognition' with onnx file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx', vnnlib file '/home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib', results file out.txt, and timeout 1000

------------------------- COMMAND ------------------------------
/home/rafael/miniconda3/envs/alpha-beta-crown/bin/python3 /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/abcrown.py --config /home/rafael/repos/VFProject/alpha-beta-CROWN/complete_verifier/exp_configs/vnncomp21/test.yaml --precompile_jit --onnx_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx --vnnlib_path /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib --results_file out.txt --timeout 1000 --save_adv_example
----------------------------------------------------------------

/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: true
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: true
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: test_instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2021/benchmarks/test
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  no_batchdim_buffers: false
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: [-1, 1]
  onnx_loader: 'Customized("custom_model_loader", "customized_TEST_loader")'
  onnx_optimization_flags: none
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 64
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: []
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 1000.0
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: true
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: input_bab
  pgd_steps: 100
  pgd_restarts: 30
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Thu Dec 21 15:03:35 2023 on rafaelban
Pre-compile jit kernels on a toy network...
JIT kernels compiled in 2.2186s.
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx
Using vnnlib /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib
Loading onnx /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.onnx wih quirks {}
/home/rafael/miniconda3/envs/alpha-beta-crown/lib/python3.9/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Precompiled vnnlib file found at /home/rafael/repos/VFProject/alpha-beta-CROWN/vnncomp2023_benchmarks/benchmarks/test/test_nano.vnnlib.compiled
Linear layers are transposed in this model.
Model: BoundedModule(
  (/0): BoundInput(name=/0, inputs=[], perturbed=True)
  (/1): BoundParams(name=/1, inputs=[], perturbed=False)
  (/2): BoundParams(name=/2, inputs=[], perturbed=False)
  (/input): BoundLinear(name=/input, inputs=[/0, /1, /2], perturbed=True)
  (/4): BoundRelu(name=/4, inputs=[/input], perturbed=True)
)
Original output: tensor([[0.]], device='cuda:0')
Split layers:
  BoundLinear(name=/input, inputs=[/0, /1, /2], perturbed=True): [(BoundRelu(name=/4, inputs=[/input], perturbed=True), 0)]
Nonlinear functions:
   BoundRelu(name=/4, inputs=[/input], perturbed=True)
layer /4 using full alpha with shape torch.Size([1]); unstable size 1; total size 1 ([1, 1])
layer /4 start_node /4 using full alpha [2, 1, 1, 1] with unstable size None total_size 1 output_shape 1
Optimizable variables initialized.
initial CROWN bounds: tensor([[0.]], device='cuda:0') None
Verified with initial CROWN!
verified with init bound!
Result: unsat
Time: 0.08977913856506348
exit code: 0
run_instance.sh exit code: 0, Result: unsat, Runtime: 3.742917490
Appending result 'unsat' to csv file 'results_traffic_signs_recognition.csv'
Timeout of executed instances: 45000 sec

